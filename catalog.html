<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AI Training Catalog</title>
<style>
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #f5f7fa; color: #1a1a2e; line-height: 1.6; }
  .header { background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); color: white; padding: 2rem; text-align: center; }
  .header h1 { font-size: 2rem; margin-bottom: 0.5rem; }
  .header p { opacity: 0.85; font-size: 1.1rem; }
  .stats-bar { display: flex; justify-content: center; gap: 2rem; margin-top: 1.5rem; flex-wrap: wrap; }
  .stat { text-align: center; }
  .stat-num { font-size: 2rem; font-weight: 700; color: #e94560; }
  .stat-label { font-size: 0.85rem; opacity: 0.7; }
  .container { max-width: 1200px; margin: 0 auto; padding: 1.5rem; }
  .tabs { display: flex; gap: 0; margin-bottom: 1.5rem; border-bottom: 2px solid #e0e0e0; }
  .tab { padding: 0.75rem 1.5rem; cursor: pointer; background: none; border: none; font-size: 1rem; color: #666; border-bottom: 3px solid transparent; margin-bottom: -2px; }
  .tab.active { color: #0f3460; border-bottom-color: #e94560; font-weight: 600; }
  .tab:hover { color: #0f3460; }
  .search-bar { display: flex; gap: 0.75rem; margin-bottom: 1.5rem; flex-wrap: wrap; }
  .search-bar input { flex: 1; min-width: 200px; padding: 0.75rem 1rem; border: 2px solid #e0e0e0; border-radius: 8px; font-size: 1rem; }
  .search-bar input:focus { outline: none; border-color: #0f3460; }
  .search-bar select { padding: 0.75rem 1rem; border: 2px solid #e0e0e0; border-radius: 8px; font-size: 0.95rem; background: white; }
  .filters { display: flex; gap: 0.5rem; flex-wrap: wrap; margin-bottom: 1rem; }
  .filter-chip { padding: 0.4rem 0.8rem; border-radius: 20px; border: 1px solid #ccc; background: white; cursor: pointer; font-size: 0.85rem; }
  .filter-chip.active { background: #0f3460; color: white; border-color: #0f3460; }
  .filter-chip:hover { border-color: #0f3460; }
  .section { display: none; }
  .section.active { display: block; }
  .card { background: white; border-radius: 10px; padding: 1.25rem; margin-bottom: 1rem; box-shadow: 0 1px 3px rgba(0,0,0,0.08); border-left: 4px solid #0f3460; }
  .card:hover { box-shadow: 0 4px 12px rgba(0,0,0,0.12); }
  .card-header { display: flex; justify-content: space-between; align-items: flex-start; margin-bottom: 0.5rem; }
  .card-title { font-size: 1.1rem; font-weight: 600; color: #1a1a2e; }
  .card-title a { color: #0f3460; text-decoration: none; }
  .card-title a:hover { text-decoration: underline; }
  .card-score { background: #e94560; color: white; padding: 0.2rem 0.6rem; border-radius: 12px; font-size: 0.8rem; font-weight: 600; white-space: nowrap; }
  .card-score.high { background: #2ecc71; }
  .card-score.medium { background: #f39c12; }
  .card-score.low { background: #e74c3c; }
  .card-desc { color: #555; font-size: 0.95rem; margin-bottom: 0.75rem; }
  .card-tags { display: flex; gap: 0.4rem; flex-wrap: wrap; }
  .tag { padding: 0.2rem 0.6rem; border-radius: 4px; font-size: 0.78rem; font-weight: 500; }
  .tag-domain { background: #e8f0fe; color: #1a73e8; }
  .tag-type { background: #fce8e6; color: #d93025; }
  .tag-difficulty { background: #e6f4ea; color: #137333; }
  .tag-provider { background: #fef7e0; color: #b06000; }
  .tag-hours { background: #f3e8fd; color: #7b1fa2; }
  .path-card { border-left-color: #e94560; }
  .path-card .path-difficulty { display: inline-block; padding: 0.2rem 0.6rem; border-radius: 4px; font-size: 0.8rem; font-weight: 600; margin-right: 0.5rem; }
  .path-difficulty.beginner { background: #e6f4ea; color: #137333; }
  .path-difficulty.intermediate { background: #fef7e0; color: #b06000; }
  .path-difficulty.advanced { background: #fce8e6; color: #d93025; }
  .module-list { margin-top: 0.75rem; padding-left: 1.5rem; }
  .module-item { margin-bottom: 0.5rem; color: #444; font-size: 0.95rem; }
  .module-resources { font-size: 0.85rem; color: #888; margin-left: 0.5rem; }
  .count-badge { background: #eee; padding: 0.2rem 0.5rem; border-radius: 10px; font-size: 0.85rem; color: #666; margin-left: 0.5rem; }
  .empty-state { text-align: center; padding: 3rem; color: #888; }
  .resource-link { display: block; margin-top: 0.4rem; }
  .resource-link a { color: #1a73e8; text-decoration: none; font-size: 0.85rem; word-break: break-all; }
  .resource-link a:hover { text-decoration: underline; }
  @media (max-width: 768px) {
    .stats-bar { gap: 1rem; }
    .stat-num { font-size: 1.5rem; }
    .card-header { flex-direction: column; gap: 0.5rem; }
  }
</style>
</head>
<body>

<div class="header">
  <h1>AI Training Catalog</h1>
  <p>Free &amp; Open Source AI Training Resources â€” Auto-Curated</p>
  <div class="stats-bar">
    <div class="stat"><div class="stat-num" id="total-resources">0</div><div class="stat-label">Resources</div></div>
    <div class="stat"><div class="stat-num" id="total-paths">0</div><div class="stat-label">Learning Paths</div></div>
    <div class="stat"><div class="stat-num" id="total-hours">0</div><div class="stat-label">Hours of Content</div></div>
    <div class="stat"><div class="stat-num" id="total-domains">0</div><div class="stat-label">Skill Domains</div></div>
  </div>
</div>

<div class="container">
  <div class="tabs">
    <button class="tab active" onclick="switchTab('catalog')">Resource Catalog</button>
    <button class="tab" onclick="switchTab('curriculum')">Learning Paths</button>
  </div>

  <!-- CATALOG TAB -->
  <div id="catalog-section" class="section active">
    <div class="search-bar">
      <input type="text" id="search-input" placeholder="Search resources by title, description, tags..." oninput="filterResources()">
      <select id="domain-filter" onchange="filterResources()">
        <option value="">All Domains</option>
      </select>
      <select id="type-filter" onchange="filterResources()">
        <option value="">All Types</option>
      </select>
      <select id="difficulty-filter" onchange="filterResources()">
        <option value="">All Levels</option>
        <option value="beginner">Beginner</option>
        <option value="intermediate">Intermediate</option>
        <option value="advanced">Advanced</option>
      </select>
    </div>
    <div id="resource-count" style="margin-bottom:1rem; color:#666; font-size:0.9rem;"></div>
    <div id="resource-list"></div>
  </div>

  <!-- CURRICULUM TAB -->
  <div id="curriculum-section" class="section">
    <div class="search-bar">
      <input type="text" id="path-search" placeholder="Search learning paths..." oninput="filterPaths()">
      <select id="path-domain-filter" onchange="filterPaths()">
        <option value="">All Domains</option>
      </select>
      <select id="path-difficulty-filter" onchange="filterPaths()">
        <option value="">All Levels</option>
        <option value="beginner">Beginner</option>
        <option value="intermediate">Intermediate</option>
        <option value="advanced">Advanced</option>
      </select>
    </div>
    <div id="path-list"></div>
  </div>
</div>

<script>
const RESOURCES = [{"id": "0abcb8d6878db0f0", "url": "https://github.com/mlabonne/llm-course", "title": "mlabonne/llm-course", "description": "Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.", "provider": "github", "domains": ["generative_ai", "nlp", "ml_basics", "deep_learning"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 1.0, "prerequisites": [], "tags": ["large language models", "RAG", "fine-tuning"], "quality_score": 0.889, "discovered_at": "2026-02-09T15:00:29.067159Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 74861, "language": null, "topics": ["course", "large-language-models", "llm", "machine-learning", "roadmap"], "updated_at": "2026-02-09T14:56:35Z"}}, {"id": "2d35d90c43823111", "url": "https://github.com/bregman-arie/devops-exercises", "title": "bregman-arie/devops-exercises", "description": "Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions", "provider": "github", "domains": ["mlops"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 4.0, "prerequisites": [], "tags": [], "quality_score": 0.84, "discovered_at": "2026-02-09T15:00:29.592283Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 80903, "language": "Python", "topics": ["ansible", "aws", "azure", "coding", "containers", "devops", "docker", "git", "interview", "interview-questions", "kubernetes", "linux", "openstack", "production-engineer", "prometheus", "python", "sql", "sre", "terraform"], "updated_at": "2026-02-09T14:58:00Z"}}, {"id": "7636653251b1bd3a", "url": "https://github.com/josephmisiti/awesome-machine-learning", "title": "josephmisiti/awesome-machine-learning", "description": "A curated list of awesome Machine Learning frameworks, libraries and software.", "provider": "github", "domains": ["ml_basics", "deep_learning", "nlp", "computer_vision", "reinforcement_learning"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 3.3, "prerequisites": [], "tags": ["feature engineering"], "quality_score": 0.839, "discovered_at": "2026-02-09T15:00:29.489379Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 71621, "language": "Python", "topics": [], "updated_at": "2026-02-09T07:22:21Z"}}, {"id": "d3dfeb6d5f0d6e87", "url": "https://github.com/hiyouga/LlamaFactory", "title": "hiyouga/LlamaFactory", "description": "Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024)", "provider": "github", "domains": ["generative_ai", "nlp", "mlops", "reinforcement_learning"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.9, "prerequisites": [], "tags": ["large language models", "fine-tuning"], "quality_score": 0.838, "discovered_at": "2026-02-09T15:00:29.996601Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 67092, "language": "Python", "topics": ["agent", "ai", "deepseek", "fine-tuning", "gemma", "gpt", "instruction-tuning", "large-language-models", "llama", "llama3", "llm", "lora", "moe", "nlp", "peft", "qlora", "quantization", "qwen", "rlhf", "transformers"], "updated_at": "2026-02-09T14:43:03Z"}}, {"id": "e6ebd93e28b6ccc2", "url": "http://arxiv.org/abs/1211.0225v1", "title": "The role of the Model Validation function to manage and mitigate model risk", "description": "This paper describes the current taxonomy of model risk, ways for its mitigation and management and the importance of the model validation function in collaboration with other departments to design and implement them.", "provider": "mit", "domains": ["ai_governance", "ai_project_management", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.69, "discovered_at": "2026-02-09T15:18:54.775011Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper describes the current taxonomy of model risk, ways for its mitigation and management and the importance of the model validation function in collaboration with other departments to design and implement them."}}, {"id": "4592da1aa1edace8", "url": "http://arxiv.org/abs/2601.16513v1", "title": "Competing Visions of Ethical AI: A Case Study of OpenAI", "description": "Introduction. AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Method. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment' and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assem", "provider": "openai", "domains": ["ai_ethics", "nlp", "ai_project_management", "ai_governance"], "content_type": "course", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.65, "discovered_at": "2026-02-09T15:00:32.094645Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Introduction. AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Method. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment' and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assembled from public documentation. Analysis. Qualitative content analysis of ethical themes combined inductively derived and deductively applied codes. Quantitative analysis leveraged computational content analysis methods via NLP to model topics and quantify changes in rhetoric over time. Visualizations report aggregate results. For reproducible results, we have released our code at https://github.com/famous-blue-raincoat/AI_Ethics_Discourse. Results. Results indicate that safety and risk discourse dominate OpenAI's public communication and documentation, without applying academic and advocacy ethics frameworks or vocabularies. Conclusions. Implications for governance are presented, along with discussion of ethics-washing practices in industry."}}, {"id": "4bedaf1c79629481", "url": "http://arxiv.org/abs/1911.04947v2", "title": "Accelerating Training in Pommerman with Imitation and Reinforcement Learning", "description": "The Pommerman simulation was recently developed to mimic the classic Japanese game Bomberman, and focuses on competitive gameplay in a multi-agent setting. We focus on the 2$\\times$2 team version of Pommerman, developed for a competition at NeurIPS 2018. Our methodology involves training an agent initially through imitation learning on a noisy expert policy, followed by a proximal-policy optimization (PPO) reinforcement learning algorithm. The basic PPO approach is modified for stable transition", "provider": "mit", "domains": ["reinforcement_learning", "ai_governance", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["reward shaping"], "quality_score": 0.65, "discovered_at": "2026-02-09T15:00:32.866523Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The Pommerman simulation was recently developed to mimic the classic Japanese game Bomberman, and focuses on competitive gameplay in a multi-agent setting. We focus on the 2$\\times$2 team version of Pommerman, developed for a competition at NeurIPS 2018. Our methodology involves training an agent initially through imitation learning on a noisy expert policy, followed by a proximal-policy optimization (PPO) reinforcement learning algorithm. The basic PPO approach is modified for stable transition from the imitation learning phase through reward shaping, action filters based on heuristics, and curriculum learning. The proposed methodology is able to beat heuristic and pure reinforcement learning baselines with a combined 100,000 training games, significantly faster than other non-tree-search methods in literature. We present results against multiple agents provided by the developers of the simulation, including some that we have enhanced. We include a sensitivity analysis over different parameters, and highlight undesirable effects of some strategies that initially appear promising. Since Pommerman is a complex multi-agent competitive environment, the strategies developed here provide insights into several real-world problems with characteristics such as partial observability, decentralized execution (without communication), and very sparse and delayed rewards."}}, {"id": "690b3cffe6e544f0", "url": "https://github.com/microsoft/Web-Dev-For-Beginners", "title": "microsoft/Web-Dev-For-Beginners", "description": "24 Lessons, 12 Weeks, Get Started as a Web Developer", "provider": "microsoft", "domains": ["generative_ai", "reinforcement_learning"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.4, "prerequisites": [], "tags": ["prompt engineering", "RAG"], "quality_score": 0.642, "discovered_at": "2026-02-09T15:00:29.570043Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 95268, "language": "JavaScript", "topics": ["css", "curriculum", "education", "html", "javascript", "learning", "microsoft-for-beginners", "tutorials"], "updated_at": "2026-02-09T14:26:45Z"}}, {"id": "8c6a97dc3e6949c7", "url": "https://github.com/Developer-Y/cs-video-courses", "title": "Developer-Y/cs-video-courses", "description": "List of Computer Science courses with video lectures.", "provider": "github", "domains": ["ml_basics", "computer_vision"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 2.2, "prerequisites": [], "tags": ["unsupervised learning", "supervised learning"], "quality_score": 0.639, "discovered_at": "2026-02-09T15:00:29.249874Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 70698, "language": null, "topics": ["algorithms", "bioinformatics", "computational-biology", "computational-physics", "computer-architecture", "computer-science", "computer-vision", "database-systems", "databases", "deep-learning", "embedded-systems", "machine-learning", "quantum-computing", "reinforcement-learning", "robotics", "security", "systems", "web-development"], "updated_at": "2026-02-09T13:56:40Z"}}, {"id": "e5249df034ae0142", "url": "https://github.com/cloudcommunity/Free-Certifications", "title": "cloudcommunity/Free-Certifications", "description": "A curated list of free courses with certifications. Also available at https://free-certifications.com/", "provider": "github", "domains": [], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.5, "prerequisites": [], "tags": [], "quality_score": 0.634, "discovered_at": "2026-02-09T15:00:29.273540Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 50889, "language": null, "topics": ["awesome", "awesome-list", "awesome-lists", "certification", "certifications", "exams", "free", "free-certification", "free-certifications", "free-coupon", "free-coupons", "free-course", "free-courses", "free-learning", "free-voucher", "free-vouchers", "freebie", "freebies", "hacktoberfest", "learning"], "updated_at": "2026-02-09T14:56:44Z"}}, {"id": "a087a2cf73f5d623", "url": "https://github.com/trimstray/the-book-of-secret-knowledge", "title": "trimstray/the-book-of-secret-knowledge", "description": "A collection of inspiring lists, manuals, cheatsheets, blogs, hacks, one-liners, cli/web tools and more.", "provider": "github", "domains": [], "content_type": "book", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 3.4, "prerequisites": [], "tags": [], "quality_score": 0.62, "discovered_at": "2026-02-09T15:00:29.770197Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 205724, "language": null, "topics": ["awesome", "awesome-list", "bsd", "cheatsheets", "devops", "guidelines", "hacking", "hacks", "howtos", "linux", "lists", "manuals", "one-liners", "pentesters", "resources", "search-engines", "security", "security-researchers", "sysops"], "updated_at": "2026-02-09T14:49:54Z"}}, {"id": "1cb7d583728bdc7d", "url": "https://github.com/jwasham/coding-interview-university", "title": "jwasham/coding-interview-university", "description": "A complete computer science study plan to become a software engineer.", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 1.9, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:29.018018Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 336895, "language": null, "topics": ["algorithm", "algorithms", "coding-interview", "coding-interviews", "computer-science", "data-structures", "interview", "interview-prep", "interview-preparation", "programming-interviews", "software-engineering", "study-plan"], "updated_at": "2026-02-09T14:57:01Z"}}, {"id": "d7ec1836f9bcf15a", "url": "https://github.com/ossu/computer-science", "title": "ossu/computer-science", "description": "\ud83c\udf93 Path to a free self-taught education in Computer Science!", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.5, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:29.024632Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 201143, "language": "HTML", "topics": ["awesome-list", "computer-science", "courses", "curriculum"], "updated_at": "2026-02-09T14:55:08Z"}}, {"id": "7932f64c0fdba3a7", "url": "https://github.com/vinta/awesome-python", "title": "vinta/awesome-python", "description": "An opinionated list of awesome Python frameworks, libraries, software and resources.", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 1.2, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:29.648331Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 282114, "language": "Python", "topics": ["awesome", "collections", "python", "python-framework", "python-library", "python-resources"], "updated_at": "2026-02-09T14:53:25Z"}}, {"id": "3523df22bb0ae2ea", "url": "https://github.com/freeCodeCamp/freeCodeCamp", "title": "freeCodeCamp/freeCodeCamp", "description": "freeCodeCamp.org's open-source codebase and curriculum. Learn math, programming, and computer science for free.", "provider": "github", "domains": ["ai_governance"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.2, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:29.710467Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 436942, "language": "TypeScript", "topics": ["careers", "certification", "community", "curriculum", "d3", "education", "freecodecamp", "javascript", "learn-to-code", "math", "nodejs", "nonprofits", "programming", "react", "teachers"], "updated_at": "2026-02-09T14:51:43Z"}}, {"id": "aac597fc68a65138", "url": "https://github.com/sindresorhus/awesome", "title": "sindresorhus/awesome", "description": "\ud83d\ude0e Awesome lists about all kinds of interesting topics", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.9, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:29.744431Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 436248, "language": null, "topics": ["awesome", "awesome-list", "lists", "resources", "unicorns"], "updated_at": "2026-02-09T14:59:09Z"}}, {"id": "afac539bd2a8ee27", "url": "https://github.com/awesome-selfhosted/awesome-selfhosted", "title": "awesome-selfhosted/awesome-selfhosted", "description": "A list of Free Software network services and web applications which can be hosted on your own servers", "provider": "github", "domains": ["mlops", "ai_ethics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 5.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:30.051027Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 272392, "language": null, "topics": ["awesome", "awesome-list", "cloud", "free-software", "hosting", "privacy", "self-hosted", "selfhosted"], "updated_at": "2026-02-09T14:57:54Z"}}, {"id": "569ebe2079d7e701", "url": "http://arxiv.org/abs/2301.00942v1", "title": "Deep Learning and Computational Physics (Lecture Notes)", "description": "These notes were compiled as lecture notes for a course developed and taught at the University of the Southern California. They should be accessible to a typical engineering graduate student with a strong background in Applied Mathematics.\n  The main objective of these notes is to introduce a student who is familiar with concepts in linear algebra and partial differential equations to select topics in deep learning. These lecture notes exploit the strong connections between deep learning algorit", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:30.167375Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "These notes were compiled as lecture notes for a course developed and taught at the University of the Southern California. They should be accessible to a typical engineering graduate student with a strong background in Applied Mathematics.\n  The main objective of these notes is to introduce a student who is familiar with concepts in linear algebra and partial differential equations to select topics in deep learning. These lecture notes exploit the strong connections between deep learning algorithms and the more conventional techniques of computational physics to achieve two goals. First, they use concepts from computational physics to develop an understanding of deep learning algorithms. Not surprisingly, many concepts in deep learning can be connected to similar concepts in computational physics, and one can utilize this connection to better understand these algorithms. Second, several novel deep learning algorithms can be used to solve challenging problems in computational physics. Thus, they offer someone who is interested in modeling a physical phenomena with a complementary set of tools."}}, {"id": "f262a6859b0c48af", "url": "http://arxiv.org/abs/2409.05211v1", "title": "ICML Topological Deep Learning Challenge 2024: Beyond the Graph Domain", "description": "This paper describes the 2nd edition of the ICML Topological Deep Learning Challenge that was hosted within the ICML 2024 ELLIS Workshop on Geometry-grounded Representation Learning and Generative Modeling (GRaM). The challenge focused on the problem of representing data in different discrete topological domains in order to bridge the gap between Topological Deep Learning (TDL) and other types of structured datasets (e.g. point clouds, graphs). Specifically, participants were asked to design and", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:30.262005Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper describes the 2nd edition of the ICML Topological Deep Learning Challenge that was hosted within the ICML 2024 ELLIS Workshop on Geometry-grounded Representation Learning and Generative Modeling (GRaM). The challenge focused on the problem of representing data in different discrete topological domains in order to bridge the gap between Topological Deep Learning (TDL) and other types of structured datasets (e.g. point clouds, graphs). Specifically, participants were asked to design and implement topological liftings, i.e. mappings between different data structures and topological domains --like hypergraphs, or simplicial/cell/combinatorial complexes. The challenge received 52 submissions satisfying all the requirements. This paper introduces the main scope of the challenge, and summarizes the main results and findings."}}, {"id": "092c9a36970ba68c", "url": "http://arxiv.org/abs/2104.12422v2", "title": "Teaching NLP with Bracelets and Restaurant Menus: An Interactive Workshop for Italian Students", "description": "Although Natural Language Processing (NLP) is at the core of many tools young people use in their everyday life, high school curricula (in Italy) do not include any computational linguistics education. This lack of exposure makes the use of such tools less responsible than it could be and makes choosing computational linguistics as a university degree unlikely. To raise awareness, curiosity, and longer-term interest in young people, we have developed an interactive workshop designed to illustrat", "provider": "arxiv", "domains": ["nlp"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:30.882235Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Although Natural Language Processing (NLP) is at the core of many tools young people use in their everyday life, high school curricula (in Italy) do not include any computational linguistics education. This lack of exposure makes the use of such tools less responsible than it could be and makes choosing computational linguistics as a university degree unlikely. To raise awareness, curiosity, and longer-term interest in young people, we have developed an interactive workshop designed to illustrate the basic principles of NLP and computational linguistics to high school Italian students aged between 13 and 18 years. The workshop takes the form of a game in which participants play the role of machines needing to solve some of the most common problems a computer faces in understanding language: from voice recognition to Markov chains to syntactic parsing. Participants are guided through the workshop with the help of instructors, who present the activities and explain core concepts from computational linguistics. The workshop was presented at numerous outlets in Italy between 2019 and 2021, both face-to-face and online."}}, {"id": "7f2816dbe3c2d58d", "url": "http://arxiv.org/abs/1909.10225v1", "title": "WiCV 2019: The Sixth Women In Computer Vision Workshop", "description": "In this paper we present the Women in Computer Vision Workshop - WiCV 2019, organized in conjunction with CVPR 2019. This event is meant for increasing the visibility and inclusion of women researchers in the computer vision field. Computer vision and machine learning have made incredible progress over the past years, but the number of female researchers is still low both in academia and in industry. WiCV is organized especially for the following reason: to raise visibility of female researchers", "provider": "arxiv", "domains": ["computer_vision", "ml_basics", "nlp"], "content_type": "course", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:30.973752Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this paper we present the Women in Computer Vision Workshop - WiCV 2019, organized in conjunction with CVPR 2019. This event is meant for increasing the visibility and inclusion of women researchers in the computer vision field. Computer vision and machine learning have made incredible progress over the past years, but the number of female researchers is still low both in academia and in industry. WiCV is organized especially for the following reason: to raise visibility of female researchers, to increase collaborations between them, and to provide mentorship to female junior researchers in the field. In this paper, we present a report of trends over the past years, along with a summary of statistics regarding presenters, attendees, and sponsorship for the current workshop."}}, {"id": "295b779723b066a6", "url": "http://arxiv.org/abs/2311.14762v1", "title": "The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024", "description": "The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024 addresses maritime computer vision for Unmanned Aerial Vehicles (UAV) and Unmanned Surface Vehicles (USV). Three challenges categories are considered: (i) UAV-based Maritime Object Tracking with Re-identification, (ii) USV-based Maritime Obstacle Segmentation and Detection, (iii) USV-based Maritime Boat Tracking. The USV-based Maritime Obstacle Segmentation and Detection features three sub-challenges, including a new embedded challenge ad", "provider": "arxiv", "domains": ["computer_vision", "nlp"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:31.140275Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024 addresses maritime computer vision for Unmanned Aerial Vehicles (UAV) and Unmanned Surface Vehicles (USV). Three challenges categories are considered: (i) UAV-based Maritime Object Tracking with Re-identification, (ii) USV-based Maritime Obstacle Segmentation and Detection, (iii) USV-based Maritime Boat Tracking. The USV-based Maritime Obstacle Segmentation and Detection features three sub-challenges, including a new embedded challenge addressing efficicent inference on real-world embedded devices. This report offers a comprehensive overview of the findings from the challenges. We provide both statistical and qualitative analyses, evaluating trends from over 195 submissions. All datasets, evaluation code, and the leaderboard are available to the public at https://macvi.org/workshop/macvi24."}}, {"id": "c8bed4e399590cde", "url": "http://arxiv.org/abs/2507.02910v1", "title": "Causal-Paced Deep Reinforcement Learning", "description": "Designing effective task sequences is crucial for curriculum reinforcement learning (CRL), where agents must gradually acquire skills by training on intermediate tasks. A key challenge in CRL is to identify tasks that promote exploration, yet are similar enough to support effective transfer. While recent approach suggests comparing tasks via their Structural Causal Models (SCMs), the method requires access to ground-truth causal structures, an unrealistic assumption in most RL settings. In this ", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "course", "difficulty": "intermediate", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:32.650455Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Designing effective task sequences is crucial for curriculum reinforcement learning (CRL), where agents must gradually acquire skills by training on intermediate tasks. A key challenge in CRL is to identify tasks that promote exploration, yet are similar enough to support effective transfer. While recent approach suggests comparing tasks via their Structural Causal Models (SCMs), the method requires access to ground-truth causal structures, an unrealistic assumption in most RL settings. In this work, we propose Causal-Paced Deep Reinforcement Learning (CP-DRL), a curriculum learning framework aware of SCM differences between tasks based on interaction data approximation. This signal captures task novelty, which we combine with the agent's learnability, measured by reward gain, to form a unified objective. Empirically, CP-DRL outperforms existing curriculum methods on the Point Mass benchmark, achieving faster convergence and higher returns. CP-DRL demonstrates reduced variance with comparable final returns in the Bipedal Walker-Trivial setting, and achieves the highest average performance in the Infeasible variant. These results indicate that leveraging causal relationships between tasks can improve the structure-awareness and sample efficiency of curriculum reinforcement learning. We provide the full implementation of CP-DRL to facilitate the reproduction of our main results at https://github.com/Cho-Geonwoo/CP-DRL."}}, {"id": "88bc034971012871", "url": "http://arxiv.org/abs/2510.21203v1", "title": "The Nuclear Analogy in AI Governance Research", "description": "The analogy between Artificial Intelligence (AI) and nuclear weapons is prominent in academic and policy discourse on AI governance. This chapter reviews 43 scholarly works which explicitly draw on the nuclear domain to derive lessons for AI governance. We identify four problem areas where researchers apply nuclear precedents: (1) early development and governance of transformative technologies; (2) international security risks and strategy; (3) international institutions and agreements; and (4) ", "provider": "arxiv", "domains": ["ai_governance", "nlp"], "content_type": "course", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:34.294422Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The analogy between Artificial Intelligence (AI) and nuclear weapons is prominent in academic and policy discourse on AI governance. This chapter reviews 43 scholarly works which explicitly draw on the nuclear domain to derive lessons for AI governance. We identify four problem areas where researchers apply nuclear precedents: (1) early development and governance of transformative technologies; (2) international security risks and strategy; (3) international institutions and agreements; and (4) domestic safety regulation. While nuclear-inspired AI proposals are often criticised due to differences across domains, this review clarifies how historical analogies can inform policy development even when technological domains differ substantially. Valuable functions include providing conceptual frameworks for analyzing strategic dynamics, offering cautionary lessons about unsuccessful governance approaches, and expanding policy imagination by legitimizing radical proposals. Given that policymakers already invoke the nuclear analogy, continued critical engagement with these historical precedents remains essential for shaping effective global AI governance."}}, {"id": "3e6b3793c15d7217", "url": "http://arxiv.org/abs/2206.03270v1", "title": "DLT Compliance Reporting", "description": "The IS discourse on the potential of distributed ledger technology (DLT) in the financial services has grown at a tremendous pace in recent years. Yet, little has been said about the related implications for the costly and highly regulated process of compliance reporting. Working with a group of representatives from industry and regulatory authorities, we employ the design science research methodology (DSR) in the design, development, and evaluation of an artefact, enabling the automated collect", "provider": "arxiv", "domains": ["ai_governance", "nlp"], "content_type": "course", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:00:34.416678Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The IS discourse on the potential of distributed ledger technology (DLT) in the financial services has grown at a tremendous pace in recent years. Yet, little has been said about the related implications for the costly and highly regulated process of compliance reporting. Working with a group of representatives from industry and regulatory authorities, we employ the design science research methodology (DSR) in the design, development, and evaluation of an artefact, enabling the automated collection and enrichment of transactional data. Our findings indicate that DLT may facilitate the automation of key compliance processes through the implementation of a \"pull-model\", in which regulators can access compliance data in near real-time to stage aggregate exposures at the supranational level. Generalizing our preliminary results, we present four propositions on the implications of DLT in compliance. The findings contribute new practical insights on the topic of compliance to the growing IS discourse on DLT."}}, {"id": "580cb4e15b659404", "url": "http://arxiv.org/abs/2507.07765v1", "title": "Distributed and Decentralised Training: Technical Governance Challenges in a Shifting AI Landscape", "description": "Advances in low-communication training algorithms are enabling a shift from centralised model training to compute setups that are either distributed across multiple clusters or decentralised via community-driven contributions. This paper distinguishes these two scenarios - distributed and decentralised training - which are little understood and often conflated in policy discourse. We discuss how they could impact technical AI governance through an increased risk of compute structuring, capabilit", "provider": "arxiv", "domains": ["ai_governance", "nlp", "ai_ethics"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:18:54.504858Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Advances in low-communication training algorithms are enabling a shift from centralised model training to compute setups that are either distributed across multiple clusters or decentralised via community-driven contributions. This paper distinguishes these two scenarios - distributed and decentralised training - which are little understood and often conflated in policy discourse. We discuss how they could impact technical AI governance through an increased risk of compute structuring, capability proliferation, and the erosion of detectability and shutdownability. While these trends foreshadow a possible new paradigm that could challenge key assumptions of compute governance, we emphasise that certain policy levers, like export controls, remain relevant. We also acknowledge potential benefits of decentralised AI, including privacy-preserving training runs that could unlock access to more data, and mitigating harmful power concentration. Our goal is to support more precise policymaking around compute, capability proliferation, and decentralised AI development."}}, {"id": "f630ccf6a4cd840d", "url": "http://arxiv.org/abs/1310.0319v3", "title": "Second Croatian Computer Vision Workshop (CCVW 2013)", "description": "Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013, http://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb, Croatia. Workshop was organized by the Center of Excellence for Computer Vision of the University of Zagreb.", "provider": "arxiv", "domains": ["computer_vision", "nlp"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.6, "discovered_at": "2026-02-09T15:39:48.415322Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013, http://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb, Croatia. Workshop was organized by the Center of Excellence for Computer Vision of the University of Zagreb."}}, {"id": "7506107d43f04477", "url": "https://github.com/avelino/awesome-go", "title": "avelino/awesome-go", "description": "A curated list of awesome Go frameworks, libraries and software", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 6.0, "prerequisites": [], "tags": [], "quality_score": 0.599, "discovered_at": "2026-02-09T15:00:29.794710Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 164642, "language": "Go", "topics": ["awesome", "awesome-list", "go", "golang", "golang-library", "hacktoberfest"], "updated_at": "2026-02-09T14:57:34Z"}}, {"id": "7e18454411f4e997", "url": "https://github.com/ripienaar/free-for-dev", "title": "ripienaar/free-for-dev", "description": "A list of SaaS, PaaS and IaaS offerings that have free tiers of interest to devops and infradev", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 5.1, "prerequisites": [], "tags": [], "quality_score": 0.595, "discovered_at": "2026-02-09T15:00:29.844434Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 117848, "language": "HTML", "topics": ["awesome-list", "free-for-developers"], "updated_at": "2026-02-09T14:58:30Z"}}, {"id": "12de4860bfa96dd0", "url": "http://arxiv.org/abs/1904.07204v1", "title": "Tutorial: Safe and Reliable Machine Learning", "description": "This document serves as a brief overview of the \"Safe and Reliable Machine Learning\" tutorial given at the 2019 ACM Conference on Fairness, Accountability, and Transparency (FAT* 2019). The talk slides can be found here: https://bit.ly/2Gfsukp, while a video of the talk is available here: https://youtu.be/FGLOCkC4KmE, and a complete list of references for the tutorial here: https://bit.ly/2GdLPme.", "provider": "arxiv", "domains": ["ai_ethics", "ml_basics", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:29.384366Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This document serves as a brief overview of the \"Safe and Reliable Machine Learning\" tutorial given at the 2019 ACM Conference on Fairness, Accountability, and Transparency (FAT* 2019). The talk slides can be found here: https://bit.ly/2Gfsukp, while a video of the talk is available here: https://youtu.be/FGLOCkC4KmE, and a complete list of references for the tutorial here: https://bit.ly/2GdLPme."}}, {"id": "0beafe0a81307d77", "url": "http://arxiv.org/abs/2110.10780v3", "title": "An Open Natural Language Processing Development Framework for EHR-based Clinical Research: A case demonstration using the National COVID Cohort Collaborative (N3C)", "description": "While we pay attention to the latest advances in clinical natural language processing (NLP), we can notice some resistance in the clinical and translational research community to adopt NLP models due to limited transparency, interpretability, and usability. In this study, we proposed an open natural language processing development framework. We evaluated it through the implementation of NLP algorithms for the National COVID Cohort Collaborative (N3C). Based on the interests in information extrac", "provider": "arxiv", "domains": ["nlp", "ai_ethics", "ai_strategy"], "content_type": "interactive_notebook", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.2, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:30.603008Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "While we pay attention to the latest advances in clinical natural language processing (NLP), we can notice some resistance in the clinical and translational research community to adopt NLP models due to limited transparency, interpretability, and usability. In this study, we proposed an open natural language processing development framework. We evaluated it through the implementation of NLP algorithms for the National COVID Cohort Collaborative (N3C). Based on the interests in information extraction from COVID-19 related clinical notes, our work includes 1) an open data annotation process using COVID-19 signs and symptoms as the use case, 2) a community-driven ruleset composing platform, and 3) a synthetic text data generation workflow to generate texts for information extraction tasks without involving human subjects. The corpora were derived from texts from three different institutions (Mayo Clinic, University of Kentucky, University of Minnesota). The gold standard annotations were tested with a single institution's (Mayo) ruleset. This resulted in performances of 0.876, 0.706, and 0.694 in F-scores for Mayo, Minnesota, and Kentucky test datasets, respectively. The study as a consortium effort of the N3C NLP subgroup demonstrates the feasibility of creating a federated NLP algorithm development and benchmarking platform to enhance multi-institution clinical NLP study and adoption. Although we use COVID-19 as a use case in this effort, our framework is general enough to be applied to other domains of interest in clinical NLP."}}, {"id": "8b8f8903342a15b2", "url": "http://arxiv.org/abs/2408.13040v1", "title": "SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks", "description": "Prompting has become a practical method for utilizing pre-trained language models (LMs). This approach offers several advantages. It allows an LM to adapt to new tasks with minimal training and parameter updates, thus achieving efficiency in both storage and computation. Additionally, prompting modifies only the LM's inputs and harnesses the generative capabilities of language models to address various downstream tasks in a unified manner. This significantly reduces the need for human labor in d", "provider": "arxiv", "domains": ["nlp", "ml_basics"], "content_type": "interactive_notebook", "difficulty": "intermediate", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:30.790766Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Prompting has become a practical method for utilizing pre-trained language models (LMs). This approach offers several advantages. It allows an LM to adapt to new tasks with minimal training and parameter updates, thus achieving efficiency in both storage and computation. Additionally, prompting modifies only the LM's inputs and harnesses the generative capabilities of language models to address various downstream tasks in a unified manner. This significantly reduces the need for human labor in designing task-specific models. These advantages become even more evident as the number of tasks served by the LM scales up. Motivated by the strengths of prompting, we are the first to explore the potential of prompting speech LMs in the domain of speech processing. Recently, there has been a growing interest in converting speech into discrete units for language modeling. Our pioneer research demonstrates that these quantized speech units are highly versatile within our unified prompting framework. Not only can they serve as class labels, but they also contain rich phonetic information that can be re-synthesized back into speech signals for speech generation tasks. Specifically, we reformulate speech processing tasks into speech-to-unit generation tasks. As a result, we can seamlessly integrate tasks such as speech classification, sequence generation, and speech generation within a single, unified prompting framework. The experiment results show that the prompting method can achieve competitive performance compared to the strong fine-tuning method based on self-supervised learning models with a similar number of trainable parameters. The prompting method also shows promising results in the few-shot setting. Moreover, with the advanced speech LMs coming into the stage, the proposed prompting framework attains great potential."}}, {"id": "89227f71807541bd", "url": "http://arxiv.org/abs/2204.05042v3", "title": "Resources for Turkish Natural Language Processing: A critical survey", "description": "This paper presents a comprehensive survey of corpora and lexical resources available for Turkish. We review a broad range of resources, focusing on the ones that are publicly available. In addition to providing information about the available linguistic resources, we present a set of recommendations, and identify gaps in the data available for conducting research and building applications in Turkish Linguistics and Natural Language Processing.", "provider": "arxiv", "domains": ["nlp"], "content_type": "interactive_notebook", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:30.822945Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper presents a comprehensive survey of corpora and lexical resources available for Turkish. We review a broad range of resources, focusing on the ones that are publicly available. In addition to providing information about the available linguistic resources, we present a set of recommendations, and identify gaps in the data available for conducting research and building applications in Turkish Linguistics and Natural Language Processing."}}, {"id": "f412a0532b24e917", "url": "http://arxiv.org/abs/2104.12405v2", "title": "A dissemination workshop for introducing young Italian students to NLP", "description": "We describe and make available the game-based material developed for a laboratory run at several Italian science festivals to popularize NLP among young students.", "provider": "arxiv", "domains": ["nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:30.854353Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We describe and make available the game-based material developed for a laboratory run at several Italian science festivals to popularize NLP among young students."}}, {"id": "c01da586be378d1e", "url": "http://arxiv.org/abs/1808.00262v3", "title": "Saliency for Fine-grained Object Recognition in Domains with Scarce Training Data", "description": "This paper investigates the role of saliency to improve the classification accuracy of a Convolutional Neural Network (CNN) for the case when scarce training data is available. Our approach consists in adding a saliency branch to an existing CNN architecture which is used to modulate the standard bottom-up visual features from the original image input, acting as an attentional mechanism that guides the feature extraction process. The main aim of the proposed approach is to enable the effective t", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "computer_vision"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:31.469618Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper investigates the role of saliency to improve the classification accuracy of a Convolutional Neural Network (CNN) for the case when scarce training data is available. Our approach consists in adding a saliency branch to an existing CNN architecture which is used to modulate the standard bottom-up visual features from the original image input, acting as an attentional mechanism that guides the feature extraction process. The main aim of the proposed approach is to enable the effective training of a fine-grained recognition model with limited training samples and to improve the performance on the task, thereby alleviating the need to annotate large dataset. % The vast majority of saliency methods are evaluated on their ability to generate saliency maps, and not on their functionality in a complete vision pipeline. Our proposed pipeline allows to evaluate saliency methods for the high-level task of object recognition. We perform extensive experiments on various fine-grained datasets (Flowers, Birds, Cars, and Dogs) under different conditions and show that saliency can considerably improve the network's performance, especially for the case of scarce training data. Furthermore, our experiments show that saliency methods that obtain improved saliency maps (as measured by traditional saliency benchmarks) also translate to saliency methods that yield improved performance gains when applied in an object recognition pipeline."}}, {"id": "324779ac4f4351ff", "url": "http://arxiv.org/abs/2510.21391v1", "title": "TerraGen: A Unified Multi-Task Layout Generation Framework for Remote Sensing Data Augmentation", "description": "Remote sensing vision tasks require extensive labeled data across multiple, interconnected domains. However, current generative data augmentation frameworks are task-isolated, i.e., each vision task requires training an independent generative model, and ignores the modeling of geographical information and spatial constraints. To address these issues, we propose \\textbf{TerraGen}, a unified layout-to-image generation framework that enables flexible, spatially controllable synthesis of remote sens", "provider": "arxiv", "domains": ["computer_vision", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:33.197687Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Remote sensing vision tasks require extensive labeled data across multiple, interconnected domains. However, current generative data augmentation frameworks are task-isolated, i.e., each vision task requires training an independent generative model, and ignores the modeling of geographical information and spatial constraints. To address these issues, we propose \\textbf{TerraGen}, a unified layout-to-image generation framework that enables flexible, spatially controllable synthesis of remote sensing imagery for various high-level vision tasks, e.g., detection, segmentation, and extraction. Specifically, TerraGen introduces a geographic-spatial layout encoder that unifies bounding box and segmentation mask inputs, combined with a multi-scale injection scheme and mask-weighted loss to explicitly encode spatial constraints, from global structures to fine details. Also, we construct the first large-scale multi-task remote sensing layout generation dataset containing 45k images and establish a standardized evaluation protocol for this task. Experimental results show that our TerraGen can achieve the best generation image quality across diverse tasks. Additionally, TerraGen can be used as a universal data-augmentation generator, enhancing downstream task performance significantly and demonstrating robust cross-task generalisation in both full-data and few-shot scenarios."}}, {"id": "262d055285c37413", "url": "http://arxiv.org/abs/2411.15497v3", "title": "AeroGen: Enhancing Remote Sensing Object Detection with Diffusion-Driven Data Generation", "description": "Remote sensing image object detection (RSIOD) aims to identify and locate specific objects within satellite or aerial imagery. However, there is a scarcity of labeled data in current RSIOD datasets, which significantly limits the performance of current detection algorithms. Although existing techniques, e.g., data augmentation and semi-supervised learning, can mitigate this scarcity issue to some extent, they are heavily dependent on high-quality labeled data and perform worse in rare object cla", "provider": "arxiv", "domains": ["computer_vision", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["object detection"], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:33.236521Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Remote sensing image object detection (RSIOD) aims to identify and locate specific objects within satellite or aerial imagery. However, there is a scarcity of labeled data in current RSIOD datasets, which significantly limits the performance of current detection algorithms. Although existing techniques, e.g., data augmentation and semi-supervised learning, can mitigate this scarcity issue to some extent, they are heavily dependent on high-quality labeled data and perform worse in rare object classes. To address this issue, this paper proposes a layout-controllable diffusion generative model (i.e. AeroGen) tailored for RSIOD. To our knowledge, AeroGen is the first model to simultaneously support horizontal and rotated bounding box condition generation, thus enabling the generation of high-quality synthetic images that meet specific layout and object category requirements. Additionally, we propose an end-to-end data augmentation framework that integrates a diversity-conditioned generator and a filtering mechanism to enhance both the diversity and quality of generated data. Experimental results demonstrate that the synthetic data produced by our method are of high quality and diversity. Furthermore, the synthetic RSIOD data can significantly improve the detection performance of existing RSIOD models, i.e., the mAP metrics on DIOR, DIOR-R, and HRSC datasets are improved by 3.7%, 4.3%, and 2.43%, respectively. The code is available at https://github.com/Sonettoo/AeroGen."}}, {"id": "385cb48c0a1c68b2", "url": "http://arxiv.org/abs/2412.06830v1", "title": "A New Strategy for the Exploration of Venus", "description": "The 2023-2032 Planetary Science and Astrobiology Decadal Survey Origins, Worlds, and Life recommended that \"NASA develop scientific exploration strategies, as it has for Mars, in areas of broad scientific importance, e.g., Venus... that have an increasing number of U.S. missions and international collaboration opportunities\" (OWL, p.22-10). In NASA's initial responses to that Decadal Survey, the agency asserted that \"...specific scientific exploration strategies should be community generated by ", "provider": "arxiv", "domains": ["reinforcement_learning", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:33.274182Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The 2023-2032 Planetary Science and Astrobiology Decadal Survey Origins, Worlds, and Life recommended that \"NASA develop scientific exploration strategies, as it has for Mars, in areas of broad scientific importance, e.g., Venus... that have an increasing number of U.S. missions and international collaboration opportunities\" (OWL, p.22-10). In NASA's initial responses to that Decadal Survey, the agency asserted that \"...specific scientific exploration strategies should be community generated by bodies such as the Analysis Groups,\" thus placing the onus on the planetary community to generate and support these exploration strategies. In late 2022, the Venus Exploration Analysis Group began a project to develop a new exploration strategy for Venus, reflecting the 2021 selections of the VERITAS, DAVINCI, and EnVision missions and the sweeping comparative planetology recommendations relevant to Venus in Origins, Worlds, and Life.\n  This is that strategy.\n  Taking a broad look at the scientific, technological, and programmatic advances required to address the key outstanding questions that Venus poses, and predicated on VERITAS, DAVINCI, and EnVision flying as planned in the early 2030s, this report outlines a set of actions available to NASA, VEXAG, and the planetary science community at large to establish a sustained program of Venus exploration in the years and decades ahead. Key to this approach is recognizing Venus as a unique setting where multiple, cross-disciplinary, Decadal-level planetary, Earth, heliophysics, and exoplanet science questions can be addressed, as well as being a worthy target of exploration in its own right.\n  This report offers Assessments of the current state of Venus exploration, and Actions for the U.S. and international Venus community, as well as NASA, to consider. This strategy is a living document and should be updated as warranted."}}, {"id": "e5454532b4e07c26", "url": "http://arxiv.org/abs/2012.02454v1", "title": "Data Lakes for Digital Humanities", "description": "Traditional data in Digital Humanities projects bear various formats (structured, semi-structured, textual) and need substantial transformations (encoding and tagging, stemming, lemmatization, etc.) to be managed and analyzed. To fully master this process, we propose the use of data lakes as a solution to data siloing and big data variety problems. We describe data lake projects we currently run in close collaboration with researchers in humanities and social sciences and discuss the lessons lea", "provider": "arxiv", "domains": ["data_engineering", "nlp"], "content_type": "interactive_notebook", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:00:33.554411Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Traditional data in Digital Humanities projects bear various formats (structured, semi-structured, textual) and need substantial transformations (encoding and tagging, stemming, lemmatization, etc.) to be managed and analyzed. To fully master this process, we propose the use of data lakes as a solution to data siloing and big data variety problems. We describe data lake projects we currently run in close collaboration with researchers in humanities and social sciences and discuss the lessons learned running these projects."}}, {"id": "99c08bfd6b91076e", "url": "http://arxiv.org/abs/2406.19847v1", "title": "An Analysis of MLOps Architectures: A Systematic Mapping Study", "description": "Context. Despite the increasing adoption of Machine Learning Operations (MLOps), teams still encounter challenges in effectively applying this paradigm to their specific projects. While there is a large variety of available tools usable for MLOps, there is simultaneously a lack of consolidated architecture knowledge that can inform the architecture design. Objective. Our primary objective is to provide a comprehensive overview of (i) how MLOps architectures are defined across the literature and ", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:18:49.272091Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Context. Despite the increasing adoption of Machine Learning Operations (MLOps), teams still encounter challenges in effectively applying this paradigm to their specific projects. While there is a large variety of available tools usable for MLOps, there is simultaneously a lack of consolidated architecture knowledge that can inform the architecture design. Objective. Our primary objective is to provide a comprehensive overview of (i) how MLOps architectures are defined across the literature and (ii) which tools are mentioned to support the implementation of each architecture component. Method. We apply the Systematic Mapping Study method and select 43 primary studies via automatic, manual, and snowballing-based search and selection procedures. Subsequently, we use card sorting to synthesize the results. Results. We contribute (i) a categorization of 35 MLOps architecture components, (ii) a description of several MLOps architecture variants, and (iii) a systematic map between the identified components and the existing MLOps tools. Conclusion. This study provides an overview of the state of the art in MLOps from an architectural perspective. Researchers and practitioners can use our findings to inform the architecture design of their MLOps systems."}}, {"id": "4cfc109e8a9b5a2f", "url": "http://arxiv.org/abs/2501.12826v1", "title": "Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek", "description": "Natural Language Processing (NLP) for lesser-resourced languages faces persistent challenges, including limited datasets, inherited biases from high-resource languages, and the need for domain-specific solutions. This study addresses these gaps for Modern Greek through three key contributions. First, we evaluate the performance of open-source (Llama-70b) and closed-source (GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset availability, revealing task-specific strengt", "provider": "arxiv", "domains": ["nlp", "generative_ai", "ml_basics"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.59, "discovered_at": "2026-02-09T15:39:47.630213Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Natural Language Processing (NLP) for lesser-resourced languages faces persistent challenges, including limited datasets, inherited biases from high-resource languages, and the need for domain-specific solutions. This study addresses these gaps for Modern Greek through three key contributions. First, we evaluate the performance of open-source (Llama-70b) and closed-source (GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset availability, revealing task-specific strengths, weaknesses, and parity in their performance. Second, we expand the scope of Greek NLP by reframing Authorship Attribution as a tool to assess potential data usage by LLMs in pre-training, with high 0-shot accuracy suggesting ethical implications for data provenance. Third, we showcase a legal NLP case study, where a Summarize, Translate, and Embed (STE) methodology outperforms the traditional TF-IDF approach for clustering \\emph{long} legal texts. Together, these contributions provide a roadmap to advance NLP in lesser-resourced languages, bridging gaps in model evaluation, task innovation, and real-world impact."}}, {"id": "0b936146360e893f", "url": "http://arxiv.org/abs/2412.08520v1", "title": "GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek", "description": "We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP) toolkit developed specifically for modern Greek. The toolkit provides state-of-the-art performance in five core NLP tasks, namely part-of-speech tagging, morphological tagging, dependency parsing, named entity recognition, and Greeklishto-Greek transliteration. The toolkit is based on pre-trained Transformers, it is freely available, and can be easily installed in Python (pip install gr-nlp-toolkit). It is also accessibl", "provider": "arxiv", "domains": ["nlp"], "content_type": "interactive_notebook", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["named entity recognition"], "quality_score": 0.59, "discovered_at": "2026-02-09T15:39:47.801202Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP) toolkit developed specifically for modern Greek. The toolkit provides state-of-the-art performance in five core NLP tasks, namely part-of-speech tagging, morphological tagging, dependency parsing, named entity recognition, and Greeklishto-Greek transliteration. The toolkit is based on pre-trained Transformers, it is freely available, and can be easily installed in Python (pip install gr-nlp-toolkit). It is also accessible through a demonstration platform on HuggingFace, along with a publicly available API for non-commercial use. We discuss the functionality provided for each task, the underlying methods, experiments against comparable open-source toolkits, and future possible enhancements. The toolkit is available at: https://github.com/nlpaueb/gr-nlp-toolkit"}}, {"id": "77abc58804469141", "url": "http://arxiv.org/abs/2110.14711v3", "title": "A Survey of Self-Supervised and Few-Shot Object Detection", "description": "Labeling data is often expensive and time-consuming, especially for tasks such as object detection and instance segmentation, which require dense labeling of the image. While few-shot object detection is about training a model on novel (unseen) object classes with little data, it still requires prior training on many labeled examples of base (seen) classes. On the other hand, self-supervised methods aim at learning representations from unlabeled data which transfer well to downstream tasks such ", "provider": "arxiv", "domains": ["computer_vision", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["object detection"], "quality_score": 0.59, "discovered_at": "2026-02-09T15:39:50.045272Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Labeling data is often expensive and time-consuming, especially for tasks such as object detection and instance segmentation, which require dense labeling of the image. While few-shot object detection is about training a model on novel (unseen) object classes with little data, it still requires prior training on many labeled examples of base (seen) classes. On the other hand, self-supervised methods aim at learning representations from unlabeled data which transfer well to downstream tasks such as object detection. Combining few-shot and self-supervised object detection is a promising research direction. In this survey, we review and characterize the most recent approaches on few-shot and self-supervised object detection. Then, we give our main takeaways and discuss future research directions. Project page at https://gabrielhuang.github.io/fsod-survey/"}}, {"id": "914d659219e96fb2", "url": "https://github.com/vuejs/awesome-vue", "title": "vuejs/awesome-vue", "description": "\ud83c\udf89 A curated list of awesome things related to Vue.js", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 2.3, "prerequisites": [], "tags": [], "quality_score": 0.589, "discovered_at": "2026-02-09T15:00:29.089660Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 73642, "language": null, "topics": [], "updated_at": "2026-02-09T12:20:25Z"}}, {"id": "5765168ebb93e8ba", "url": "https://github.com/fffaraz/awesome-cpp", "title": "fffaraz/awesome-cpp", "description": "A curated list of awesome C++ (or C) frameworks, libraries, resources, and shiny things. Inspired by awesome-... stuff.", "provider": "github", "domains": ["deep_learning", "ml_basics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 2.9, "prerequisites": [], "tags": ["neural networks"], "quality_score": 0.588, "discovered_at": "2026-02-09T15:00:29.516081Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 69624, "language": null, "topics": ["awesome", "awesome-list", "c", "c-plus-plus", "cpp", "cpp-library", "cppcon", "libraries", "list", "lists", "programming-tutorial", "resources"], "updated_at": "2026-02-09T14:36:38Z"}}, {"id": "b3ce7b5fceb9c593", "url": "https://github.com/GitHubDaily/GitHubDaily", "title": "GitHubDaily/GitHubDaily", "description": "\u575a\u6301\u5206\u4eab GitHub \u4e0a\u9ad8\u8d28\u91cf\u3001\u6709\u8da3\u5b9e\u7528\u7684\u5f00\u6e90\u6280\u672f\u6559\u7a0b\u3001\u5f00\u53d1\u8005\u5de5\u5177\u3001\u7f16\u7a0b\u7f51\u7ad9\u3001\u6280\u672f\u8d44\u8baf\u3002A list cool, interesting projects of GitHub.", "provider": "github", "domains": ["generative_ai", "reinforcement_learning", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.9, "prerequisites": [], "tags": ["RAG"], "quality_score": 0.583, "discovered_at": "2026-02-09T15:00:29.297406Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 45118, "language": null, "topics": ["ai", "algorithms-and-data-structures", "backend", "developer-tools", "development", "frontend", "github", "java", "javascript", "kubernetes", "linux", "markdown", "open-source", "python", "tutorials", "web"], "updated_at": "2026-02-09T14:16:43Z"}}, {"id": "b512ede17bcf8fe2", "url": "http://arxiv.org/abs/2107.09957v2", "title": "Memorization in Deep Neural Networks: Does the Loss Function matter?", "description": "Deep Neural Networks, often owing to the overparameterization, are shown to be capable of exactly memorizing even randomly labelled data. Empirical studies have also shown that none of the standard regularization techniques mitigate such overfitting. We investigate whether the choice of the loss function can affect this memorization. We empirically show, with benchmark data sets MNIST and CIFAR-10, that a symmetric loss function, as opposed to either cross-entropy or squared error loss, results ", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.575, "discovered_at": "2026-02-09T15:00:30.338826Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep Neural Networks, often owing to the overparameterization, are shown to be capable of exactly memorizing even randomly labelled data. Empirical studies have also shown that none of the standard regularization techniques mitigate such overfitting. We investigate whether the choice of the loss function can affect this memorization. We empirically show, with benchmark data sets MNIST and CIFAR-10, that a symmetric loss function, as opposed to either cross-entropy or squared error loss, results in significant improvement in the ability of the network to resist such overfitting. We then provide a formal definition for robustness to memorization and provide a theoretical explanation as to why the symmetric losses provide this robustness. Our results clearly bring out the role loss functions alone can play in this phenomenon of memorization."}}, {"id": "23f4a5d4daecec85", "url": "http://arxiv.org/abs/2210.17484v1", "title": "The Open MatSci ML Toolkit: A Flexible Framework for Machine Learning in Materials Science", "description": "We present the Open MatSci ML Toolkit: a flexible, self-contained, and scalable Python-based framework to apply deep learning models and methods on scientific data with a specific focus on materials science and the OpenCatalyst Dataset. Our toolkit provides: 1. A scalable machine learning workflow for materials science leveraging PyTorch Lightning, which enables seamless scaling across different computation capabilities (laptop, server, cluster) and hardware platforms (CPU, GPU, XPU). 2. Deep Gr", "provider": "arxiv", "domains": ["ml_basics", "deep_learning", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.573, "discovered_at": "2026-02-09T15:00:29.545505Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We present the Open MatSci ML Toolkit: a flexible, self-contained, and scalable Python-based framework to apply deep learning models and methods on scientific data with a specific focus on materials science and the OpenCatalyst Dataset. Our toolkit provides: 1. A scalable machine learning workflow for materials science leveraging PyTorch Lightning, which enables seamless scaling across different computation capabilities (laptop, server, cluster) and hardware platforms (CPU, GPU, XPU). 2. Deep Graph Library (DGL) support for rapid graph neural network prototyping and development. By publishing and sharing this toolkit with the research community via open-source release, we hope to: 1. Lower the entry barrier for new machine learning researchers and practitioners that want to get started with the OpenCatalyst dataset, which presently comprises the largest computational materials science dataset. 2. Enable the scientific community to apply advanced machine learning tools to high-impact scientific challenges, such as modeling of materials behavior for clean energy applications. We demonstrate the capabilities of our framework by enabling three new equivariant neural network models for multiple OpenCatalyst tasks and arrive at promising results for compute scaling and model performance."}}, {"id": "329bc46ce7a1bbd7", "url": "http://arxiv.org/abs/2304.12244v3", "title": "WizardLM: Empowering large pre-trained language models to follow complex instructions", "description": "Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rew", "provider": "arxiv", "domains": ["nlp", "generative_ai"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.573, "discovered_at": "2026-02-09T15:00:32.578481Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation, WizardLM achieves more than 90\\% capacity of ChatGPT on 17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing LLMs. Our code and data are public at https://github.com/nlpxucan/WizardLM"}}, {"id": "511a5089717fad8a", "url": "https://github.com/yt-dlp/yt-dlp", "title": "yt-dlp/yt-dlp", "description": "A feature-rich command-line audio/video downloader", "provider": "github", "domains": [], "content_type": "video_series", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 3.3, "prerequisites": [], "tags": [], "quality_score": 0.558, "discovered_at": "2026-02-09T15:00:29.817829Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 146444, "language": "Python", "topics": ["cli", "downloader", "python", "sponsorblock", "youtube-dl", "youtube-downloader", "yt-dlp"], "updated_at": "2026-02-09T14:59:15Z"}}, {"id": "f41ca49032766a2c", "url": "http://arxiv.org/abs/2006.16189v4", "title": "DOME: Recommendations for supervised machine learning validation in biology", "description": "Modern biology frequently relies on machine learning to provide predictions and improve decision processes. There have been recent calls for more scrutiny on machine learning performance and possible limitations. Here we present a set of community-wide recommendations aiming to help establish standards of supervised machine learning validation in biology. Adopting a structured methods description for machine learning based on data, optimization, model, evaluation (DOME) will aim to help both rev", "provider": "arxiv", "domains": ["ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:29.143511Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Modern biology frequently relies on machine learning to provide predictions and improve decision processes. There have been recent calls for more scrutiny on machine learning performance and possible limitations. Here we present a set of community-wide recommendations aiming to help establish standards of supervised machine learning validation in biology. Adopting a structured methods description for machine learning based on data, optimization, model, evaluation (DOME) will aim to help both reviewers and readers to better understand and assess the performance and limitations of a method or outcome. The recommendations are formulated as questions to anyone wishing to pursue implementation of a machine learning algorithm. Answers to these questions can be easily included in the supplementary material of published papers."}}, {"id": "4919f6a8cb375813", "url": "http://arxiv.org/abs/2201.12150v2", "title": "Learning Curves for Decision Making in Supervised Machine Learning: A Survey", "description": "Learning curves are a concept from social sciences that has been adopted in the context of machine learning to assess the performance of a learning algorithm with respect to a certain resource, e.g., the number of training examples or the number of training iterations. Learning curves have important applications in several machine learning contexts, most notably in data acquisition, early stopping of model training, and model selection. For instance, learning curves can be used to model the perf", "provider": "arxiv", "domains": ["ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:29.172122Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Learning curves are a concept from social sciences that has been adopted in the context of machine learning to assess the performance of a learning algorithm with respect to a certain resource, e.g., the number of training examples or the number of training iterations. Learning curves have important applications in several machine learning contexts, most notably in data acquisition, early stopping of model training, and model selection. For instance, learning curves can be used to model the performance of the combination of an algorithm and its hyperparameter configuration, providing insights into their potential suitability at an early stage and often expediting the algorithm selection process. Various learning curve models have been proposed to use learning curves for decision making. Some of these models answer the binary decision question of whether a given algorithm at a certain budget will outperform a certain reference performance, whereas more complex models predict the entire learning curve of an algorithm. We contribute a framework that categorises learning curve approaches using three criteria: the decision-making situation they address, the intrinsic learning curve question they answer and the type of resources they use. We survey papers from the literature and classify them into this framework."}}, {"id": "c312d42c5d01cbd3", "url": "http://arxiv.org/abs/2303.15563v1", "title": "Privacy-preserving machine learning for healthcare: open challenges and future perspectives", "description": "Machine Learning (ML) has recently shown tremendous success in modeling various healthcare prediction tasks, ranging from disease diagnosis and prognosis to patient treatment. Due to the sensitive nature of medical data, privacy must be considered along the entire ML pipeline, from model training to inference. In this paper, we conduct a review of recent literature concerning Privacy-Preserving Machine Learning (PPML) for healthcare. We primarily focus on privacy-preserving training and inferenc", "provider": "arxiv", "domains": ["ai_ethics", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:29.224369Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Machine Learning (ML) has recently shown tremendous success in modeling various healthcare prediction tasks, ranging from disease diagnosis and prognosis to patient treatment. Due to the sensitive nature of medical data, privacy must be considered along the entire ML pipeline, from model training to inference. In this paper, we conduct a review of recent literature concerning Privacy-Preserving Machine Learning (PPML) for healthcare. We primarily focus on privacy-preserving training and inference-as-a-service, and perform a comprehensive review of existing trends, identify challenges, and discuss opportunities for future research directions. The aim of this review is to guide the development of private and efficient ML models in healthcare, with the prospects of translating research efforts into real-world settings."}}, {"id": "56e365ded63b97b1", "url": "http://arxiv.org/abs/2404.12511v1", "title": "Generalizing Machine Learning Evaluation through the Integration of Shannon Entropy and Rough Set Theory", "description": "This research paper delves into the innovative integration of Shannon entropy and rough set theory, presenting a novel approach to generalize the evaluation approach in machine learning. The conventional application of entropy, primarily focused on information uncertainty, is extended through its combination with rough set theory to offer a deeper insight into data's intrinsic structure and the interpretability of machine learning models. We introduce a comprehensive framework that synergizes th", "provider": "arxiv", "domains": ["ml_basics", "ai_ethics", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:29.413083Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This research paper delves into the innovative integration of Shannon entropy and rough set theory, presenting a novel approach to generalize the evaluation approach in machine learning. The conventional application of entropy, primarily focused on information uncertainty, is extended through its combination with rough set theory to offer a deeper insight into data's intrinsic structure and the interpretability of machine learning models. We introduce a comprehensive framework that synergizes the granularity of rough set theory with the uncertainty quantification of Shannon entropy, applied across a spectrum of machine learning algorithms. Our methodology is rigorously tested on various datasets, showcasing its capability to not only assess predictive performance but also to illuminate the underlying data complexity and model robustness. The results underscore the utility of this integrated approach in enhancing the evaluation landscape of machine learning, offering a multi-faceted perspective that balances accuracy with a profound understanding of data attributes and model dynamics. This paper contributes a groundbreaking perspective to machine learning evaluation, proposing a method that encapsulates a holistic view of model performance, thereby facilitating more informed decision-making in model selection and application."}}, {"id": "e5b36f5a8f482548", "url": "http://arxiv.org/abs/1905.04749v2", "title": "A Benchmark Study of Machine Learning Models for Online Fake News Detection", "description": "The proliferation of fake news and its propagation on social media has become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been suggested to detect fake news. However, most of those focused on a specific type of news (such as political) which leads us to the question of dataset-bias of the models used. In this research, we conducted a benchmark study to assess the performance of different applicable machine learning approaches on th", "provider": "arxiv", "domains": ["ml_basics", "ai_ethics", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:29.682230Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The proliferation of fake news and its propagation on social media has become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been suggested to detect fake news. However, most of those focused on a specific type of news (such as political) which leads us to the question of dataset-bias of the models used. In this research, we conducted a benchmark study to assess the performance of different applicable machine learning approaches on three different datasets where we accumulated the largest and most diversified one. We explored a number of advanced pre-trained language models for fake news detection along with the traditional and deep learning ones and compared their performances from different aspects for the first time to the best of our knowledge. We find that BERT and similar pre-trained models perform the best for fake news detection, especially with very small dataset. Hence, these models are significantly better option for languages with limited electronic contents, i.e., training data. We also carried out several analysis based on the models' performance, article's topic, article's length, and discussed different lessons learned from them. We believe that this benchmark study will help the research community to explore further and news sites/blogs to select the most appropriate fake news detection method."}}, {"id": "dfaec7de21108086", "url": "http://arxiv.org/abs/2306.11113v2", "title": "Learn to Accumulate Evidence from All Training Samples: Theory and Practice", "description": "Evidential deep learning, built upon belief theory and subjective logic, offers a principled and computationally efficient way to turn a deterministic neural network uncertainty-aware. The resultant evidential models can quantify fine-grained uncertainty using the learned evidence. To ensure theoretically sound evidential models, the evidence needs to be non-negative, which requires special activation functions for model training and inference. This constraint often leads to inferior predictive ", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:30.078397Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Evidential deep learning, built upon belief theory and subjective logic, offers a principled and computationally efficient way to turn a deterministic neural network uncertainty-aware. The resultant evidential models can quantify fine-grained uncertainty using the learned evidence. To ensure theoretically sound evidential models, the evidence needs to be non-negative, which requires special activation functions for model training and inference. This constraint often leads to inferior predictive performance compared to standard softmax models, making it challenging to extend them to many large-scale datasets. To unveil the real cause of this undesired behavior, we theoretically investigate evidential models and identify a fundamental limitation that explains the inferior performance: existing evidential activation functions create zero evidence regions, which prevent the model to learn from training samples falling into such regions. A deeper analysis of evidential activation functions based on our theoretical underpinning inspires the design of a novel regularizer that effectively alleviates this fundamental limitation. Extensive experiments over many challenging real-world datasets and settings confirm our theoretical findings and demonstrate the effectiveness of our proposed approach."}}, {"id": "113d0c60ac980f89", "url": "http://arxiv.org/abs/2105.04026v2", "title": "The Modern Mathematics of Deep Learning", "description": "We describe the new field of mathematical analysis of deep learning. This field emerged around a list of research questions that were not answered within the classical framework of learning theory. These questions concern: the outstanding generalization power of overparametrized neural networks, the role of depth in deep architectures, the apparent absence of the curse of dimensionality, the surprisingly successful optimization performance despite the non-convexity of the problem, understanding ", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["neural networks"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:30.105411Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We describe the new field of mathematical analysis of deep learning. This field emerged around a list of research questions that were not answered within the classical framework of learning theory. These questions concern: the outstanding generalization power of overparametrized neural networks, the role of depth in deep architectures, the apparent absence of the curse of dimensionality, the surprisingly successful optimization performance despite the non-convexity of the problem, understanding what features are learned, why deep architectures perform exceptionally well in physical problems, and which fine aspects of an architecture affect the behavior of a learning task in which way. We present an overview of modern approaches that yield partial answers to these questions. For selected approaches, we describe the main ideas in more detail."}}, {"id": "885cdff08a2ec511", "url": "http://arxiv.org/abs/1903.03040v2", "title": "Deep learning observables in computational fluid dynamics", "description": "Many large scale problems in computational fluid dynamics such as uncertainty quantification, Bayesian inversion, data assimilation and PDE constrained optimization are considered very challenging computationally as they require a large number of expensive (forward) numerical solutions of the corresponding PDEs. We propose a machine learning algorithm, based on deep artificial neural networks, that predicts the underlying \\emph{input parameters to observable} map from a few training samples (com", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["neural networks"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:30.301906Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Many large scale problems in computational fluid dynamics such as uncertainty quantification, Bayesian inversion, data assimilation and PDE constrained optimization are considered very challenging computationally as they require a large number of expensive (forward) numerical solutions of the corresponding PDEs. We propose a machine learning algorithm, based on deep artificial neural networks, that predicts the underlying \\emph{input parameters to observable} map from a few training samples (computed realizations of this map). By a judicious combination of theoretical arguments and empirical observations, we find suitable network architectures and training hyperparameters that result in robust and efficient neural network approximations of the parameters to observable map. Numerical experiments are presented to demonstrate low prediction errors for the trained network networks, even when the network has been trained with a few samples, at a computational cost which is several orders of magnitude lower than the underlying PDE solver.\n  Moreover, we combine the proposed deep learning algorithm with Monte Carlo (MC) and Quasi-Monte Carlo (QMC) methods to efficiently compute uncertainty propagation for nonlinear PDEs. Under the assumption that the underlying neural networks generalize well, we prove that the deep learning MC and QMC algorithms are guaranteed to be faster than the baseline (quasi-) Monte Carlo methods. Numerical experiments demonstrating one to two orders of magnitude speed up over baseline QMC and MC algorithms, for the intricate problem of computing probability distributions of the observable, are also presented."}}, {"id": "be4770c7456c2cd3", "url": "http://arxiv.org/abs/1609.04846v1", "title": "A Tutorial about Random Neural Networks in Supervised Learning", "description": "Random Neural Networks (RNNs) are a class of Neural Networks (NNs) that can also be seen as a specific type of queuing network. They have been successfully used in several domains during the last 25 years, as queuing networks to analyze the performance of resource sharing in many engineering areas, as learning tools and in combinatorial optimization, where they are seen as neural systems, and also as models of neurological aspects of living beings. In this article we focus on their learning capa", "provider": "arxiv", "domains": ["deep_learning", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["neural networks"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:30.439248Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Random Neural Networks (RNNs) are a class of Neural Networks (NNs) that can also be seen as a specific type of queuing network. They have been successfully used in several domains during the last 25 years, as queuing networks to analyze the performance of resource sharing in many engineering areas, as learning tools and in combinatorial optimization, where they are seen as neural systems, and also as models of neurological aspects of living beings. In this article we focus on their learning capabilities, and more specifically, we present a practical guide for using the RNN to solve supervised learning problems. We give a general description of these models using almost indistinctly the terminology of Queuing Theory and the neural one. We present the standard learning procedures used by RNNs, adapted from similar well-established improvements in the standard NN field. We describe in particular a set of learning algorithms covering techniques based on the use of first order and, then, of second order derivatives. We also discuss some issues related to these objects and present new perspectives about their use in supervised learning problems. The tutorial describes their most relevant applications, and also provides a large bibliography."}}, {"id": "cb58526271c9ce0f", "url": "http://arxiv.org/abs/2306.14753v1", "title": "The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory", "description": "Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing, physical modeling, computational science, communication science, and stochastic analysis. Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approach", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["neural networks"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:30.539987Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing, physical modeling, computational science, communication science, and stochastic analysis. Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approaches based on DANNs, the kernel structure of neural signal processing remains the same, where the node response is encoded as a linear superposition of neural activity, while the non-linearity is triggered by the activation functions. In the current paper, we suggest to analyze the neural signal processing in DANNs from the point of view of homogeneous chaos theory as known from polynomial chaos expansion (PCE). From the PCE perspective, the (linear) response on each node of a DANN could be seen as a $1^{st}$ degree multi-variate polynomial of single neurons from the previous layer, i.e. linear weighted sum of monomials. From this point of view, the conventional DANN structure relies implicitly (but erroneously) on a Gaussian distribution of neural signals. Additionally, this view revels that by design DANNs do not necessarily fulfill any orthogonality or orthonormality condition for a majority of data-driven applications. Therefore, the prevailing handling of neural signals in DANNs could lead to redundant representation as any neural signal could contain some partial information from other neural signals. To tackle that challenge, we suggest to employ the data-driven generalization of PCE theory known as arbitrary polynomial chaos (aPC) to construct a corresponding multi-variate orthonormal representations on each node of a DANN to obtain Deep arbitrary polynomial chaos neural networks."}}, {"id": "9e0514ef7ec160be", "url": "http://arxiv.org/abs/2507.07824v1", "title": "Conditional Unigram Tokenization with Parallel Data", "description": "We introduce conditional unigram tokenization, a novel approach that extends unigram tokenization by conditioning target token probabilities on source-language tokens from parallel data. Given a fixed source tokenizer, our method learns a target tokenizer that maximizes cross-lingual semantic alignment. We evaluate our tokenizer on four language pairs across different families and resource levels, examining intrinsic properties and downstream performance on machine translation and language model", "provider": "arxiv", "domains": ["nlp", "ai_ethics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["machine translation"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:30.912324Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We introduce conditional unigram tokenization, a novel approach that extends unigram tokenization by conditioning target token probabilities on source-language tokens from parallel data. Given a fixed source tokenizer, our method learns a target tokenizer that maximizes cross-lingual semantic alignment. We evaluate our tokenizer on four language pairs across different families and resource levels, examining intrinsic properties and downstream performance on machine translation and language modeling. While our conditional tokenizer maintains comparable statistical properties to standard unigram tokenizers, results are mixed: we observe no improvements in machine translation quality, but find consistent perplexity reductions in language modeling. We hypothesize that quadratic scaling of conditional probability estimation with respect to the vocabulary size creates a data efficiency bottleneck. Our findings suggest that alternative parameterizations may be necessary for practical cross-lingual tokenization."}}, {"id": "b8999e0f0287a5e8", "url": "http://arxiv.org/abs/2111.11066v1", "title": "FedCV: A Federated Learning Framework for Diverse Computer Vision Tasks", "description": "Federated Learning (FL) is a distributed learning paradigm that can learn a global or personalized model from decentralized datasets on edge devices. However, in the computer vision domain, model performance in FL is far behind centralized training due to the lack of exploration in diverse tasks with a unified FL framework. FL has rarely been demonstrated effectively in advanced computer vision tasks such as object detection and image segmentation. To bridge the gap and facilitate the developmen", "provider": "arxiv", "domains": ["computer_vision", "reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["image classification", "image segmentation", "object detection"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:31.213067Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Federated Learning (FL) is a distributed learning paradigm that can learn a global or personalized model from decentralized datasets on edge devices. However, in the computer vision domain, model performance in FL is far behind centralized training due to the lack of exploration in diverse tasks with a unified FL framework. FL has rarely been demonstrated effectively in advanced computer vision tasks such as object detection and image segmentation. To bridge the gap and facilitate the development of FL for computer vision tasks, in this work, we propose a federated learning library and benchmarking framework, named FedCV, to evaluate FL on the three most representative computer vision tasks: image classification, image segmentation, and object detection. We provide non-I.I.D. benchmarking datasets, models, and various reference FL algorithms. Our benchmark study suggests that there are multiple challenges that deserve future exploration: centralized training tricks may not be directly applied to FL; the non-I.I.D. dataset actually downgrades the model accuracy to some degree in different tasks; improving the system efficiency of federated training is challenging given the huge number of parameters and the per-client memory cost. We believe that such a library and benchmark, along with comparable evaluation settings, is necessary to make meaningful progress in FL on computer vision tasks. FedCV is publicly available: https://github.com/FedML-AI/FedCV."}}, {"id": "df517d92ff23bebf", "url": "http://arxiv.org/abs/2302.10473v6", "title": "Oriented object detection in optical remote sensing images using deep learning: a survey", "description": "Oriented object detection is a fundamental yet challenging task in remote sensing (RS), aiming to locate and classify objects with arbitrary orientations. Recent advancements in deep learning have significantly enhanced the capabilities of oriented object detection methods. Given the rapid development of this field, a comprehensive survey of the recent advances in oriented object detection is presented in this paper. Specifically, we begin by tracing the technical evolution from horizontal objec", "provider": "arxiv", "domains": ["computer_vision", "deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["object detection"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:31.546100Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Oriented object detection is a fundamental yet challenging task in remote sensing (RS), aiming to locate and classify objects with arbitrary orientations. Recent advancements in deep learning have significantly enhanced the capabilities of oriented object detection methods. Given the rapid development of this field, a comprehensive survey of the recent advances in oriented object detection is presented in this paper. Specifically, we begin by tracing the technical evolution from horizontal object detection to oriented object detection and highlighting the specific related challenges, including feature misalignment, spatial misalignment, oriented bounding box (OBB) regression problems, and common issues encountered in RS. Subsequently, we further categorize the existing methods into detection frameworks, OBB regression techniques, feature representation approaches, and solutions to common issues and provide an in-depth discussion of how these methods address the above challenges. In addition, we cover several publicly available datasets and evaluation protocols. Furthermore, we provide a comprehensive comparison and analysis involving the state-of-the-art methods. Toward the end of this paper, we identify several future directions for oriented object detection research."}}, {"id": "4d487b6df54665a0", "url": "http://arxiv.org/abs/2601.20415v1", "title": "An Empirical Evaluation of Modern MLOps Frameworks", "description": "Given the increasing adoption of AI solutions in professional environments, it is necessary for developers to be able to make informed decisions about the current tool landscape. This work empirically evaluates various MLOps (Machine Learning Operations) tools to facilitate the management of the ML model lifecycle: MLflow, Metaflow, Apache Airflow, and Kubeflow Pipelines. The tools are evaluated by assessing the criteria of Ease of installation, Configuration flexibility, Interoperability, Code ", "provider": "arxiv", "domains": ["mlops", "ml_basics", "data_engineering", "nlp", "ai_ethics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:31.715528Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Given the increasing adoption of AI solutions in professional environments, it is necessary for developers to be able to make informed decisions about the current tool landscape. This work empirically evaluates various MLOps (Machine Learning Operations) tools to facilitate the management of the ML model lifecycle: MLflow, Metaflow, Apache Airflow, and Kubeflow Pipelines. The tools are evaluated by assessing the criteria of Ease of installation, Configuration flexibility, Interoperability, Code instrumentation complexity, result interpretability, and Documentation when implementing two common ML scenarios: Digit classifier with MNIST and Sentiment classifier with IMDB and BERT. The evaluation is completed by providing weighted results that lead to practical conclusions on which tools are best suited for different scenarios."}}, {"id": "96a873d477a47c29", "url": "http://arxiv.org/abs/2512.11541v1", "title": "A Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts", "description": "The performance of machine learning (ML) models often deteriorates when the underlying data distribution changes over time, a phenomenon known as data distribution drift. When this happens, ML models need to be retrained and redeployed. ML Operations (MLOps) is often manual, i.e., humans trigger the process of model retraining and redeployment. In this work, we present an automated MLOps pipeline designed to address neural network classifier retraining in response to significant data distributio", "provider": "arxiv", "domains": ["mlops", "ml_basics", "deep_learning", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:31.750971Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The performance of machine learning (ML) models often deteriorates when the underlying data distribution changes over time, a phenomenon known as data distribution drift. When this happens, ML models need to be retrained and redeployed. ML Operations (MLOps) is often manual, i.e., humans trigger the process of model retraining and redeployment. In this work, we present an automated MLOps pipeline designed to address neural network classifier retraining in response to significant data distribution changes. Our MLOps pipeline employs multi-criteria statistical techniques to detect distribution shifts and triggers model updates only when necessary, ensuring computational efficiency and resource optimization. We demonstrate the effectiveness of our framework through experiments on several benchmark anomaly detection data sets, showing significant improvements in model accuracy and robustness compared to traditional retraining strategies. Our work provides a foundation for deploying more reliable and adaptive ML systems in dynamic real-world settings, where data distribution changes are common."}}, {"id": "4a969de2a3635f3f", "url": "http://arxiv.org/abs/2308.10908v1", "title": "MLOps: A Review", "description": "Recently, Machine Learning (ML) has become a widely accepted method for significant progress that is rapidly evolving. Since it employs computational methods to teach machines and produce acceptable answers. The significance of the Machine Learning Operations (MLOps) methods, which can provide acceptable answers for such problems, is examined in this study. To assist in the creation of software that is simple to use, the authors research MLOps methods. To choose the best tool structure for certa", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:31.824026Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Recently, Machine Learning (ML) has become a widely accepted method for significant progress that is rapidly evolving. Since it employs computational methods to teach machines and produce acceptable answers. The significance of the Machine Learning Operations (MLOps) methods, which can provide acceptable answers for such problems, is examined in this study. To assist in the creation of software that is simple to use, the authors research MLOps methods. To choose the best tool structure for certain projects, the authors also assess the features and operability of various MLOps methods. A total of 22 papers were assessed that attempted to apply the MLOps idea. Finally, the authors admit the scarcity of fully effective MLOps methods based on which advancements can self-regulate by limiting human engagement."}}, {"id": "d4c99f9641ad12f1", "url": "http://arxiv.org/abs/2407.09107v1", "title": "MLOps: A Multiple Case Study in Industry 4.0", "description": "As Machine Learning (ML) becomes more prevalent in Industry 4.0, there is a growing need to understand how systematic approaches to bringing ML into production can be practically implemented in industrial environments. Here, MLOps comes into play. MLOps refers to the processes, tools, and organizational structures used to develop, test, deploy, and manage ML models reliably and efficiently. However, there is currently a lack of information on the practical implementation of MLOps in industrial e", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "intermediate", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["model deployment"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:31.861619Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "As Machine Learning (ML) becomes more prevalent in Industry 4.0, there is a growing need to understand how systematic approaches to bringing ML into production can be practically implemented in industrial environments. Here, MLOps comes into play. MLOps refers to the processes, tools, and organizational structures used to develop, test, deploy, and manage ML models reliably and efficiently. However, there is currently a lack of information on the practical implementation of MLOps in industrial enterprises. To address this issue, we conducted a multiple case study on MLOps in three large companies with dedicated MLOps teams, using established tools and well-defined model deployment processes in the Industry 4.0 environment. This study describes four of the companies' Industry 4.0 scenarios and provides relevant insights into their implementation and the challenges they faced in numerous projects. Further, we discuss MLOps processes, procedures, technologies, as well as contextual variations among companies."}}, {"id": "4f0c70b677a0ccf6", "url": "http://arxiv.org/abs/2306.14895v1", "title": "Large Multimodal Models: Notes on CVPR 2023 Tutorial", "description": "This tutorial note summarizes the presentation on ``Large Multimodal Models: Towards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023 tutorial on ``Recent Advances in Vision Foundation Models''. The tutorial consists of three parts. We first introduce the background on recent GPT-like large models for vision-and-language modeling to motivate the research in instruction-tuned large multimodal models (LMMs). As a pre-requisite, we describe the basics of instruction-tuning in large l", "provider": "arxiv", "domains": ["nlp", "computer_vision"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:31.975189Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This tutorial note summarizes the presentation on ``Large Multimodal Models: Towards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023 tutorial on ``Recent Advances in Vision Foundation Models''. The tutorial consists of three parts. We first introduce the background on recent GPT-like large models for vision-and-language modeling to motivate the research in instruction-tuned large multimodal models (LMMs). As a pre-requisite, we describe the basics of instruction-tuning in large language models, which is further extended to the multimodal space. Lastly, we illustrate how to build the minimum prototype of multimodal GPT-4 like models with the open-source resource, and review the recently emerged topics."}}, {"id": "f3e7a7ec896819f7", "url": "http://arxiv.org/abs/2504.03931v3", "title": "NAACL2025 Tutorial: Adaptation of Large Language Models", "description": "This tutorial on adaptation of LLMs is designed to address the growing demand for models that go beyond the static capabilities of generic LLMs by providing an overview of dynamic, domain-specific, and task-adaptive LLM adaptation techniques. While general LLMs have demonstrated strong generalization across a variety of tasks, they often struggle to perform well in specialized domains such as finance, healthcare, and code generation for underrepresented languages. Additionally, their static natu", "provider": "arxiv", "domains": ["generative_ai", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["large language models", "RAG"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.014531Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This tutorial on adaptation of LLMs is designed to address the growing demand for models that go beyond the static capabilities of generic LLMs by providing an overview of dynamic, domain-specific, and task-adaptive LLM adaptation techniques. While general LLMs have demonstrated strong generalization across a variety of tasks, they often struggle to perform well in specialized domains such as finance, healthcare, and code generation for underrepresented languages. Additionally, their static nature limits their ability to evolve with the changing world, and they are often extremely large in size, making them impractical and costly to deploy at scale. As a result, the adaptation of LLMs has drawn much attention since the birth of LLMs and is of core importance, both for industry, which focuses on serving its targeted users, and academia, which can greatly benefit from small but powerful LLMs. To address this gap, this tutorial aims to provide an overview of the LLM adaptation techniques. We start with an introduction to LLM adaptation, from both the data perspective and the model perspective. We then emphasize how the evaluation metrics and benchmarks are different from other techniques. After establishing the problems, we explore various adaptation techniques. We categorize adaptation techniques into two main families. The first is parametric knowledge adaptation, which focuses on updating the parametric knowledge within LLMs. Additionally, we will discuss real-time adaptation techniques, including model editing, which allows LLMs to be updated dynamically in production environments. The second kind of adaptation is semi-parametric knowledge adaptation, where the goal is to update LLM parameters to better leverage external knowledge or tools through techniques like retrieval-augmented generation (RAG) and agent-based systems."}}, {"id": "21457ada3ea75e96", "url": "http://arxiv.org/abs/2003.07679v1", "title": "Business (mis)Use Cases of Generative AI", "description": "Generative AI is a class of machine learning technology that learns to generate new data from training data. While deep fakes and media-and art-related generative AI breakthroughs have recently caught people's attention and imagination, the overall area is in its infancy for business use. Further, little is known about generative AI's potential for malicious misuse at large scale. Using co-creation design fictions with AI engineers, we explore the plausibility and severity of business misuse cas", "provider": "arxiv", "domains": ["generative_ai", "ml_basics", "ai_strategy", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.339433Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Generative AI is a class of machine learning technology that learns to generate new data from training data. While deep fakes and media-and art-related generative AI breakthroughs have recently caught people's attention and imagination, the overall area is in its infancy for business use. Further, little is known about generative AI's potential for malicious misuse at large scale. Using co-creation design fictions with AI engineers, we explore the plausibility and severity of business misuse cases."}}, {"id": "8e1f56955ab17438", "url": "http://arxiv.org/abs/2503.00491v1", "title": "Tutorial Proposal: Speculative Decoding for Efficient LLM Inference", "description": "This tutorial presents a comprehensive introduction to Speculative Decoding (SD), an advanced technique for LLM inference acceleration that has garnered significant research interest in recent years. SD is introduced as an innovative decoding paradigm to mitigate the high inference latency stemming from autoregressive decoding in LLMs. At each decoding step, SD efficiently drafts several future tokens and then verifies them in parallel. This approach, unlike traditional autoregressive decoding, ", "provider": "arxiv", "domains": ["generative_ai", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.460032Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This tutorial presents a comprehensive introduction to Speculative Decoding (SD), an advanced technique for LLM inference acceleration that has garnered significant research interest in recent years. SD is introduced as an innovative decoding paradigm to mitigate the high inference latency stemming from autoregressive decoding in LLMs. At each decoding step, SD efficiently drafts several future tokens and then verifies them in parallel. This approach, unlike traditional autoregressive decoding, facilitates the simultaneous decoding of multiple tokens per step, thereby achieving promising 2x-4x speedups in LLM inference while maintaining original distributions. This tutorial delves into the latest techniques in SD, including draft model architectures and verification strategies. Additionally, it explores the acceleration potential and future research directions in this promising field. We aim for this tutorial to elucidate the current research landscape and offer insights for researchers interested in Speculative Decoding, ultimately contributing to more efficient LLM inference."}}, {"id": "59ed652e61705a23", "url": "http://arxiv.org/abs/2409.18827v1", "title": "ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning", "description": "Hyperparameters are a critical factor in reliably training well-performing reinforcement learning (RL) agents. Unfortunately, developing and evaluating automated approaches for tuning such hyperparameters is both costly and time-consuming. As a result, such approaches are often only evaluated on a single domain or algorithm, making comparisons difficult and limiting insights into their generalizability. We propose ARLBench, a benchmark for hyperparameter optimization (HPO) in RL that allows comp", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.613203Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Hyperparameters are a critical factor in reliably training well-performing reinforcement learning (RL) agents. Unfortunately, developing and evaluating automated approaches for tuning such hyperparameters is both costly and time-consuming. As a result, such approaches are often only evaluated on a single domain or algorithm, making comparisons difficult and limiting insights into their generalizability. We propose ARLBench, a benchmark for hyperparameter optimization (HPO) in RL that allows comparisons of diverse HPO approaches while being highly efficient in evaluation. To enable research into HPO in RL, even in settings with low compute resources, we select a representative subset of HPO tasks spanning a variety of algorithm and environment combinations. This selection allows for generating a performance profile of an automated RL (AutoRL) method using only a fraction of the compute previously necessary, enabling a broader range of researchers to work on HPO in RL. With the extensive and large-scale dataset on hyperparameter landscapes that our selection is based on, ARLBench is an efficient, flexible, and future-oriented foundation for research on AutoRL. Both the benchmark and the dataset are available at https://github.com/automl/arlbench."}}, {"id": "f2d726b29f059232", "url": "http://arxiv.org/abs/1807.05037v1", "title": "Exploring Hierarchy-Aware Inverse Reinforcement Learning", "description": "We introduce a new generative model for human planning under the Bayesian Inverse Reinforcement Learning (BIRL) framework which takes into account the fact that humans often plan using hierarchical strategies. We describe the Bayesian Inverse Hierarchical RL (BIHRL) algorithm for inferring the values of hierarchical planners, and use an illustrative toy model to show that BIHRL retains accuracy where standard BIRL fails. Furthermore, BIHRL is able to accurately predict the goals of `Wikispeedia'", "provider": "arxiv", "domains": ["reinforcement_learning", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.689324Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We introduce a new generative model for human planning under the Bayesian Inverse Reinforcement Learning (BIRL) framework which takes into account the fact that humans often plan using hierarchical strategies. We describe the Bayesian Inverse Hierarchical RL (BIHRL) algorithm for inferring the values of hierarchical planners, and use an illustrative toy model to show that BIHRL retains accuracy where standard BIRL fails. Furthermore, BIHRL is able to accurately predict the goals of `Wikispeedia' game players, with inclusion of hierarchical structure in the model resulting in a large boost in accuracy. We show that BIHRL is able to significantly outperform BIRL even when we only have a weak prior on the hierarchical structure of the plans available to the agent, and discuss the significant challenges that remain for scaling up this framework to more realistic settings."}}, {"id": "e14be50b90ceb2fa", "url": "http://arxiv.org/abs/2301.08028v4", "title": "A Tutorial on Meta-Reinforcement Learning", "description": "While deep reinforcement learning (RL) has fueled multiple high-profile successes in machine learning, it is held back from more widespread adoption by its often poor data efficiency and the limited generality of the policies it produces. A promising approach for alleviating these limitations is to cast the development of better RL algorithms as a machine learning problem itself in a process called meta-RL. Meta-RL is most commonly studied in a problem setting where, given a distribution of task", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.723714Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "While deep reinforcement learning (RL) has fueled multiple high-profile successes in machine learning, it is held back from more widespread adoption by its often poor data efficiency and the limited generality of the policies it produces. A promising approach for alleviating these limitations is to cast the development of better RL algorithms as a machine learning problem itself in a process called meta-RL. Meta-RL is most commonly studied in a problem setting where, given a distribution of tasks, the goal is to learn a policy that is capable of adapting to any new task from the task distribution with as little data as possible. In this survey, we describe the meta-RL problem setting in detail as well as its major variations. We discuss how, at a high level, meta-RL research can be clustered based on the presence of a task distribution and the learning budget available for each individual task. Using these clusters, we then survey meta-RL algorithms and applications. We conclude by presenting the open problems on the path to making meta-RL part of the standard toolbox for a deep RL practitioner."}}, {"id": "22e616695896713a", "url": "http://arxiv.org/abs/2406.04896v2", "title": "Stabilizing Extreme Q-learning by Maclaurin Expansion", "description": "In offline reinforcement learning, in-sample learning methods have been widely used to prevent performance degradation caused by evaluating out-of-distribution actions from the dataset. Extreme Q-learning (XQL) employs a loss function based on the assumption that Bellman error follows a Gumbel distribution, enabling it to model the soft optimal value function in an in-sample manner. It has demonstrated strong performance in both offline and online reinforcement learning settings. However, issues", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["Q-learning"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.760955Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In offline reinforcement learning, in-sample learning methods have been widely used to prevent performance degradation caused by evaluating out-of-distribution actions from the dataset. Extreme Q-learning (XQL) employs a loss function based on the assumption that Bellman error follows a Gumbel distribution, enabling it to model the soft optimal value function in an in-sample manner. It has demonstrated strong performance in both offline and online reinforcement learning settings. However, issues remain, such as the instability caused by the exponential term in the loss function and the risk of the error distribution deviating from the Gumbel distribution. Therefore, we propose Maclaurin Expanded Extreme Q-learning to enhance stability. In this method, applying Maclaurin expansion to the loss function in XQL enhances stability against large errors. This approach involves adjusting the modeled value function between the value function under the behavior policy and the soft optimal value function, thus achieving a trade-off between stability and optimality depending on the order of expansion. It also enables adjustment of the error distribution assumption from a normal distribution to a Gumbel distribution. Our method significantly stabilizes learning in online RL tasks from DM Control, where XQL was previously unstable. Additionally, it improves performance in several offline RL tasks from D4RL."}}, {"id": "df9ce4fe3b6240d0", "url": "http://arxiv.org/abs/1908.09381v5", "title": "Tutorial and Survey on Probabilistic Graphical Model and Variational Inference in Deep Reinforcement Learning", "description": "Aiming at a comprehensive and concise tutorial survey, recap of variational inference and reinforcement learning with Probabilistic Graphical Models are given with detailed derivations. Reviews and comparisons on recent advances in deep reinforcement learning are made from various aspects. We offer detailed derivations to a taxonomy of Probabilistic Graphical Model and Variational Inference methods in deep reinforcement learning, which serves as a complementary material on top of the original co", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.798669Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Aiming at a comprehensive and concise tutorial survey, recap of variational inference and reinforcement learning with Probabilistic Graphical Models are given with detailed derivations. Reviews and comparisons on recent advances in deep reinforcement learning are made from various aspects. We offer detailed derivations to a taxonomy of Probabilistic Graphical Model and Variational Inference methods in deep reinforcement learning, which serves as a complementary material on top of the original contributions."}}, {"id": "6c8891ba2ea27b5b", "url": "http://arxiv.org/abs/2010.04816v1", "title": "Characterizing Policy Divergence for Personalized Meta-Reinforcement Learning", "description": "Despite ample motivation from costly exploration and limited trajectory data, rapidly adapting to new environments with few-shot reinforcement learning (RL) can remain a challenging task, especially with respect to personalized settings. Here, we consider the problem of recommending optimal policies to a set of multiple entities each with potentially different characteristics, such that individual entities may parameterize distinct environments with unique transition dynamics. Inspired by existi", "provider": "arxiv", "domains": ["reinforcement_learning", "ai_governance", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.905087Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Despite ample motivation from costly exploration and limited trajectory data, rapidly adapting to new environments with few-shot reinforcement learning (RL) can remain a challenging task, especially with respect to personalized settings. Here, we consider the problem of recommending optimal policies to a set of multiple entities each with potentially different characteristics, such that individual entities may parameterize distinct environments with unique transition dynamics. Inspired by existing literature in meta-learning, we extend previous work by focusing on the notion that certain environments are more similar to each other than others in personalized settings, and propose a model-free meta-learning algorithm that prioritizes past experiences by relevance during gradient-based adaptation. Our algorithm involves characterizing past policy divergence through methods in inverse reinforcement learning, and we illustrate how such metrics are able to effectively distinguish past policy parameters by the environment they were deployed in, leading to more effective fast adaptation during test time. To study personalization more effectively we introduce a navigation testbed to specifically incorporate environment diversity across training episodes, and demonstrate that our approach outperforms meta-learning alternatives with respect to few-shot reinforcement learning in personalized settings."}}, {"id": "7912874316b9da40", "url": "http://arxiv.org/abs/1705.05172v1", "title": "Emotion in Reinforcement Learning Agents and Robots: A Survey", "description": "This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for thr", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.940256Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research."}}, {"id": "4db6d95b4928de7c", "url": "http://arxiv.org/abs/2306.16208v4", "title": "Continuous-time q-learning for mean-field control problems", "description": "This paper studies the q-learning, recently coined as the continuous time counterpart of Q-learning by Jia and Zhou (2023), for continuous time Mckean-Vlasov control problems in the setting of entropy-regularized reinforcement learning. In contrast to the single agent's control problem in Jia and Zhou (2023), the mean-field interaction of agents renders the definition of the q-function more subtle, for which we reveal that two distinct q-functions naturally arise: (i) the integrated q-function (", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["Q-learning"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:32.975973Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper studies the q-learning, recently coined as the continuous time counterpart of Q-learning by Jia and Zhou (2023), for continuous time Mckean-Vlasov control problems in the setting of entropy-regularized reinforcement learning. In contrast to the single agent's control problem in Jia and Zhou (2023), the mean-field interaction of agents renders the definition of the q-function more subtle, for which we reveal that two distinct q-functions naturally arise: (i) the integrated q-function (denoted by $q$) as the first-order approximation of the integrated Q-function introduced in Gu, Guo, Wei and Xu (2023), which can be learnt by a weak martingale condition involving test policies; and (ii) the essential q-function (denoted by $q_e$) that is employed in the policy improvement iterations. We show that two q-functions are related via an integral representation under all test policies. Based on the weak martingale condition and our proposed searching method of test policies, some model-free learning algorithms are devised. In two examples, one in LQ control framework and one beyond LQ control framework, we can obtain the exact parameterization of the optimal value function and q-functions and illustrate our algorithms with simulation experiments."}}, {"id": "c18509ff0fb89c5a", "url": "http://arxiv.org/abs/2504.16644v1", "title": "A Systematic Review of Common Beginner Programming Mistakes in Data Engineering", "description": "The design of effective programming languages, libraries, frameworks, tools, and platforms for data engineering strongly depends on their ease and correctness of use. Anyone who ignores that it is humans who use these tools risks building tools that are useless, or worse, harmful. To ensure our data engineering tools are based on solid foundations, we performed a systematic review of common programming mistakes in data engineering. We focus on programming beginners (students) by analyzing both t", "provider": "arxiv", "domains": ["data_engineering", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:33.161837Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The design of effective programming languages, libraries, frameworks, tools, and platforms for data engineering strongly depends on their ease and correctness of use. Anyone who ignores that it is humans who use these tools risks building tools that are useless, or worse, harmful. To ensure our data engineering tools are based on solid foundations, we performed a systematic review of common programming mistakes in data engineering. We focus on programming beginners (students) by analyzing both the limited literature specific to data engineering mistakes and general programming mistakes in languages commonly used in data engineering (Python, SQL, Java). Through analysis of 21 publications spanning from 2003 to 2024, we synthesized these complementary sources into a comprehensive classification that captures both general programming challenges and domain-specific data engineering mistakes. This classification provides an empirical foundation for future tool development and educational strategies. We believe our systematic categorization will help researchers, practitioners, and educators better understand and address the challenges faced by novice data engineers."}}, {"id": "74cac193ee27792b", "url": "http://arxiv.org/abs/2004.11434v1", "title": "Responsible AI and Its Stakeholders", "description": "Responsible Artificial Intelligence (AI) proposes a framework that holds all stakeholders involved in the development of AI to be responsible for their systems. It, however, fails to accommodate the possibility of holding AI responsible per se, which could close some legal and moral gaps concerning the deployment of autonomous and self-learning systems. We discuss three notions of responsibility (i.e., blameworthiness, accountability, and liability) for all stakeholders, including AI, and sugges", "provider": "arxiv", "domains": ["ai_ethics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["privacy", "accountability"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:33.670718Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Responsible Artificial Intelligence (AI) proposes a framework that holds all stakeholders involved in the development of AI to be responsible for their systems. It, however, fails to accommodate the possibility of holding AI responsible per se, which could close some legal and moral gaps concerning the deployment of autonomous and self-learning systems. We discuss three notions of responsibility (i.e., blameworthiness, accountability, and liability) for all stakeholders, including AI, and suggest the roles of jurisdiction and the general public in this matter."}}, {"id": "062751c1972b2e5a", "url": "http://arxiv.org/abs/1912.06166v3", "title": "ABOUT ML: Annotation and Benchmarking on Understanding and Transparency of Machine Learning Lifecycles", "description": "We present the \"Annotation and Benchmarking on Understanding and Transparency of Machine Learning Lifecycles\" (ABOUT ML) project as an initiative to operationalize ML transparency and work towards a standard ML documentation practice. We make the case for the project's relevance and effectiveness in consolidating disparate efforts across a variety of stakeholders, as well as bringing in the perspectives of currently missing voices that will be valuable in shaping future conversations. We describ", "provider": "arxiv", "domains": ["ai_ethics", "ml_basics", "ai_governance", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:00:33.918059Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We present the \"Annotation and Benchmarking on Understanding and Transparency of Machine Learning Lifecycles\" (ABOUT ML) project as an initiative to operationalize ML transparency and work towards a standard ML documentation practice. We make the case for the project's relevance and effectiveness in consolidating disparate efforts across a variety of stakeholders, as well as bringing in the perspectives of currently missing voices that will be valuable in shaping future conversations. We describe the details of the initiative and the gaps we hope this project will help address."}}, {"id": "9858f13fc8934b90", "url": "http://arxiv.org/abs/2507.06378v1", "title": "Evaluating Morphological Alignment of Tokenizers in 70 Languages", "description": "While tokenization is a key step in language modeling, with effects on model training and performance, it remains unclear how to effectively evaluate tokenizer quality. One proposed dimension of tokenizer quality is the extent to which tokenizers preserve linguistically meaningful subwords, aligning token boundaries with morphological boundaries within a word. We expand MorphScore (Arnett & Bergen, 2025), which previously covered 22 languages, to support a total of 70 languages. The updated Morp", "provider": "arxiv", "domains": ["nlp", "ai_ethics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["privacy"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:48.876328Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "While tokenization is a key step in language modeling, with effects on model training and performance, it remains unclear how to effectively evaluate tokenizer quality. One proposed dimension of tokenizer quality is the extent to which tokenizers preserve linguistically meaningful subwords, aligning token boundaries with morphological boundaries within a word. We expand MorphScore (Arnett & Bergen, 2025), which previously covered 22 languages, to support a total of 70 languages. The updated MorphScore offers more flexibility in evaluation and addresses some of the limitations of the original version. We then correlate our alignment scores with downstream task performance for five pre-trained languages models on seven tasks, with at least one task in each of the languages in our sample. We find that morphological alignment does not explain very much variance in model performance, suggesting that morphological alignment alone does not measure dimensions of tokenization quality relevant to model performance."}}, {"id": "35ed62652fe81ddf", "url": "http://arxiv.org/abs/2510.20590v1", "title": "Embedding the MLOps Lifecycle into OT Reference Models", "description": "Machine Learning Operations (MLOps) practices are increas- ingly adopted in industrial settings, yet their integration with Opera- tional Technology (OT) systems presents significant challenges. This pa- per analyzes the fundamental obstacles in combining MLOps with OT en- vironments and proposes a systematic approach to embed MLOps prac- tices into established OT reference models. We evaluate the suitability of the Reference Architectural Model for Industry 4.0 (RAMI 4.0) and the International ", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:49.330115Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Machine Learning Operations (MLOps) practices are increas- ingly adopted in industrial settings, yet their integration with Opera- tional Technology (OT) systems presents significant challenges. This pa- per analyzes the fundamental obstacles in combining MLOps with OT en- vironments and proposes a systematic approach to embed MLOps prac- tices into established OT reference models. We evaluate the suitability of the Reference Architectural Model for Industry 4.0 (RAMI 4.0) and the International Society of Automation Standard 95 (ISA-95) for MLOps integration and present a detailed mapping of MLOps lifecycle compo- nents to RAMI 4.0 exemplified by a real-world use case. Our findings demonstrate that while standard MLOps practices cannot be directly transplanted to OT environments, structured adaptation using existing reference models can provide a pathway for successful integration."}}, {"id": "84960b232a76d170", "url": "http://arxiv.org/abs/2402.12281v1", "title": "Challenges and Experiences of Iranian Developers with MLOps at Enterprise", "description": "Data is becoming more complex, and so are the approaches designed to process it. Enterprises have access to more data than ever, but many still struggle to glean the full potential of insights from what they have. This research explores the challenges and experiences of Iranian developers in implementing the MLOps paradigm within enterprise settings. MLOps, or Machine Learning Operations, is a discipline focused on automating the continuous delivery of machine learning models. In this study, we ", "provider": "arxiv", "domains": ["mlops", "ml_basics", "ai_project_management", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["model deployment"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:49.457581Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Data is becoming more complex, and so are the approaches designed to process it. Enterprises have access to more data than ever, but many still struggle to glean the full potential of insights from what they have. This research explores the challenges and experiences of Iranian developers in implementing the MLOps paradigm within enterprise settings. MLOps, or Machine Learning Operations, is a discipline focused on automating the continuous delivery of machine learning models. In this study, we review the most popular MLOps tools used by leading technology enterprises. Additionally, we present the results of a questionnaire answered by over 110 Iranian Machine Learning experts and Software Developers, shedding light on MLOps tools and the primary obstacles faced. The findings reveal that data quality problems, a lack of resources, and difficulties in model deployment are among the primary challenges faced by practitioners. Collaboration between ML, DevOps, Ops, and Science teams is seen as a pivotal challenge in implementing MLOps effectively."}}, {"id": "0ea56d77cb1b9075", "url": "http://arxiv.org/abs/2311.18252v3", "title": "Privacy and Copyright Protection in Generative AI: A Lifecycle Perspective", "description": "The advent of Generative AI has marked a significant milestone in artificial intelligence, demonstrating remarkable capabilities in generating realistic images, texts, and data patterns. However, these advancements come with heightened concerns over data privacy and copyright infringement, primarily due to the reliance on vast datasets for model training. Traditional approaches like differential privacy, machine unlearning, and data poisoning only offer fragmented solutions to these complex issu", "provider": "arxiv", "domains": ["ai_ethics", "generative_ai", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["privacy"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:49.972359Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The advent of Generative AI has marked a significant milestone in artificial intelligence, demonstrating remarkable capabilities in generating realistic images, texts, and data patterns. However, these advancements come with heightened concerns over data privacy and copyright infringement, primarily due to the reliance on vast datasets for model training. Traditional approaches like differential privacy, machine unlearning, and data poisoning only offer fragmented solutions to these complex issues. Our paper delves into the multifaceted challenges of privacy and copyright protection within the data lifecycle. We advocate for integrated approaches that combines technical innovation with ethical foresight, holistically addressing these concerns by investigating and devising solutions that are informed by the lifecycle perspective. This work aims to catalyze a broader discussion and inspire concerted efforts towards data privacy and copyright integrity in Generative AI."}}, {"id": "c42bc6523470c1e4", "url": "http://arxiv.org/abs/2409.18051v1", "title": "Inverse Reinforcement Learning with Multiple Planning Horizons", "description": "In this work, we study an inverse reinforcement learning (IRL) problem where the experts are planning under a shared reward function but with different, unknown planning horizons. Without the knowledge of discount factors, the reward function has a larger feasible solution set, which makes it harder for existing IRL approaches to identify a reward function. To overcome this challenge, we develop algorithms that can learn a global multi-agent reward function with agent-specific discount factors t", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:51.299644Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this work, we study an inverse reinforcement learning (IRL) problem where the experts are planning under a shared reward function but with different, unknown planning horizons. Without the knowledge of discount factors, the reward function has a larger feasible solution set, which makes it harder for existing IRL approaches to identify a reward function. To overcome this challenge, we develop algorithms that can learn a global multi-agent reward function with agent-specific discount factors that reconstruct the expert policies. We characterize the feasible solution space of the reward function and discount factors for both algorithms and demonstrate the generalizability of the learned reward function across multiple domains."}}, {"id": "73f5db2959ca3dd8", "url": "http://arxiv.org/abs/2309.05105v1", "title": "Convex Q Learning in a Stochastic Environment: Extended Version", "description": "The paper introduces the first formulation of convex Q-learning for Markov decision processes with function approximation. The algorithms and theory rest on a relaxation of a dual of Manne's celebrated linear programming characterization of optimal control. The main contributions firstly concern properties of the relaxation, described as a deterministic convex program: we identify conditions for a bounded solution, and a significant relationship between the solution to the new convex program, an", "provider": "arxiv", "domains": ["reinforcement_learning", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["Markov decision processes", "Q-learning"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:51.500085Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The paper introduces the first formulation of convex Q-learning for Markov decision processes with function approximation. The algorithms and theory rest on a relaxation of a dual of Manne's celebrated linear programming characterization of optimal control. The main contributions firstly concern properties of the relaxation, described as a deterministic convex program: we identify conditions for a bounded solution, and a significant relationship between the solution to the new convex program, and the solution to standard Q-learning. The second set of contributions concern algorithm design and analysis: (i) A direct model-free method for approximating the convex program for Q-learning shares properties with its ideal. In particular, a bounded solution is ensured subject to a simple property of the basis functions; (ii) The proposed algorithms are convergent and new techniques are introduced to obtain the rate of convergence in a mean-square sense; (iii) The approach can be generalized to a range of performance criteria, and it is found that variance can be reduced by considering ``relative'' dynamic programming equations; (iv) The theory is illustrated with an application to a classical inventory control problem."}}, {"id": "c0fd179f031d8ea9", "url": "http://arxiv.org/abs/2006.15690v1", "title": "Lookahead-Bounded Q-Learning", "description": "We introduce the lookahead-bounded Q-learning (LBQL) algorithm, a new, provably convergent variant of Q-learning that seeks to improve the performance of standard Q-learning in stochastic environments through the use of ``lookahead'' upper and lower bounds. To do this, LBQL employs previously collected experience and each iteration's state-action values as dual feasible penalties to construct a sequence of sampled information relaxation problems. The solutions to these problems provide estimated", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["Q-learning"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:51.569361Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We introduce the lookahead-bounded Q-learning (LBQL) algorithm, a new, provably convergent variant of Q-learning that seeks to improve the performance of standard Q-learning in stochastic environments through the use of ``lookahead'' upper and lower bounds. To do this, LBQL employs previously collected experience and each iteration's state-action values as dual feasible penalties to construct a sequence of sampled information relaxation problems. The solutions to these problems provide estimated upper and lower bounds on the optimal value, which we track via stochastic approximation. These quantities are then used to constrain the iterates to stay within the bounds at every iteration. Numerical experiments on benchmark problems show that LBQL exhibits faster convergence and more robustness to hyperparameters when compared to standard Q-learning and several related techniques. Our approach is particularly appealing in problems that require expensive simulations or real-world interactions."}}, {"id": "d8287dda74789e77", "url": "http://arxiv.org/abs/2211.03994v1", "title": "Reinforcement Learning with Stepwise Fairness Constraints", "description": "AI methods are used in societally important settings, ranging from credit to employment to housing, and it is crucial to provide fairness in regard to algorithmic decision making. Moreover, many settings are dynamic, with populations responding to sequential decision policies. We introduce the study of reinforcement learning (RL) with stepwise fairness constraints, requiring group fairness at each time step. Our focus is on tabular episodic RL, and we provide learning algorithms with strong theo", "provider": "arxiv", "domains": ["reinforcement_learning", "ai_ethics", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["privacy", "fairness"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:53.262792Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "AI methods are used in societally important settings, ranging from credit to employment to housing, and it is crucial to provide fairness in regard to algorithmic decision making. Moreover, many settings are dynamic, with populations responding to sequential decision policies. We introduce the study of reinforcement learning (RL) with stepwise fairness constraints, requiring group fairness at each time step. Our focus is on tabular episodic RL, and we provide learning algorithms with strong theoretical guarantees in regard to policy optimality and fairness violation. Our framework provides useful tools to study the impact of fairness constraints in sequential settings and brings up new challenges in RL."}}, {"id": "263dce8f0d4aaeba", "url": "http://arxiv.org/abs/2001.05266v1", "title": "Deep Learning for MIR Tutorial", "description": "Deep Learning has become state of the art in visual computing and continuously emerges into the Music Information Retrieval (MIR) and audio retrieval domain. In order to bring attention to this topic we propose an introductory tutorial on deep learning for MIR. Besides a general introduction to neural networks, the proposed tutorial covers a wide range of MIR relevant deep learning approaches. \\textbf{Convolutional Neural Networks} are currently a de-facto standard for deep learning based audio ", "provider": "arxiv", "domains": ["deep_learning", "computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["neural networks"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:53.340233Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep Learning has become state of the art in visual computing and continuously emerges into the Music Information Retrieval (MIR) and audio retrieval domain. In order to bring attention to this topic we propose an introductory tutorial on deep learning for MIR. Besides a general introduction to neural networks, the proposed tutorial covers a wide range of MIR relevant deep learning approaches. \\textbf{Convolutional Neural Networks} are currently a de-facto standard for deep learning based audio retrieval. \\textbf{Recurrent Neural Networks} have proven to be effective in onset detection tasks such as beat or audio-event detection. \\textbf{Siamese Networks} have been shown effective in learning audio representations and distance functions specific for music similarity retrieval. We will incorporate both academic and industrial points of view into the tutorial. Accompanying the tutorial, we will create a Github repository for the content presented at the tutorial as well as references to state of the art work and literature for further reading. This repository will remain public after the conference."}}, {"id": "6a694be1e8ddefd7", "url": "http://arxiv.org/abs/2502.19567v2", "title": "Atlas: A Framework for ML Lifecycle Provenance & Transparency", "description": "The rapid adoption of open source machine learning (ML) datasets and models exposes today's AI applications to critical risks like data poisoning and supply chain attacks across the ML lifecycle. With growing regulatory pressure to address these issues through greater transparency, ML model vendors face challenges balancing these requirements against confidentiality for data and intellectual property needs. We propose Atlas, a framework that enables fully attestable ML pipelines. Atlas leverages", "provider": "arxiv", "domains": ["ai_ethics", "ai_project_management", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["privacy"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:18:53.984890Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The rapid adoption of open source machine learning (ML) datasets and models exposes today's AI applications to critical risks like data poisoning and supply chain attacks across the ML lifecycle. With growing regulatory pressure to address these issues through greater transparency, ML model vendors face challenges balancing these requirements against confidentiality for data and intellectual property needs. We propose Atlas, a framework that enables fully attestable ML pipelines. Atlas leverages open specifications for data and software supply chain provenance to collect verifiable records of model artifact authenticity and end-to-end lineage metadata. Atlas combines trusted hardware and transparency logs to enhance metadata integrity, preserve data confidentiality, and limit unauthorized access during ML pipeline operations, from training through deployment. Our prototype implementation of Atlas integrates several open-source tools to build an ML lifecycle transparency system, and assess the practicality of Atlas through two case study ML pipelines."}}, {"id": "d46108234f819ab2", "url": "http://arxiv.org/abs/2110.00207v1", "title": "Contraction-Based Methods for Stable Identification and Robust Machine Learning: a Tutorial", "description": "This tutorial paper provides an introduction to recently developed tools for machine learning, especially learning dynamical systems (system identification), with stability and robustness constraints. The main ideas are drawn from contraction analysis and robust control, but adapted to problems in which large-scale models can be learnt with behavioural guarantees. We illustrate the methods with applications in robust image recognition and system identification.", "provider": "arxiv", "domains": ["ml_basics", "computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:44.485060Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This tutorial paper provides an introduction to recently developed tools for machine learning, especially learning dynamical systems (system identification), with stability and robustness constraints. The main ideas are drawn from contraction analysis and robust control, but adapted to problems in which large-scale models can be learnt with behavioural guarantees. We illustrate the methods with applications in robust image recognition and system identification."}}, {"id": "67a9cecd9aa85c17", "url": "http://arxiv.org/abs/2512.23753v1", "title": "Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation", "description": "Evidential deep learning (EDL) models, based on Subjective Logic, introduce a principled and computationally efficient way to make deterministic neural networks uncertainty-aware. The resulting evidential models can quantify fine-grained uncertainty using learned evidence. However, the Subjective-Logic framework constrains evidence to be non-negative, requiring specific activation functions whose geometric properties can induce activation-dependent learning-freeze behavior: a regime where gradie", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["neural networks"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:45.953860Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Evidential deep learning (EDL) models, based on Subjective Logic, introduce a principled and computationally efficient way to make deterministic neural networks uncertainty-aware. The resulting evidential models can quantify fine-grained uncertainty using learned evidence. However, the Subjective-Logic framework constrains evidence to be non-negative, requiring specific activation functions whose geometric properties can induce activation-dependent learning-freeze behavior: a regime where gradients become extremely small for samples mapped into low-evidence regions. We theoretically characterize this behavior and analyze how different evidential activations influence learning dynamics. Building on this analysis, we design a general family of activation functions and corresponding evidential regularizers that provide an alternative pathway for consistent evidence updates across activation regimes. Extensive experiments on four benchmark classification problems (MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet), two few-shot classification problems, and blind face restoration problem empirically validate the developed theory and demonstrate the effectiveness of the proposed generalized regularized evidential models."}}, {"id": "17bc13f60395b48c", "url": "http://arxiv.org/abs/1903.04717v2", "title": "Activation Analysis of a Byte-Based Deep Neural Network for Malware Classification", "description": "Feature engineering is one of the most costly aspects of developing effective machine learning models, and that cost is even greater in specialized problem domains, like malware classification, where expert skills are necessary to identify useful features. Recent work, however, has shown that deep learning models can be used to automatically learn feature representations directly from the raw, unstructured bytes of the binaries themselves. In this paper, we explore what these models are learning", "provider": "arxiv", "domains": ["ml_basics", "deep_learning", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["feature engineering"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:46.033708Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Feature engineering is one of the most costly aspects of developing effective machine learning models, and that cost is even greater in specialized problem domains, like malware classification, where expert skills are necessary to identify useful features. Recent work, however, has shown that deep learning models can be used to automatically learn feature representations directly from the raw, unstructured bytes of the binaries themselves. In this paper, we explore what these models are learning about malware. To do so, we examine the learned features at multiple levels of resolution, from individual byte embeddings to end-to-end analysis of the model. At each step, we connect these byte-oriented activations to their original semantics through parsing and disassembly of the binary to arrive at human-understandable features. Through our results, we identify several interesting features learned by the model and their connection to manually-derived features typically used by traditional machine learning models. Additionally, we explore the impact of training data volume and regularization on the quality of the learned features and the efficacy of the classifiers, revealing the somewhat paradoxical insight that better generalization does not necessarily result in better performance for byte-based malware classifiers."}}, {"id": "74afd64fe39afabc", "url": "http://arxiv.org/abs/1708.05866v2", "title": "A Brief Survey of Deep Reinforcement Learning", "description": "Deep reinforcement learning is poised to revolutionise the field of AI and represents a step towards building autonomous systems with a higher level understanding of the visual world. Currently, deep learning is enabling reinforcement learning to scale to problems that were previously intractable, such as learning to play video games directly from pixels. Deep reinforcement learning algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera i", "provider": "arxiv", "domains": ["reinforcement_learning", "deep_learning", "ml_basics", "nlp", "ai_governance"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:46.385039Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep reinforcement learning is poised to revolutionise the field of AI and represents a step towards building autonomous systems with a higher level understanding of the visual world. Currently, deep learning is enabling reinforcement learning to scale to problems that were previously intractable, such as learning to play video games directly from pixels. Deep reinforcement learning algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of reinforcement learning, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep reinforcement learning, including the deep $Q$-network, trust region policy optimisation, and asynchronous advantage actor-critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via reinforcement learning. To conclude, we describe several current areas of research within the field."}}, {"id": "1117b9367d23ff3e", "url": "http://arxiv.org/abs/1807.09844v2", "title": "Modular Mechanistic Networks: On Bridging Mechanistic and Phenomenological Models with Deep Neural Networks in Natural Language Processing", "description": "Natural language processing (NLP) can be done using either top-down (theory driven) and bottom-up (data driven) approaches, which we call mechanistic and phenomenological respectively. The approaches are frequently considered to stand in opposition to each other. Examining some recent approaches in deep learning we argue that deep neural networks incorporate both perspectives and, furthermore, that leveraging this aspect of deep learning may help in solving complex problems within language techn", "provider": "arxiv", "domains": ["deep_learning", "nlp", "ml_basics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:47.285001Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Natural language processing (NLP) can be done using either top-down (theory driven) and bottom-up (data driven) approaches, which we call mechanistic and phenomenological respectively. The approaches are frequently considered to stand in opposition to each other. Examining some recent approaches in deep learning we argue that deep neural networks incorporate both perspectives and, furthermore, that leveraging this aspect of deep learning may help in solving complex problems within language technology, such as modelling language and perception in the domain of spatial cognition."}}, {"id": "888c1a45d3452807", "url": "http://arxiv.org/abs/2404.04510v1", "title": "IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials", "description": "Large Language models (LLMs) have demonstrated state-of-the-art performance in various natural language processing (NLP) tasks across multiple domains, yet they are prone to shortcut learning and factual inconsistencies. This research investigates LLMs' robustness, consistency, and faithful reasoning when performing Natural Language Inference (NLI) on breast cancer Clinical Trial Reports (CTRs) in the context of SemEval 2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials.", "provider": "arxiv", "domains": ["nlp", "generative_ai"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:47.490956Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Large Language models (LLMs) have demonstrated state-of-the-art performance in various natural language processing (NLP) tasks across multiple domains, yet they are prone to shortcut learning and factual inconsistencies. This research investigates LLMs' robustness, consistency, and faithful reasoning when performing Natural Language Inference (NLI) on breast cancer Clinical Trial Reports (CTRs) in the context of SemEval 2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials. We examine the reasoning capabilities of LLMs and their adeptness at logical problem-solving. A comparative analysis is conducted on pre-trained language models (PLMs), GPT-3.5, and Gemini Pro under zero-shot settings using Retrieval-Augmented Generation (RAG) framework, integrating various reasoning chains. The evaluation yields an F1 score of 0.69, consistency of 0.71, and a faithfulness score of 0.90 on the test dataset."}}, {"id": "0e3f22993e8f0d56", "url": "http://arxiv.org/abs/1807.00571v1", "title": "The Interplay between Lexical Resources and Natural Language Processing", "description": "Incorporating linguistic, world and common sense knowledge into AI/NLP systems is currently an important research area, with several open problems and challenges. At the same time, processing and storing this knowledge in lexical resources is not a straightforward task. This tutorial proposes to address these complementary goals from two methodological perspectives: the use of NLP methods to help the process of constructing and enriching lexical resources and the use of lexical resources for imp", "provider": "arxiv", "domains": ["nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:47.753857Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Incorporating linguistic, world and common sense knowledge into AI/NLP systems is currently an important research area, with several open problems and challenges. At the same time, processing and storing this knowledge in lexical resources is not a straightforward task. This tutorial proposes to address these complementary goals from two methodological perspectives: the use of NLP methods to help the process of constructing and enriching lexical resources and the use of lexical resources for improving NLP applications. Two main types of audience can benefit from this tutorial: those working on language resources who are interested in becoming acquainted with automatic NLP techniques, with the end goal of speeding and/or easing up the process of resource curation; and on the other hand, researchers in NLP who would like to benefit from the knowledge of lexical resources to improve their systems and models. The slides of the tutorial are available at https://bitbucket.org/luisespinosa/lr-nlp/"}}, {"id": "eba90e97da6515f2", "url": "http://arxiv.org/abs/1611.02145v1", "title": "Crowdsourcing in Computer Vision", "description": "Computer vision systems require large amounts of manually annotated data to properly learn challenging visual concepts. Crowdsourcing platforms offer an inexpensive method to capture human knowledge and understanding, for a vast number of visual perception tasks. In this survey, we describe the types of annotations computer vision researchers have collected using crowdsourcing, and how they have ensured that this data is of high quality while annotation effort is minimized. We begin by discussin", "provider": "arxiv", "domains": ["computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:48.323891Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Computer vision systems require large amounts of manually annotated data to properly learn challenging visual concepts. Crowdsourcing platforms offer an inexpensive method to capture human knowledge and understanding, for a vast number of visual perception tasks. In this survey, we describe the types of annotations computer vision researchers have collected using crowdsourcing, and how they have ensured that this data is of high quality while annotation effort is minimized. We begin by discussing data collection on both classic (e.g., object recognition) and recent (e.g., visual story-telling) vision tasks. We then summarize key design decisions for creating effective data collection interfaces and workflows, and present strategies for intelligently selecting the most important data instances to annotate. Finally, we conclude with some thoughts on the future of crowdsourcing in computer vision."}}, {"id": "9c3844ef06608c5b", "url": "http://arxiv.org/abs/1910.13796v1", "title": "Deep Learning vs. Traditional Computer Vision", "description": "Deep Learning has pushed the limits of what was possible in the domain of Digital Image Processing. However, that is not to say that the traditional computer vision techniques which had been undergoing progressive development in years prior to the rise of DL have become obsolete. This paper will analyse the benefits and drawbacks of each approach. The aim of this paper is to promote a discussion on whether knowledge of classical computer vision techniques should be maintained. The paper will als", "provider": "arxiv", "domains": ["computer_vision", "deep_learning", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:48.637720Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep Learning has pushed the limits of what was possible in the domain of Digital Image Processing. However, that is not to say that the traditional computer vision techniques which had been undergoing progressive development in years prior to the rise of DL have become obsolete. This paper will analyse the benefits and drawbacks of each approach. The aim of this paper is to promote a discussion on whether knowledge of classical computer vision techniques should be maintained. The paper will also explore how the two sides of computer vision can be combined. Several recent hybrid methodologies are reviewed which have demonstrated the ability to improve computer vision performance and to tackle problems not suited to Deep Learning. For example, combining traditional computer vision techniques with Deep Learning has been popular in emerging domains such as Panoramic Vision and 3D vision for which Deep Learning models have not yet been fully optimised"}}, {"id": "0925bf274bf1ad9f", "url": "http://arxiv.org/abs/2006.01423v1", "title": "Monocular Human Pose Estimation: A Survey of Deep Learning-based Methods", "description": "Vision-based monocular human pose estimation, as one of the most fundamental and challenging problems in computer vision, aims to obtain posture of the human body from input images or video sequences. The recent developments of deep learning techniques have been brought significant progress and remarkable breakthroughs in the field of human pose estimation. This survey extensively reviews the recent deep learning-based 2D and 3D human pose estimation methods published since 2014. This paper summ", "provider": "arxiv", "domains": ["deep_learning", "computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:48.842082Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Vision-based monocular human pose estimation, as one of the most fundamental and challenging problems in computer vision, aims to obtain posture of the human body from input images or video sequences. The recent developments of deep learning techniques have been brought significant progress and remarkable breakthroughs in the field of human pose estimation. This survey extensively reviews the recent deep learning-based 2D and 3D human pose estimation methods published since 2014. This paper summarizes the challenges, main frameworks, benchmark datasets, evaluation metrics, performance comparison, and discusses some promising future research directions."}}, {"id": "926a5ac41b59492f", "url": "http://arxiv.org/abs/2508.19294v2", "title": "Object Detection with Multimodal Large Vision-Language Models: An In-depth Review", "description": "The fusion of language and vision in large vision-language models (LVLMs) has revolutionized deep learning-based object detection by enhancing adaptability, contextual reasoning, and generalization beyond traditional architectures. This in-depth review presents a structured exploration of the state-of-the-art in LVLMs, systematically organized through a three-step research review process. First, we discuss the functioning of vision language models (VLMs) for object detection, describing how thes", "provider": "arxiv", "domains": ["nlp", "computer_vision", "deep_learning"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["object detection"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:50.147988Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The fusion of language and vision in large vision-language models (LVLMs) has revolutionized deep learning-based object detection by enhancing adaptability, contextual reasoning, and generalization beyond traditional architectures. This in-depth review presents a structured exploration of the state-of-the-art in LVLMs, systematically organized through a three-step research review process. First, we discuss the functioning of vision language models (VLMs) for object detection, describing how these models harness natural language processing (NLP) and computer vision (CV) techniques to revolutionize object detection and localization. We then explain the architectural innovations, training paradigms, and output flexibility of recent LVLMs for object detection, highlighting how they achieve advanced contextual understanding for object detection. The review thoroughly examines the approaches used in integration of visual and textual information, demonstrating the progress made in object detection using VLMs that facilitate more sophisticated object detection and localization strategies. This review presents comprehensive visualizations demonstrating LVLMs' effectiveness in diverse scenarios including localization and segmentation, and then compares their real-time performance, adaptability, and complexity to traditional deep learning systems. Based on the review, its is expected that LVLMs will soon meet or surpass the performance of conventional methods in object detection. The review also identifies a few major limitations of the current LVLM modes, proposes solutions to address those challenges, and presents a clear roadmap for the future advancement in this field. We conclude, based on this study, that the recent advancement in LVLMs have made and will continue to make a transformative impact on object detection and robotic applications in the future."}}, {"id": "f0fca9799240887c", "url": "http://arxiv.org/abs/2307.13473v1", "title": "Exploring MLOps Dynamics: An Experimental Analysis in a Real-World Machine Learning Project", "description": "This article presents an experiment focused on optimizing the MLOps (Machine Learning Operations) process, a crucial aspect of efficiently implementing machine learning projects. The objective is to identify patterns and insights to enhance the MLOps workflow, considering its iterative and interdependent nature in real-world model development scenarios.\n  The experiment involves a comprehensive MLOps workflow, covering essential phases like problem definition, data acquisition, data preparation,", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["model deployment"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:50.925856Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This article presents an experiment focused on optimizing the MLOps (Machine Learning Operations) process, a crucial aspect of efficiently implementing machine learning projects. The objective is to identify patterns and insights to enhance the MLOps workflow, considering its iterative and interdependent nature in real-world model development scenarios.\n  The experiment involves a comprehensive MLOps workflow, covering essential phases like problem definition, data acquisition, data preparation, model development, model deployment, monitoring, management, scalability, and governance and compliance. Practical tips and recommendations are derived from the results, emphasizing proactive planning and continuous improvement for the MLOps workflow.\n  The experimental investigation was strategically integrated within a real-world ML project which followed essential phases of the MLOps process in a production environment, handling large-scale structured data. A systematic tracking approach was employed to document revisits to specific phases from a main phase under focus, capturing the reasons for such revisits. By constructing a matrix to quantify the degree of overlap between phases, the study unveils the dynamic and iterative nature of the MLOps workflow.\n  The resulting data provides visual representations of the MLOps process's interdependencies and iterative characteristics within the experimental framework, offering valuable insights for optimizing the workflow and making informed decisions in real-world scenarios. This analysis contributes to enhancing the efficiency and effectiveness of machine learning projects through an improved MLOps process.\n  Keywords: MLOps, Machine Learning Operations, Optimization, Experimental Analysis, Iterative Process, Pattern Identification."}}, {"id": "82417e4eb69b25bb", "url": "http://arxiv.org/abs/2405.09819v1", "title": "Automating the Training and Deployment of Models in MLOps by Integrating Systems with Machine Learning", "description": "This article introduces the importance of machine learning in real-world applications and explores the rise of MLOps (Machine Learning Operations) and its importance for solving challenges such as model deployment and performance monitoring. By reviewing the evolution of MLOps and its relationship to traditional software development methods, the paper proposes ways to integrate the system into machine learning to solve the problems faced by existing MLOps and improve productivity. This paper foc", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp", "ai_ethics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["model deployment"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:50.981660Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This article introduces the importance of machine learning in real-world applications and explores the rise of MLOps (Machine Learning Operations) and its importance for solving challenges such as model deployment and performance monitoring. By reviewing the evolution of MLOps and its relationship to traditional software development methods, the paper proposes ways to integrate the system into machine learning to solve the problems faced by existing MLOps and improve productivity. This paper focuses on the importance of automated model training, and the method to ensure the transparency and repeatability of the training process through version control system. In addition, the challenges of integrating machine learning components into traditional CI/CD pipelines are discussed, and solutions such as versioning environments and containerization are proposed. Finally, the paper emphasizes the importance of continuous monitoring and feedback loops after model deployment to maintain model performance and reliability. Using case studies and best practices from Netflix, the article presents key strategies and lessons learned for successful implementation of MLOps practices, providing valuable references for other organizations to build and optimize their own MLOps practices."}}, {"id": "a042599a0c81ab67", "url": "http://arxiv.org/abs/2305.19298v1", "title": "MLOps: A Step Forward to Enterprise Machine Learning", "description": "Machine Learning Operations (MLOps) is becoming a highly crucial part of businesses looking to capitalize on the benefits of AI and ML models. This research presents a detailed review of MLOps, its benefits, difficulties, evolutions, and important underlying technologies such as MLOps frameworks, Docker, GitHub actions, and Kubernetes. The MLOps workflow, which includes model design, deployment, and operations, is explained in detail along with the various tools necessary for both model and data", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp", "computer_vision"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:51.042093Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Machine Learning Operations (MLOps) is becoming a highly crucial part of businesses looking to capitalize on the benefits of AI and ML models. This research presents a detailed review of MLOps, its benefits, difficulties, evolutions, and important underlying technologies such as MLOps frameworks, Docker, GitHub actions, and Kubernetes. The MLOps workflow, which includes model design, deployment, and operations, is explained in detail along with the various tools necessary for both model and data exploration and deployment. This article also puts light on the end-to-end production of ML projects using various maturity levels of automated pipelines, with the least at no automation at all and the highest with complete CI/CD and CT capabilities. Furthermore, a detailed example of an enterprise-level MLOps project for an object detection service is used to explain the workflow of the technology in a real-world scenario. For this purpose, a web application hosting a pre-trained model from TensorFlow 2 Model Zoo is packaged and deployed to the internet making sure that the system is scalable, reliable, and optimized for deployment at an enterprise level."}}, {"id": "fae0fad77a35f6e4", "url": "http://arxiv.org/abs/2205.02302v3", "title": "Machine Learning Operations (MLOps): Overview, Definition, and Architecture", "description": "The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequen", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:51.097315Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we provide an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we furnish a definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies."}}, {"id": "d762d44d4af1c90b", "url": "http://arxiv.org/abs/2503.15577v1", "title": "Navigating MLOps: Insights into Maturity, Lifecycle, Tools, and Careers", "description": "The adoption of Machine Learning Operations (MLOps) enables automation and reliable model deployments across industries. However, differing MLOps lifecycle frameworks and maturity models proposed by industry, academia, and organizations have led to confusion regarding standard adoption practices. This paper introduces a unified MLOps lifecycle framework, further incorporating Large Language Model Operations (LLMOps), to address this gap. Additionally, we outlines key roles, tools, and costs asso", "provider": "arxiv", "domains": ["mlops", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["model deployment"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:51.207106Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The adoption of Machine Learning Operations (MLOps) enables automation and reliable model deployments across industries. However, differing MLOps lifecycle frameworks and maturity models proposed by industry, academia, and organizations have led to confusion regarding standard adoption practices. This paper introduces a unified MLOps lifecycle framework, further incorporating Large Language Model Operations (LLMOps), to address this gap. Additionally, we outlines key roles, tools, and costs associated with MLOps adoption at various maturity levels. By providing a standardized framework, we aim to help organizations clearly define and allocate the resources needed to implement MLOps effectively."}}, {"id": "fd2a7e2bd5b9cb24", "url": "http://arxiv.org/abs/1812.06834v3", "title": "A Tutorial on Deep Latent Variable Models of Natural Language", "description": "There has been much recent, exciting work on combining the complementary strengths of latent variable models and deep learning. Latent variable modeling makes it easy to explicitly specify model constraints through conditional independence properties, while deep learning makes it possible to parameterize these conditional likelihoods with powerful function approximators. While these \"deep latent variable\" models provide a rich, flexible framework for modeling many real-world phenomena, difficult", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:51.264333Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "There has been much recent, exciting work on combining the complementary strengths of latent variable models and deep learning. Latent variable modeling makes it easy to explicitly specify model constraints through conditional independence properties, while deep learning makes it possible to parameterize these conditional likelihoods with powerful function approximators. While these \"deep latent variable\" models provide a rich, flexible framework for modeling many real-world phenomena, difficulties exist: deep parameterizations of conditional likelihoods usually make posterior inference intractable, and latent variable objectives often complicate backpropagation by introducing points of non-differentiability. This tutorial explores these issues in depth through the lens of variational inference."}}, {"id": "e02d868af0a25063", "url": "http://arxiv.org/abs/2407.12036v2", "title": "Exploring Advanced Large Language Models with LLMsuite", "description": "This tutorial explores the advancements and challenges in the development of Large Language Models (LLMs) such as ChatGPT and Gemini. It addresses inherent limitations like temporal knowledge cutoffs, mathematical inaccuracies, and the generation of incorrect information, proposing solutions like Retrieval Augmented Generation (RAG), Program-Aided Language Models (PAL), and frameworks such as ReAct and LangChain. The integration of these techniques enhances LLM performance and reliability, espec", "provider": "arxiv", "domains": ["generative_ai", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["large language models", "RAG", "fine-tuning"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:52.763771Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This tutorial explores the advancements and challenges in the development of Large Language Models (LLMs) such as ChatGPT and Gemini. It addresses inherent limitations like temporal knowledge cutoffs, mathematical inaccuracies, and the generation of incorrect information, proposing solutions like Retrieval Augmented Generation (RAG), Program-Aided Language Models (PAL), and frameworks such as ReAct and LangChain. The integration of these techniques enhances LLM performance and reliability, especially in multi-step reasoning and complex task execution. The paper also covers fine-tuning strategies, including instruction fine-tuning, parameter-efficient methods like LoRA, and Reinforcement Learning from Human Feedback (RLHF) as well as Reinforced Self-Training (ReST). Additionally, it provides a comprehensive survey of transformer architectures and training techniques for LLMs. The source code can be accessed by contacting the author via email for a request."}}, {"id": "7452d547fadb48e4", "url": "http://arxiv.org/abs/2503.21676v2", "title": "How do language models learn facts? Dynamics, curricula and hallucinations", "description": "Large language models accumulate vast knowledge during pre-training, yet the dynamics governing this acquisition remain poorly understood. This work investigates the learning dynamics of language models on a synthetic factual recall task, uncovering three key findings: First, language models learn in three phases, exhibiting a performance plateau before acquiring precise factual knowledge. Mechanistically, this plateau coincides with the formation of attention-based circuits that support recall.", "provider": "arxiv", "domains": ["nlp", "generative_ai"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:52.824665Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Large language models accumulate vast knowledge during pre-training, yet the dynamics governing this acquisition remain poorly understood. This work investigates the learning dynamics of language models on a synthetic factual recall task, uncovering three key findings: First, language models learn in three phases, exhibiting a performance plateau before acquiring precise factual knowledge. Mechanistically, this plateau coincides with the formation of attention-based circuits that support recall. Second, the training data distribution significantly impacts learning dynamics, as imbalanced distributions lead to shorter plateaus. Finally, hallucinations emerge simultaneously with knowledge, and integrating new knowledge into the model through fine-tuning is challenging, as it quickly corrupts its existing parametric memories. Our results emphasize the importance of data distribution in knowledge acquisition and suggest novel data scheduling strategies to accelerate neural network training."}}, {"id": "204d68c9134cf197", "url": "http://arxiv.org/abs/1909.11939v6", "title": "MERL: Multi-Head Reinforcement Learning", "description": "A common challenge in reinforcement learning is how to convert the agent's interactions with an environment into fast and robust learning. For instance, earlier work makes use of domain knowledge to improve existing reinforcement learning algorithms in complex tasks. While promising, previously acquired knowledge is often costly and challenging to scale up. Instead, we decide to consider problem knowledge with signals from quantities relevant to solve any task, e.g., self-performance assessment ", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["policy gradient"], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:53.263655Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "A common challenge in reinforcement learning is how to convert the agent's interactions with an environment into fast and robust learning. For instance, earlier work makes use of domain knowledge to improve existing reinforcement learning algorithms in complex tasks. While promising, previously acquired knowledge is often costly and challenging to scale up. Instead, we decide to consider problem knowledge with signals from quantities relevant to solve any task, e.g., self-performance assessment and accurate expectations. $\\mathcal{V}^{ex}$ is such a quantity. It is the fraction of variance explained by the value function $V$ and measures the discrepancy between $V$ and the returns. Taking advantage of $\\mathcal{V}^{ex}$, we propose MERL, a general framework for structuring reinforcement learning by injecting problem knowledge into policy gradient updates. As a result, the agent is not only optimized for a reward but learns using problem-focused quantities provided by MERL, applicable out-of-the-box to any task. In this paper: (a) We introduce and define MERL, the multi-head reinforcement learning framework we use throughout this work. (b) We conduct experiments across a variety of standard benchmark environments, including 9 continuous control tasks, where results show improved performance. (c) We demonstrate that MERL also improves transfer learning on a set of challenging pixel-based tasks. (d) We ponder how MERL tackles the problem of reward sparsity and better conditions the feature space of reinforcement learning agents."}}, {"id": "2c2b104ee8f75006", "url": "http://arxiv.org/abs/1904.09489v1", "title": "Compression and Localization in Reinforcement Learning for ATARI Games", "description": "Deep neural networks have become commonplace in the domain of reinforcement learning, but are often expensive in terms of the number of parameters needed. While compressing deep neural networks has of late assumed great importance to overcome this drawback, little work has been done to address this problem in the context of reinforcement learning agents. This work aims at making first steps towards model compression in an RL agent. In particular, we compress networks to drastically reduce the nu", "provider": "arxiv", "domains": ["reinforcement_learning", "deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:53.326607Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep neural networks have become commonplace in the domain of reinforcement learning, but are often expensive in terms of the number of parameters needed. While compressing deep neural networks has of late assumed great importance to overcome this drawback, little work has been done to address this problem in the context of reinforcement learning agents. This work aims at making first steps towards model compression in an RL agent. In particular, we compress networks to drastically reduce the number of parameters in them (to sizes less than 3% of their original size), further facilitated by applying a global max pool after the final convolution layer, and propose using Actor-Mimic in the context of compression. Finally, we show that this global max-pool allows for weakly supervised object localization, improving the ability to identify the agent's points of focus."}}, {"id": "d6aba3e232717055", "url": "http://arxiv.org/abs/1912.02877v2", "title": "Training Agents using Upside-Down Reinforcement Learning", "description": "We develop Upside-Down Reinforcement Learning (UDRL), a method for learning to act using only supervised learning techniques. Unlike traditional algorithms, UDRL does not use reward prediction or search for an optimal policy. Instead, it trains agents to follow commands such as \"obtain so much total reward in so much time.\" Many of its general principles are outlined in a companion report; the goal of this paper is to develop a practical learning algorithm and show that this conceptually simple ", "provider": "arxiv", "domains": ["reinforcement_learning", "ai_governance", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "intermediate", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:53.661448Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We develop Upside-Down Reinforcement Learning (UDRL), a method for learning to act using only supervised learning techniques. Unlike traditional algorithms, UDRL does not use reward prediction or search for an optimal policy. Instead, it trains agents to follow commands such as \"obtain so much total reward in so much time.\" Many of its general principles are outlined in a companion report; the goal of this paper is to develop a practical learning algorithm and show that this conceptually simple perspective on agent training can produce a range of rewarding behaviors for multiple episodic environments. Experiments show that on some tasks UDRL's performance can be surprisingly competitive with, and even exceed that of some traditional baseline algorithms developed over decades of research. Based on these results, we suggest that alternative approaches to expected reward maximization have an important role to play in training useful autonomous agents."}}, {"id": "7b92e2dfc6fa7c3e", "url": "http://arxiv.org/abs/2007.05196v1", "title": "Pre-trained Word Embeddings for Goal-conditional Transfer Learning in Reinforcement Learning", "description": "Reinforcement learning (RL) algorithms typically start tabula rasa, without any prior knowledge of the environment, and without any prior skills. This however often leads to low sample efficiency, requiring a large amount of interaction with the environment. This is especially true in a lifelong learning setting, in which the agent needs to continually extend its capabilities. In this paper, we examine how a pre-trained task-independent language model can make a goal-conditional RL agent more sa", "provider": "arxiv", "domains": ["reinforcement_learning", "nlp", "ml_basics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:53.729085Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Reinforcement learning (RL) algorithms typically start tabula rasa, without any prior knowledge of the environment, and without any prior skills. This however often leads to low sample efficiency, requiring a large amount of interaction with the environment. This is especially true in a lifelong learning setting, in which the agent needs to continually extend its capabilities. In this paper, we examine how a pre-trained task-independent language model can make a goal-conditional RL agent more sample efficient. We do this by facilitating transfer learning between different related tasks. We experimentally demonstrate our approach on a set of object navigation tasks."}}, {"id": "708ed270c86ce081", "url": "http://arxiv.org/abs/1705.00470v2", "title": "Learning Multimodal Transition Dynamics for Model-Based Reinforcement Learning", "description": "In this paper we study how to learn stochastic, multimodal transition dynamics in reinforcement learning (RL) tasks. We focus on evaluating transition function estimation, while we defer planning over this model to future work. Stochasticity is a fundamental property of many task environments. However, discriminative function approximators have difficulty estimating multimodal stochasticity. In contrast, deep generative models do capture complex high-dimensional outcome distributions. First we d", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:53.855428Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this paper we study how to learn stochastic, multimodal transition dynamics in reinforcement learning (RL) tasks. We focus on evaluating transition function estimation, while we defer planning over this model to future work. Stochasticity is a fundamental property of many task environments. However, discriminative function approximators have difficulty estimating multimodal stochasticity. In contrast, deep generative models do capture complex high-dimensional outcome distributions. First we discuss why, amongst such models, conditional variational inference (VI) is theoretically most appealing for model-based RL. Subsequently, we compare different VI models on their ability to learn complex stochasticity on simulated functions, as well as on a typical RL gridworld with multimodal dynamics. Results show VI successfully predicts multimodal outcomes, but also robustly ignores these for deterministic parts of the transition dynamics. In summary, we show a robust method to learn multimodal transitions using function approximation, which is a key preliminary for model-based RL in stochastic domains."}}, {"id": "0cc2ae610a80d62c", "url": "http://arxiv.org/abs/1911.11285v1", "title": "Biologically inspired architectures for sample-efficient deep reinforcement learning", "description": "Deep reinforcement learning requires a heavy price in terms of sample efficiency and overparameterization in the neural networks used for function approximation. In this work, we use tensor factorization in order to learn more compact representation for reinforcement learning policies. We show empirically that in the low-data regime, it is possible to learn online policies with 2 to 10 times less total coefficients, with little to no loss of performance. We also leverage progress in second order", "provider": "arxiv", "domains": ["reinforcement_learning", "deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:53.920971Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep reinforcement learning requires a heavy price in terms of sample efficiency and overparameterization in the neural networks used for function approximation. In this work, we use tensor factorization in order to learn more compact representation for reinforcement learning policies. We show empirically that in the low-data regime, it is possible to learn online policies with 2 to 10 times less total coefficients, with little to no loss of performance. We also leverage progress in second order optimization, and use the theory of wavelet scattering to further reduce the number of learned coefficients, by foregoing learning the topmost convolutional layer filters altogether. We evaluate our results on the Atari suite against recent baseline algorithms that represent the state-of-the-art in data efficiency, and get comparable results with an order of magnitude gain in weight parsimony."}}, {"id": "e300f743f7783882", "url": "http://arxiv.org/abs/2509.16679v1", "title": "Reinforcement Learning Meets Large Language Models: A Survey of Advancements and Applications Across the LLM Lifecycle", "description": "In recent years, training methods centered on Reinforcement Learning (RL) have markedly enhanced the reasoning and alignment performance of Large Language Models (LLMs), particularly in understanding human intents, following user instructions, and bolstering inferential strength. Although existing surveys offer overviews of RL augmented LLMs, their scope is often limited, failing to provide a comprehensive summary of how RL operates across the full lifecycle of LLMs. We systematically review the", "provider": "arxiv", "domains": ["reinforcement_learning", "generative_ai", "nlp", "ai_ethics"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:53.983700Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In recent years, training methods centered on Reinforcement Learning (RL) have markedly enhanced the reasoning and alignment performance of Large Language Models (LLMs), particularly in understanding human intents, following user instructions, and bolstering inferential strength. Although existing surveys offer overviews of RL augmented LLMs, their scope is often limited, failing to provide a comprehensive summary of how RL operates across the full lifecycle of LLMs. We systematically review the theoretical and practical advancements whereby RL empowers LLMs, especially Reinforcement Learning with Verifiable Rewards (RLVR). First, we briefly introduce the basic theory of RL. Second, we thoroughly detail application strategies for RL across various phases of the LLM lifecycle, including pre-training, alignment fine-tuning, and reinforced reasoning. In particular, we emphasize that RL methods in the reinforced reasoning phase serve as a pivotal driving force for advancing model reasoning to its limits. Next, we collate existing datasets and evaluation benchmarks currently used for RL fine-tuning, spanning human-annotated datasets, AI-assisted preference data, and program-verification-style corpora. Subsequently, we review the mainstream open-source tools and training frameworks available, providing clear practical references for subsequent research. Finally, we analyse the future challenges and trends in the field of RL-enhanced LLMs. This survey aims to present researchers and practitioners with the latest developments and frontier trends at the intersection of RL and LLMs, with the goal of fostering the evolution of LLMs that are more intelligent, generalizable, and secure."}}, {"id": "0b60a23f51022b31", "url": "http://arxiv.org/abs/1810.05587v3", "title": "A Survey and Critique of Multiagent Deep Reinforcement Learning", "description": "Deep reinforcement learning (RL) has achieved outstanding results in recent years. This has led to a dramatic increase in the number of applications and methods. Recent works have explored learning beyond single-agent scenarios and have considered multiagent learning (MAL) scenarios. Initial results report successes in complex multiagent domains, although there are several challenges to be addressed. The primary goal of this article is to provide a clear overview of current multiagent deep reinf", "provider": "arxiv", "domains": ["reinforcement_learning", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.55, "discovered_at": "2026-02-09T15:39:54.039668Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep reinforcement learning (RL) has achieved outstanding results in recent years. This has led to a dramatic increase in the number of applications and methods. Recent works have explored learning beyond single-agent scenarios and have considered multiagent learning (MAL) scenarios. Initial results report successes in complex multiagent domains, although there are several challenges to be addressed. The primary goal of this article is to provide a clear overview of current multiagent deep reinforcement learning (MDRL) literature. Additionally, we complement the overview with a broader analysis: (i) we revisit previous key components, originally presented in MAL and RL, and highlight how they have been adapted to multiagent deep reinforcement learning settings. (ii) We provide general guidelines to new practitioners in the area: describing lessons learned from MDRL works, pointing to recent benchmarks, and outlining open avenues of research. (iii) We take a more critical tone raising practical challenges of MDRL (e.g., implementation and computational demands). We expect this article will help unify and motivate future research to take advantage of the abundant literature that exists (e.g., RL and MAL) in a joint effort to promote fruitful research in the multiagent community."}}, {"id": "3cd8ceff924a7c68", "url": "https://github.com/dariubs/GoBooks", "title": "dariubs/GoBooks", "description": "List of Golang books", "provider": "github", "domains": [], "content_type": "book", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 1.3, "prerequisites": [], "tags": [], "quality_score": 0.542, "discovered_at": "2026-02-09T15:00:29.352568Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 19119, "language": "Go", "topics": ["awesome", "awesome-go", "awesome-golang", "awesome-list", "awesome-lists", "book", "books", "development", "devops", "go", "go-books", "gobooks", "golang", "golang-books", "list", "resources", "roadmap"], "updated_at": "2026-02-09T14:08:12Z"}}, {"id": "e60d3f47eeb4bebc", "url": "http://arxiv.org/abs/2304.02381v2", "title": "Physics-Inspired Interpretability Of Machine Learning Models", "description": "The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the phys", "provider": "arxiv", "domains": ["ml_basics", "ai_ethics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.541, "discovered_at": "2026-02-09T15:00:29.622592Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences. By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making. Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule. However, no such approach exists for machine learning loss landscapes. We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both synthetic and from the real world, for how these methods can help to make models more interpretable."}}, {"id": "f9b845057c6d6e97", "url": "http://arxiv.org/abs/2406.01548v3", "title": "How to discretize continuous state-action spaces in Q-learning: A symbolic control approach", "description": "Q-learning is widely recognized as an effective approach for synthesizing controllers to achieve specific goals. However, handling challenges posed by continuous state-action spaces remains an ongoing research focus. This paper presents a systematic analysis that highlights a major drawback in space discretization methods. To address this challenge, the paper proposes a symbolic model that represents behavioral relations, such as alternating simulation from abstraction to the controlled system. ", "provider": "arxiv", "domains": ["reinforcement_learning", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["Q-learning"], "quality_score": 0.541, "discovered_at": "2026-02-09T15:00:33.013028Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Q-learning is widely recognized as an effective approach for synthesizing controllers to achieve specific goals. However, handling challenges posed by continuous state-action spaces remains an ongoing research focus. This paper presents a systematic analysis that highlights a major drawback in space discretization methods. To address this challenge, the paper proposes a symbolic model that represents behavioral relations, such as alternating simulation from abstraction to the controlled system. This relation allows for seamless application of the synthesized controller based on abstraction to the original system. Introducing a novel Q-learning technique for symbolic models, the algorithm yields two Q-tables encoding optimal policies. Theoretical analysis demonstrates that these Q-tables serve as both upper and lower bounds on the Q-values of the original system with continuous spaces. Additionally, the paper explores the correlation between the parameters of the space abstraction and the loss in Q-values. The resulting algorithm facilitates achieving optimality within an arbitrary accuracy, providing control over the trade-off between accuracy and computational complexity. The obtained results provide valuable insights for selecting appropriate learning parameters and refining the controller. The engineering relevance of the proposed Q-learning based symbolic model is illustrated through two case studies."}}, {"id": "9c2629126655c0db", "url": "http://arxiv.org/abs/1906.06668v2", "title": "Principles alone cannot guarantee ethical AI", "description": "AI Ethics is now a global topic of discussion in academic and policy circles. At least 84 public-private initiatives have produced statements describing high-level principles, values, and other tenets to guide the ethical development, deployment, and governance of AI. According to recent meta-analyses, AI Ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI", "provider": "arxiv", "domains": ["ai_ethics", "ai_governance", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["privacy", "accountability"], "quality_score": 0.541, "discovered_at": "2026-02-09T15:00:33.635041Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "AI Ethics is now a global topic of discussion in academic and policy circles. At least 84 public-private initiatives have produced statements describing high-level principles, values, and other tenets to guide the ethical development, deployment, and governance of AI. According to recent meta-analyses, AI Ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI Ethics by the connection to principles in medical ethics, there are reasons to be concerned about its future impact on AI development and governance. Significant differences exist between medicine and AI development that suggest a principled approach in the latter may not enjoy success comparable to the former. Compared to medicine, AI development lacks (1) common aims and fiduciary duties, (2) professional history and norms, (3) proven methods to translate principles into practice, and (4) robust legal and professional accountability mechanisms. These differences suggest we should not yet celebrate consensus around high-level principles that hide deep political and normative disagreement."}}, {"id": "f4c9bb95e98fa37f", "url": "https://github.com/MunGell/awesome-for-beginners", "title": "MunGell/awesome-for-beginners", "description": "A list of awesome beginners-friendly projects.", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.8, "prerequisites": [], "tags": [], "quality_score": 0.54, "discovered_at": "2026-02-09T15:00:29.438091Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 82493, "language": null, "topics": ["awesome", "awesome-list", "beginner-project", "beginners-friendly", "list"], "updated_at": "2026-02-09T14:03:25Z"}}, {"id": "cb8f252ccaaf10b0", "url": "https://github.com/modelcontextprotocol/servers", "title": "modelcontextprotocol/servers", "description": "Model Context Protocol Servers", "provider": "github", "domains": ["generative_ai", "reinforcement_learning"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 5.1, "prerequisites": [], "tags": ["large language models", "RAG", "AI agents"], "quality_score": 0.54, "discovered_at": "2026-02-09T15:00:29.461702Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 78328, "language": "TypeScript", "topics": [], "updated_at": "2026-02-09T14:31:46Z"}}, {"id": "56b7830958786e1d", "url": "https://github.com/sdmg15/Best-websites-a-programmer-should-visit", "title": "sdmg15/Best-websites-a-programmer-should-visit", "description": ":link: Some useful websites for programmers.", "provider": "github", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 1.6, "prerequisites": [], "tags": [], "quality_score": 0.539, "discovered_at": "2026-02-09T15:00:29.046381Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 75621, "language": null, "topics": ["books", "cs", "hacktoberfest", "links", "programmer", "sites"], "updated_at": "2026-02-09T14:32:26Z"}}, {"id": "216a655ceb2d3718", "url": "http://arxiv.org/abs/2010.01177v4", "title": "Global Adaptive Filtering Layer for Computer Vision", "description": "We devise a universal adaptive neural layer to \"learn\" optimal frequency filter for each image together with the weights of the base neural network that performs some computer vision task. The proposed approach takes the source image in the spatial domain, automatically selects the best frequencies from the frequency domain, and transmits the inverse-transform image to the main neural network. Remarkably, such a simple add-on layer dramatically improves the performance of the main network regard", "provider": "arxiv", "domains": ["deep_learning", "computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.538, "discovered_at": "2026-02-09T15:00:31.032800Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We devise a universal adaptive neural layer to \"learn\" optimal frequency filter for each image together with the weights of the base neural network that performs some computer vision task. The proposed approach takes the source image in the spatial domain, automatically selects the best frequencies from the frequency domain, and transmits the inverse-transform image to the main neural network. Remarkably, such a simple add-on layer dramatically improves the performance of the main network regardless of its design. We observe that the light networks gain a noticeable boost in the performance metrics; whereas, the training of the heavy ones converges faster when our adaptive layer is allowed to \"learn\" alongside the main architecture. We validate the idea in four classical computer vision tasks: classification, segmentation, denoising, and erasing, considering popular natural and medical data benchmarks."}}, {"id": "03d0e48887047c09", "url": "http://arxiv.org/abs/1906.01101v1", "title": "MEMe: An Accurate Maximum Entropy Method for Efficient Approximations in Large-Scale Machine Learning", "description": "Efficient approximation lies at the heart of large-scale machine learning problems. In this paper, we propose a novel, robust maximum entropy algorithm, which is capable of dealing with hundreds of moments and allows for computationally efficient approximations. We showcase the usefulness of the proposed method, its equivalence to constrained Bayesian variational inference and demonstrate its superiority over existing approaches in two applications, namely, fast log determinant estimation and in", "provider": "arxiv", "domains": ["ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.538, "discovered_at": "2026-02-09T15:18:48.262051Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Efficient approximation lies at the heart of large-scale machine learning problems. In this paper, we propose a novel, robust maximum entropy algorithm, which is capable of dealing with hundreds of moments and allows for computationally efficient approximations. We showcase the usefulness of the proposed method, its equivalence to constrained Bayesian variational inference and demonstrate its superiority over existing approaches in two applications, namely, fast log determinant estimation and information-theoretic Bayesian optimisation."}}, {"id": "375c691182e4b4cc", "url": "http://arxiv.org/abs/1809.09501v1", "title": "Anderson Acceleration for Reinforcement Learning", "description": "Anderson acceleration is an old and simple method for accelerating the computation of a fixed point. However, as far as we know and quite surprisingly, it has never been applied to dynamic programming or reinforcement learning. In this paper, we explain briefly what Anderson acceleration is and how it can be applied to value iteration, this being supported by preliminary experiments showing a significant speed up of convergence, that we critically discuss. We also discuss how this idea could be ", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.535, "discovered_at": "2026-02-09T15:39:53.143374Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Anderson acceleration is an old and simple method for accelerating the computation of a fixed point. However, as far as we know and quite surprisingly, it has never been applied to dynamic programming or reinforcement learning. In this paper, we explain briefly what Anderson acceleration is and how it can be applied to value iteration, this being supported by preliminary experiments showing a significant speed up of convergence, that we critically discuss. We also discuss how this idea could be applied more generally to (deep) reinforcement learning."}}, {"id": "69905fc02537c60a", "url": "http://arxiv.org/abs/0812.4210v1", "title": "A Stochastic Processes Toolkit for Risk Management", "description": "In risk management it is desirable to grasp the essential statistical features of a time series representing a risk factor. This tutorial aims to introduce a number of different stochastic processes that can help in grasping the essential features of risk factors describing different asset classes or behaviors. This paper does not aim at being exhaustive, but gives examples and a feeling for practically implementable models allowing for stylised features in the data. The reader may also use thes", "provider": "arxiv", "domains": ["ai_project_management", "nlp"], "content_type": "tutorial", "difficulty": "intermediate", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["risk management"], "quality_score": 0.533, "discovered_at": "2026-02-09T15:18:54.655770Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In risk management it is desirable to grasp the essential statistical features of a time series representing a risk factor. This tutorial aims to introduce a number of different stochastic processes that can help in grasping the essential features of risk factors describing different asset classes or behaviors. This paper does not aim at being exhaustive, but gives examples and a feeling for practically implementable models allowing for stylised features in the data. The reader may also use these models as building blocks to build more complex models, although for a number of risk management applications the models developed here suffice for the first step in the quantitative analysis. The broad qualitative features addressed here are {fat tails} and {mean reversion}. We give some orientation on the initial choice of a suitable stochastic process and then explain how the process parameters can be estimated based on historical data. Once the process has been calibrated, typically through maximum likelihood estimation, one may simulate the risk factor and build future scenarios for the risky portfolio. On the terminal simulated distribution of the portfolio one may then single out several risk measures, although here we focus on the stochastic processes estimation preceding the simulation of the risk factors Finally, this first survey report focuses on single time series. Correlation or more generally dependence across risk factors, leading to multivariate processes modeling, will be addressed in future work."}}, {"id": "ea21c2b0cf8000d0", "url": "http://arxiv.org/abs/2306.04338v1", "title": "Changing Data Sources in the Age of Machine Learning for Official Statistics", "description": "Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in ", "provider": "arxiv", "domains": ["ml_basics", "nlp", "ai_ethics", "ai_governance"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:29.113687Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics.\n  This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, and public perception. Next, we highlight the repercussions of changing data sources on statistical reporting. These include technical effects such as concept drift, bias, availability, validity, accuracy and completeness, but also the neutrality and potential discontinuation of the statistical offering. We offer a few important precautionary measures, such as enhancing robustness in both data sourcing and statistical techniques, and thorough monitoring. In doing so, machine learning-based official statistics can maintain integrity, reliability, consistency, and relevance in policy-making, decision-making, and public discourse."}}, {"id": "e748a9c136de1ee2", "url": "http://arxiv.org/abs/1807.04970v1", "title": "Analysis Acoustic Features for Acoustic Scene Classification and Score fusion of multi-classification systems applied to DCASE 2016 challenge", "description": "This paper describes an acoustic scene classification method which achieved the 4th ranking result in the IEEE AASP challenge of Detection and Classification of Acoustic Scenes and Events 2016. In order to accomplish the ensuing task, several methods are explored in three aspects: feature extraction, feature transformation, and score fusion for final decision. In the part of feature extraction, several features are investigated for effective acoustic scene classification. For resolving the issue", "provider": "arxiv", "domains": ["ml_basics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.026837Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper describes an acoustic scene classification method which achieved the 4th ranking result in the IEEE AASP challenge of Detection and Classification of Acoustic Scenes and Events 2016. In order to accomplish the ensuing task, several methods are explored in three aspects: feature extraction, feature transformation, and score fusion for final decision. In the part of feature extraction, several features are investigated for effective acoustic scene classification. For resolving the issue that the same sound can be heard in different places, a feature transformation is applied for better separation for classification. From these, several systems based on different feature sets are devised for classification. The final result is determined by fusing the individual systems. The method is demonstrated and validated by the experiment conducted using the Challenge database."}}, {"id": "73efc4df34145eee", "url": "http://arxiv.org/abs/2107.12808v2", "title": "Open-Ended Learning Leads to Generally Capable Agents", "description": "In this work we create agents that can perform well beyond a single, individual task, that exhibit much wider generalisation of behaviour to a massive, rich space of challenges. We define a universe of tasks within an environment domain and demonstrate the ability to train agents that are generally capable across this vast space and beyond. The environment is natively multi-agent, spanning the continuum of competitive, cooperative, and independent games, which are situated within procedurally ge", "provider": "arxiv", "domains": ["reinforcement_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.135759Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this work we create agents that can perform well beyond a single, individual task, that exhibit much wider generalisation of behaviour to a massive, rich space of challenges. We define a universe of tasks within an environment domain and demonstrate the ability to train agents that are generally capable across this vast space and beyond. The environment is natively multi-agent, spanning the continuum of competitive, cooperative, and independent games, which are situated within procedurally generated physical 3D worlds. The resulting space is exceptionally diverse in terms of the challenges posed to agents, and as such, even measuring the learning progress of an agent is an open research problem. We propose an iterative notion of improvement between successive generations of agents, rather than seeking to maximise a singular objective, allowing us to quantify progress despite tasks being incomparable in terms of achievable rewards. We show that through constructing an open-ended learning process, which dynamically changes the training task distributions and training objectives such that the agent never stops learning, we achieve consistent learning of new behaviours. The resulting agent is able to score reward in every one of our humanly solvable evaluation levels, with behaviour generalising to many held-out points in the universe of tasks. Examples of this zero-shot generalisation include good performance on Hide and Seek, Capture the Flag, and Tag. Through analysis and hand-authored probe tasks we characterise the behaviour of our agent, and find interesting emergent heuristic behaviours such as trial-and-error experimentation, simple tool use, option switching, and cooperation. Finally, we demonstrate that the general capabilities of this agent could unlock larger scale transfer of behaviour through cheap finetuning."}}, {"id": "fb70fe5268a6f05d", "url": "http://arxiv.org/abs/1912.06732v2", "title": "On the approximation of rough functions with deep neural networks", "description": "Deep neural networks and the ENO procedure are both efficient frameworks for approximating rough functions. We prove that at any order, the ENO interpolation procedure can be cast as a deep ReLU neural network. This surprising fact enables the transfer of several desirable properties of the ENO procedure to deep neural networks, including its high-order accuracy at approximating Lipschitz functions. Numerical tests for the resulting neural networks show excellent performance for approximating so", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.370305Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep neural networks and the ENO procedure are both efficient frameworks for approximating rough functions. We prove that at any order, the ENO interpolation procedure can be cast as a deep ReLU neural network. This surprising fact enables the transfer of several desirable properties of the ENO procedure to deep neural networks, including its high-order accuracy at approximating Lipschitz functions. Numerical tests for the resulting neural networks show excellent performance for approximating solutions of nonlinear conservation laws and at data compression."}}, {"id": "219b1ee51e04d185", "url": "http://arxiv.org/abs/2502.01654v1", "title": "Predicting concentration levels of air pollutants by transfer learning and recurrent neural network", "description": "Air pollution (AP) poses a great threat to human health, and people are paying more attention than ever to its prediction. Accurate prediction of AP helps people to plan for their outdoor activities and aids protecting human health. In this paper, long-short term memory (LSTM) recurrent neural networks (RNNs) have been used to predict the future concentration of air pollutants (APS) in Macau. Additionally, meteorological data and data on the concentration of APS have been utilized. Moreover, in ", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.471991Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Air pollution (AP) poses a great threat to human health, and people are paying more attention than ever to its prediction. Accurate prediction of AP helps people to plan for their outdoor activities and aids protecting human health. In this paper, long-short term memory (LSTM) recurrent neural networks (RNNs) have been used to predict the future concentration of air pollutants (APS) in Macau. Additionally, meteorological data and data on the concentration of APS have been utilized. Moreover, in Macau, some air quality monitoring stations (AQMSs) have less observed data in quantity, and, at the same time, some AQMSs recorded less observed data of certain types of APS. Therefore, the transfer learning and pre-trained neural networks have been employed to assist AQMSs with less observed data to build a neural network with high prediction accuracy. The experimental sample covers a period longer than 12-year and includes daily measurements from several APS as well as other more classical meteorological values. Records from five stations, four out of them are AQMSs and the remaining one is an automatic weather station, have been prepared from the aforesaid period and eventually underwent to computational intelligence techniques to build and extract a prediction knowledge-based system. As shown by experimentation, LSTM RNNs initialized with transfer learning methods have higher prediction accuracy; it incurred shorter training time than randomly initialized recurrent neural networks."}}, {"id": "2f867a15b4f5e1d7", "url": "http://arxiv.org/abs/1803.02421v2", "title": "Masked Conditional Neural Networks for Audio Classification", "description": "We present the ConditionaL Neural Network (CLNN) and the Masked ConditionaL Neural Network (MCLNN) designed for temporal signal recognition. The CLNN takes into consideration the temporal nature of the sound signal and the MCLNN extends upon the CLNN through a binary mask to preserve the spatial locality of the features and allows an automated exploration of the features combination analogous to hand-crafting the most relevant features for the recognition task. MCLNN has achieved competitive rec", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "reinforcement_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.509246Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We present the ConditionaL Neural Network (CLNN) and the Masked ConditionaL Neural Network (MCLNN) designed for temporal signal recognition. The CLNN takes into consideration the temporal nature of the sound signal and the MCLNN extends upon the CLNN through a binary mask to preserve the spatial locality of the features and allows an automated exploration of the features combination analogous to hand-crafting the most relevant features for the recognition task. MCLNN has achieved competitive recognition accuracies on the GTZAN and the ISMIR2004 music datasets that surpass several state-of-the-art neural network based architectures and hand-crafted methods applied on both datasets."}}, {"id": "7c460b801ebd68e9", "url": "http://arxiv.org/abs/2006.16212v1", "title": "Towards the Study of Morphological Processing of the Tangkhul Language", "description": "There is no or little work on natural language processing of Tangkhul language. The current work is a humble beginning of morphological processing of this language using an unsupervised approach. We use a small corpus collected from different sources of text books, short stories and articles of other topics. Based on the experiments carried out, the morpheme identification task using morphessor gives reasonable and interesting output despite using a small corpus.", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.663467Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "There is no or little work on natural language processing of Tangkhul language. The current work is a humble beginning of morphological processing of this language using an unsupervised approach. We use a small corpus collected from different sources of text books, short stories and articles of other topics. Based on the experiments carried out, the morpheme identification task using morphessor gives reasonable and interesting output despite using a small corpus."}}, {"id": "af03584d9cd46d2d", "url": "http://arxiv.org/abs/2103.14757v1", "title": "An Automated Multiple-Choice Question Generation Using Natural Language Processing Techniques", "description": "Automatic multiple-choice question generation (MCQG) is a useful yet challenging task in Natural Language Processing (NLP). It is the task of automatic generation of correct and relevant questions from textual data. Despite its usefulness, manually creating sizeable, meaningful and relevant questions is a time-consuming and challenging task for teachers. In this paper, we present an NLP-based system for automatic MCQG for Computer-Based Testing Examination (CBTE).We used NLP technique to extract", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.695971Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Automatic multiple-choice question generation (MCQG) is a useful yet challenging task in Natural Language Processing (NLP). It is the task of automatic generation of correct and relevant questions from textual data. Despite its usefulness, manually creating sizeable, meaningful and relevant questions is a time-consuming and challenging task for teachers. In this paper, we present an NLP-based system for automatic MCQG for Computer-Based Testing Examination (CBTE).We used NLP technique to extract keywords that are important words in a given lesson material. To validate that the system is not perverse, five lesson materials were used to check the effectiveness and efficiency of the system. The manually extracted keywords by the teacher were compared to the auto-generated keywords and the result shows that the system was capable of extracting keywords from lesson materials in setting examinable questions. This outcome is presented in a user-friendly interface for easy accessibility."}}, {"id": "4fadafdfd9490046", "url": "http://arxiv.org/abs/2312.04649v1", "title": "PyThaiNLP: Thai Natural Language Processing in Python", "description": "We present PyThaiNLP, a free and open-source natural language processing (NLP) library for Thai language implemented in Python. It provides a wide range of software, models, and datasets for Thai language. We first provide a brief historical context of tools for Thai language prior to the development of PyThaiNLP. We then outline the functionalities it provided as well as datasets and pre-trained language models. We later summarize its development milestones and discuss our experience during its", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.726423Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We present PyThaiNLP, a free and open-source natural language processing (NLP) library for Thai language implemented in Python. It provides a wide range of software, models, and datasets for Thai language. We first provide a brief historical context of tools for Thai language prior to the development of PyThaiNLP. We then outline the functionalities it provided as well as datasets and pre-trained language models. We later summarize its development milestones and discuss our experience during its development. We conclude by demonstrating how industrial and research communities utilize PyThaiNLP in their work. The library is freely available at https://github.com/pythainlp/pythainlp."}}, {"id": "4153472d9fa06ffc", "url": "http://arxiv.org/abs/2504.10335v2", "title": "MorphTok: Morphologically Grounded Tokenization for Indian Languages", "description": "Tokenization is a crucial step in NLP, especially with the rise of large language models (LLMs), impacting downstream performance, computational cost, and efficiency. Existing LLMs rely on the classical Byte-pair Encoding (BPE) algorithm for subword tokenization that greedily merges frequent character bigrams, often leading to segmentation that does not align with linguistically meaningful units. To address this, we propose morphology-aware segmentation as a pre-tokenization step before applying", "provider": "arxiv", "domains": ["nlp", "generative_ai"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:30.943528Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Tokenization is a crucial step in NLP, especially with the rise of large language models (LLMs), impacting downstream performance, computational cost, and efficiency. Existing LLMs rely on the classical Byte-pair Encoding (BPE) algorithm for subword tokenization that greedily merges frequent character bigrams, often leading to segmentation that does not align with linguistically meaningful units. To address this, we propose morphology-aware segmentation as a pre-tokenization step before applying BPE. To facilitate morphology-aware segmentation, we create a novel dataset for Hindi and Marathi, incorporating sandhi splitting to enhance the subword tokenization. Experiments on downstream tasks show that morphologically grounded tokenization improves machine translation and language modeling performance. Additionally, to handle the dependent vowels common in syllable-based writing systems used by Indic languages, we propose Constrained BPE (CBPE), an extension to the standard BPE algorithm incorporating script-specific constraints. In particular, CBPE handles dependent vowels to form a cohesive unit with other characters instead of occurring as a single unit. Our results show that CBPE achieves a 1.68\\% reduction in fertility scores while maintaining comparable or improved downstream performance in machine translation and language modeling, offering a computationally efficient alternative to standard BPE. Moreover, to evaluate segmentation across different tokenization algorithms, we introduce a new human evaluation metric, \\textit{EvalTok}, enabling more human-grounded assessment."}}, {"id": "5405c88567776272", "url": "http://arxiv.org/abs/1402.0859v3", "title": "The Informed Sampler: A Discriminative Approach to Bayesian Inference in Generative Computer Vision Models", "description": "Computer vision is hard because of a large variability in lighting, shape, and texture; in addition the image signal is non-additive due to occlusion. Generative models promised to account for this variability by accurately modelling the image formation process as a function of latent variables with prior beliefs. Bayesian posterior inference could then, in principle, explain the observation. While intuitively appealing, generative models for computer vision have largely failed to deliver on tha", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:31.102851Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Computer vision is hard because of a large variability in lighting, shape, and texture; in addition the image signal is non-additive due to occlusion. Generative models promised to account for this variability by accurately modelling the image formation process as a function of latent variables with prior beliefs. Bayesian posterior inference could then, in principle, explain the observation. While intuitively appealing, generative models for computer vision have largely failed to deliver on that promise due to the difficulty of posterior inference. As a result the community has favoured efficient discriminative approaches. We still believe in the usefulness of generative models in computer vision, but argue that we need to leverage existing discriminative or even heuristic computer vision methods. We implement this idea in a principled way with an \"informed sampler\" and in careful experiments demonstrate it on challenging generative models which contain renderer programs as their components. We concentrate on the problem of inverting an existing graphics rendering engine, an approach that can be understood as \"Inverse Graphics\". The informed sampler, using simple discriminative proposals based on existing computer vision technology, achieves significant improvements of inference."}}, {"id": "be42ca9e49333d20", "url": "http://arxiv.org/abs/1909.02410v3", "title": "Semantic-Aware Scene Recognition", "description": "Scene recognition is currently one of the top-challenging research fields in computer vision. This may be due to the ambiguity between classes: images of several scene classes may share similar objects, which causes confusion among them. The problem is aggravated when images of a particular scene class are notably different. Convolutional Neural Networks (CNNs) have significantly boosted performance in scene recognition, albeit it is still far below from other recognition tasks (e.g., object or ", "provider": "arxiv", "domains": ["computer_vision", "deep_learning"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:31.435786Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Scene recognition is currently one of the top-challenging research fields in computer vision. This may be due to the ambiguity between classes: images of several scene classes may share similar objects, which causes confusion among them. The problem is aggravated when images of a particular scene class are notably different. Convolutional Neural Networks (CNNs) have significantly boosted performance in scene recognition, albeit it is still far below from other recognition tasks (e.g., object or image recognition). In this paper, we describe a novel approach for scene recognition based on an end-to-end multi-modal CNN that combines image and context information by means of an attention module. Context information, in the shape of semantic segmentation, is used to gate features extracted from the RGB image by leveraging on information encoded in the semantic representation: the set of scene objects and stuff, and their relative locations. This gating process reinforces the learning of indicative scene content and enhances scene disambiguation by refocusing the receptive fields of the CNN towards them. Experimental results on four publicly available datasets show that the proposed approach outperforms every other state-of-the-art method while significantly reducing the number of network parameters. All the code and data used along this paper is available at https://github.com/vpulab/Semantic-Aware-Scene-Recognition"}}, {"id": "e59c7b8b2194628e", "url": "http://arxiv.org/abs/2106.13217v3", "title": "Exploring Depth Contribution for Camouflaged Object Detection", "description": "Camouflaged object detection (COD) aims to segment camouflaged objects hiding in the environment, which is challenging due to the similar appearance of camouflaged objects and their surroundings. Research in biology suggests depth can provide useful object localization cues for camouflaged object discovery. In this paper, we study the depth contribution for camouflaged object detection, where the depth maps are generated with existing monocular depth estimation (MDE) methods. Due to the domain g", "provider": "arxiv", "domains": ["computer_vision", "reinforcement_learning"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:31.646509Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Camouflaged object detection (COD) aims to segment camouflaged objects hiding in the environment, which is challenging due to the similar appearance of camouflaged objects and their surroundings. Research in biology suggests depth can provide useful object localization cues for camouflaged object discovery. In this paper, we study the depth contribution for camouflaged object detection, where the depth maps are generated with existing monocular depth estimation (MDE) methods. Due to the domain gap between the MDE dataset and our COD dataset, the generated depth maps are not accurate enough to be directly used. We then introduce two solutions to avoid the noisy depth maps from dominating the training process. Firstly, we present an auxiliary depth estimation branch (\"ADE\"), aiming to regress the depth maps. We find that \"ADE\" is especially necessary for our \"generated depth\" scenario. Secondly, we introduce a multi-modal confidence-aware loss function via a generative adversarial network to weigh the contribution of depth for camouflaged object detection. Our extensive experiments on various camouflaged object detection datasets explain that the existing \"sensor depth\" based RGB-D segmentation techniques work poorly with \"generated depth\", and our proposed two solutions work cooperatively, achieving effective depth contribution exploration for camouflaged object detection."}}, {"id": "38ba961fd499cda5", "url": "http://arxiv.org/abs/2202.10169v2", "title": "Machine Learning Operations: A Survey on MLOps Tool Support", "description": "Machine Learning (ML) has become a fast-growing, trending approach in solution development in practice. Deep Learning (DL) which is a subset of ML, learns using deep neural networks to simulate the human brain. It trains machines to learn techniques and processes individually using computer algorithms, which is also considered to be a role of Artificial Intelligence (AI). In this paper, we study current technical issues related to software development and delivery in organizations that work on M", "provider": "arxiv", "domains": ["ml_basics", "deep_learning", "mlops", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:31.898224Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Machine Learning (ML) has become a fast-growing, trending approach in solution development in practice. Deep Learning (DL) which is a subset of ML, learns using deep neural networks to simulate the human brain. It trains machines to learn techniques and processes individually using computer algorithms, which is also considered to be a role of Artificial Intelligence (AI). In this paper, we study current technical issues related to software development and delivery in organizations that work on ML projects. Therefore, the importance of the Machine Learning Operations (MLOps) concept, which can deliver appropriate solutions for such concerns, is discussed. We investigate commercially available MLOps tool support in software development. The comparison between MLOps tools analyzes the performance of each system and its use cases. Moreover, we examine the features and usability of MLOps tools to identify the most appropriate tool support for given scenarios. Finally, we recognize that there is a shortage in the availability of a fully functional MLOps platform on which processes can be automated by reducing human intervention."}}, {"id": "7a0e993dd0f94c94", "url": "http://arxiv.org/abs/2501.02842v1", "title": "Foundations of GenIR", "description": "The chapter discusses the foundational impact of modern generative AI models on information access (IA) systems. In contrast to traditional AI, the large-scale training and superior data modeling of generative AI models enable them to produce high-quality, human-like responses, which brings brand new opportunities for the development of IA paradigms. In this chapter, we identify and introduce two of them in details, i.e., information generation and information synthesis. Information generation a", "provider": "arxiv", "domains": ["generative_ai"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:32.052246Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The chapter discusses the foundational impact of modern generative AI models on information access (IA) systems. In contrast to traditional AI, the large-scale training and superior data modeling of generative AI models enable them to produce high-quality, human-like responses, which brings brand new opportunities for the development of IA paradigms. In this chapter, we identify and introduce two of them in details, i.e., information generation and information synthesis. Information generation allows AI to create tailored content addressing user needs directly, enhancing user experience with immediate, relevant outputs. Information synthesis leverages the ability of generative AI to integrate and reorganize existing information, providing grounded responses and mitigating issues like model hallucination, which is particularly valuable in scenarios requiring precision and external knowledge. This chapter delves into the foundational aspects of generative models, including architecture, scaling, and training, and discusses their applications in multi-modal scenarios. Additionally, it examines the retrieval-augmented generation paradigm and other methods for corpus modeling and understanding, demonstrating how generative AI can enhance information access systems. It also summarizes potential challenges and fruitful directions for future studies."}}, {"id": "ae13b6bfc876727a", "url": "http://arxiv.org/abs/2504.08817v2", "title": "Exploring utilization of generative AI for research and education in data-driven materials science", "description": "Generative AI has recently had a profound impact on various fields, including daily life, research, and education. To explore its efficient utilization in data-driven materials science, we organized a hackathon -- AIMHack2024 -- in July 2024. In this hackathon, researchers from fields such as materials science, information science, bioinformatics, and condensed matter physics worked together to explore how generative AI can facilitate research and education. Based on the results of the hackathon", "provider": "arxiv", "domains": ["generative_ai"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:32.212046Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Generative AI has recently had a profound impact on various fields, including daily life, research, and education. To explore its efficient utilization in data-driven materials science, we organized a hackathon -- AIMHack2024 -- in July 2024. In this hackathon, researchers from fields such as materials science, information science, bioinformatics, and condensed matter physics worked together to explore how generative AI can facilitate research and education. Based on the results of the hackathon, this paper presents topics related to (1) conducting AI-assisted software trials, (2) building AI tutors for software, and (3) developing GUI applications for software. While generative AI continues to evolve rapidly, this paper provides an early record of its application in data-driven materials science and highlights strategies for integrating AI into research and education."}}, {"id": "c0d8ff32d9ca67cf", "url": "http://arxiv.org/abs/2410.02371v1", "title": "NTU-NPU System for Voice Privacy 2024 Challenge", "description": "In this work, we describe our submissions for the Voice Privacy Challenge 2024. Rather than proposing a novel speech anonymization system, we enhance the provided baselines to meet all required conditions and improve evaluated metrics. Specifically, we implement emotion embedding and experiment with WavLM and ECAPA2 speaker embedders for the B3 baseline. Additionally, we compare different speaker and prosody anonymization techniques. Furthermore, we introduce Mean Reversion F0 for B5, which help", "provider": "arxiv", "domains": ["ai_ethics", "nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:32.299448Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this work, we describe our submissions for the Voice Privacy Challenge 2024. Rather than proposing a novel speech anonymization system, we enhance the provided baselines to meet all required conditions and improve evaluated metrics. Specifically, we implement emotion embedding and experiment with WavLM and ECAPA2 speaker embedders for the B3 baseline. Additionally, we compare different speaker and prosody anonymization techniques. Furthermore, we introduce Mean Reversion F0 for B5, which helps to enhance privacy without a loss in utility. Finally, we explore disentanglement models, namely $\u03b2$-VAE and NaturalSpeech3 FACodec."}}, {"id": "5fcb1dcbcbc18c43", "url": "http://arxiv.org/abs/2504.19056v1", "title": "Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions", "description": "Generative AI is reshaping art, gaming, and most notably animation. Recent breakthroughs in foundation and diffusion models have reduced the time and cost of producing animated content. Characters are central animation components, involving motion, emotions, gestures, and facial expressions. The pace and breadth of advances in recent months make it difficult to maintain a coherent view of the field, motivating the need for an integrative review. Unlike earlier overviews that treat avatars, gestu", "provider": "arxiv", "domains": ["generative_ai"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:32.377097Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Generative AI is reshaping art, gaming, and most notably animation. Recent breakthroughs in foundation and diffusion models have reduced the time and cost of producing animated content. Characters are central animation components, involving motion, emotions, gestures, and facial expressions. The pace and breadth of advances in recent months make it difficult to maintain a coherent view of the field, motivating the need for an integrative review. Unlike earlier overviews that treat avatars, gestures, or facial animation in isolation, this survey offers a single, comprehensive perspective on all the main generative AI applications for character animation. We begin by examining the state-of-the-art in facial animation, expression rendering, image synthesis, avatar creation, gesture modeling, motion synthesis, object generation, and texture synthesis. We highlight leading research, practical deployments, commonly used datasets, and emerging trends for each area. To support newcomers, we also provide a comprehensive background section that introduces foundational models and evaluation metrics, equipping readers with the knowledge needed to enter the field. We discuss open challenges and map future research directions, providing a roadmap to advance AI-driven character-animation technologies. This survey is intended as a resource for researchers and developers entering the field of generative AI animation or adjacent fields. Resources are available at: https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey."}}, {"id": "faff2e82fc483822", "url": "http://arxiv.org/abs/2402.11651v2", "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents", "description": "Large language models (LLMs) have achieved success in acting as agents, which interact with environments through tools such as search engines. However, LLMs are optimized for language generation instead of tool use during training or alignment, limiting their effectiveness as agents. To resolve this problem, previous work has first collected interaction trajectories between LLMs and environments, using only trajectories that successfully finished the task to fine-tune smaller models, making fine", "provider": "arxiv", "domains": ["generative_ai", "nlp", "ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:32.500299Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Large language models (LLMs) have achieved success in acting as agents, which interact with environments through tools such as search engines. However, LLMs are optimized for language generation instead of tool use during training or alignment, limiting their effectiveness as agents. To resolve this problem, previous work has first collected interaction trajectories between LLMs and environments, using only trajectories that successfully finished the task to fine-tune smaller models, making fine-tuning data scarce and acquiring it both difficult and costly. Discarding failed trajectories also leads to significant wastage of data and resources and limits the possible optimization paths during fine-tuning. In this paper, we argue that unsuccessful trajectories offer valuable insights, and LLMs can learn from these trajectories through appropriate quality control and fine-tuning strategies. By simply adding a prefix or suffix that tells the model whether to generate a successful trajectory during training, we improve model performance by a large margin on mathematical reasoning, multi-hop question answering, and strategic question answering tasks. We further analyze the inference results and find that our method provides a better trade-off between valuable information and errors in unsuccessful trajectories. To our knowledge, we are the first to demonstrate the value of negative trajectories and their application in agent-tunning scenarios. Our findings offer guidance for developing better agent-tuning methods and low-resource data usage techniques."}}, {"id": "3fe577f6e2e2ec54", "url": "http://arxiv.org/abs/2312.10793v3", "title": "Demystifying Instruction Mixing for Fine-tuning Large Language Models", "description": "Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP downstream tasks, coding, and general chat. We explore the effects of instruction tuning on different combinations of datasets on LLM performance, and find that certain instruction types are more advant", "provider": "arxiv", "domains": ["generative_ai", "nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:32.538271Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP downstream tasks, coding, and general chat. We explore the effects of instruction tuning on different combinations of datasets on LLM performance, and find that certain instruction types are more advantageous for specific applications but can negatively impact other areas. This work provides insights into instruction mixtures, laying the foundations for future research."}}, {"id": "6437037bfb7f0e80", "url": "http://arxiv.org/abs/2302.10816v1", "title": "Tailoring Requirements Engineering for Responsible AI", "description": "Requirements Engineering (RE) is the discipline for identifying, analyzing, as well as ensuring the implementation and delivery of user, technical, and societal requirements. Recently reported issues concerning the acceptance of Artificial Intelligence (AI) solutions after deployment, e.g. in the medical, automotive, or scientific domains, stress the importance of RE for designing and delivering Responsible AI systems. In this paper, we argue that RE should not only be carefully conducted but al", "provider": "arxiv", "domains": ["ai_ethics", "ai_project_management"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:33.121341Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Requirements Engineering (RE) is the discipline for identifying, analyzing, as well as ensuring the implementation and delivery of user, technical, and societal requirements. Recently reported issues concerning the acceptance of Artificial Intelligence (AI) solutions after deployment, e.g. in the medical, automotive, or scientific domains, stress the importance of RE for designing and delivering Responsible AI systems. In this paper, we argue that RE should not only be carefully conducted but also tailored for Responsible AI. We outline related challenges for research and practice."}}, {"id": "9c8aabbc2042ee16", "url": "http://arxiv.org/abs/2308.12400v1", "title": "Towards The Ultimate Brain: Exploring Scientific Discovery with ChatGPT AI", "description": "This paper presents a novel approach to scientific discovery using an artificial intelligence (AI) environment known as ChatGPT, developed by OpenAI. This is the first paper entirely generated with outputs from ChatGPT. We demonstrate how ChatGPT can be instructed through a gamification environment to define and benchmark hypothetical physical theories. Through this environment, ChatGPT successfully simulates the creation of a new improved model, called GPT$^4$, which combines the concepts of GP", "provider": "arxiv", "domains": ["generative_ai", "reinforcement_learning", "nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:33.390702Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper presents a novel approach to scientific discovery using an artificial intelligence (AI) environment known as ChatGPT, developed by OpenAI. This is the first paper entirely generated with outputs from ChatGPT. We demonstrate how ChatGPT can be instructed through a gamification environment to define and benchmark hypothetical physical theories. Through this environment, ChatGPT successfully simulates the creation of a new improved model, called GPT$^4$, which combines the concepts of GPT in AI (generative pretrained transformer) and GPT in physics (generalized probabilistic theory). We show that GPT$^4$ can use its built-in mathematical and statistical capabilities to simulate and analyze physical laws and phenomena. As a demonstration of its language capabilities, GPT$^4$ also generates a limerick about itself. Overall, our results demonstrate the promising potential for human-AI collaboration in scientific discovery, as well as the importance of designing systems that effectively integrate AI's capabilities with human intelligence."}}, {"id": "bd00aab94075c161", "url": "http://arxiv.org/abs/2511.21975v1", "title": "The Risk-Adjusted Intelligence Dividend: A Quantitative Framework for Measuring AI Return on Investment Integrating ISO 42001 and Regulatory Exposure", "description": "Organizations investing in artificial intelligence face a fundamental challenge: traditional return on investment calculations fail to capture the dual nature of AI implementations, which simultaneously reduce certain operational risks while introducing novel exposures related to algorithmic malfunction, adversarial attacks, and regulatory liability. This research presents a comprehensive financial framework for quantifying AI project returns that explicitly integrates changes in organizational ", "provider": "arxiv", "domains": ["ai_roi"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:34.006959Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Organizations investing in artificial intelligence face a fundamental challenge: traditional return on investment calculations fail to capture the dual nature of AI implementations, which simultaneously reduce certain operational risks while introducing novel exposures related to algorithmic malfunction, adversarial attacks, and regulatory liability. This research presents a comprehensive financial framework for quantifying AI project returns that explicitly integrates changes in organizational risk profiles. The methodology addresses a critical gap in current practice where investment decisions rely on optimistic benefit projections without accounting for the probabilistic costs of AI-specific threats including model drift, bias-related litigation, and compliance failures under emerging regulations such as the European Union Artificial Intelligence Act and ISO/IEC 42001. Drawing on established risk quantification methods, including annual loss expectancy calculations and Monte Carlo simulation techniques, this framework enables practitioners to compute net benefits that incorporate both productivity gains and the delta between pre-implementation and post-implementation risk exposures. The analysis demonstrates that accurate AI investment evaluation requires explicit modeling of control effectiveness, reserve requirements for algorithmic failures, and the ongoing operational costs of maintaining model performance. Practical implications include specific guidance for establishing governance structures, conducting phased validations, and integrating risk-adjusted metrics into capital allocation decisions, ultimately enabling evidence-based AI portfolio management that satisfies both fiduciary responsibilities and regulatory mandates."}}, {"id": "25a1f05617e698c7", "url": "http://arxiv.org/abs/2309.13057v3", "title": "The Return on Investment in AI Ethics: A Holistic Framework", "description": "We propose a Holistic Return on Ethics (HROE) framework for understanding the return on organizational investments in artificial intelligence (AI) ethics efforts. This framework is useful for organizations that wish to quantify the return for their investment decisions. The framework identifies the direct economic returns of such investments, the indirect paths to return through intangibles associated with organizational reputation, and real options associated with capabilities. The holistic fra", "provider": "arxiv", "domains": ["ai_ethics", "ai_roi"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:34.047293Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We propose a Holistic Return on Ethics (HROE) framework for understanding the return on organizational investments in artificial intelligence (AI) ethics efforts. This framework is useful for organizations that wish to quantify the return for their investment decisions. The framework identifies the direct economic returns of such investments, the indirect paths to return through intangibles associated with organizational reputation, and real options associated with capabilities. The holistic framework ultimately provides organizations with the competency to employ and justify AI ethics investments."}}, {"id": "b3fee3fe12046032", "url": "http://arxiv.org/abs/2112.03171v1", "title": "The Cost-Benefit Fallacy: Why Cost-Benefit Analysis Is Broken and How to Fix It", "description": "Most cost-benefit analyses assume that the estimates of costs and benefits are more or less accurate and unbiased. But what if, in reality, estimates are highly inaccurate and biased? Then the assumption that cost-benefit analysis is a rational way to improve resource allocation would be a fallacy. Based on the largest dataset of its kind, we test the assumption that cost and benefit estimates of public investments are accurate and unbiased. We find this is not the case with overwhelming statist", "provider": "arxiv", "domains": ["ai_roi"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:34.098205Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Most cost-benefit analyses assume that the estimates of costs and benefits are more or less accurate and unbiased. But what if, in reality, estimates are highly inaccurate and biased? Then the assumption that cost-benefit analysis is a rational way to improve resource allocation would be a fallacy. Based on the largest dataset of its kind, we test the assumption that cost and benefit estimates of public investments are accurate and unbiased. We find this is not the case with overwhelming statistical significance. We document the extent of cost overruns, benefit shortfalls, and forecasting bias in public investments. We further assess whether such inaccuracies seriously distort effective resource allocation, which is found to be the case. We explain our findings in behavioral terms and explore their policy implications. Finally, we conclude that cost-benefit analysis of public investments stands in need of reform and we outline four steps to such reform."}}, {"id": "4b28d484a302b135", "url": "http://arxiv.org/abs/2601.17191v1", "title": "The Global Majority in International AI Governance", "description": "This chapter examines the global governance of artificial intelligence (AI) through the lens of the Global AI Divide, focusing on disparities in AI development, innovation, and regulation. It highlights systemic inequities in education, digital infrastructure, and access to decision-making processes, perpetuating a dependency and exclusion cycle for Global Majority countries. The analysis also explores the dominance of Western nations and corporations in shaping AI governance frameworks, which o", "provider": "arxiv", "domains": ["ai_governance"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:34.214643Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This chapter examines the global governance of artificial intelligence (AI) through the lens of the Global AI Divide, focusing on disparities in AI development, innovation, and regulation. It highlights systemic inequities in education, digital infrastructure, and access to decision-making processes, perpetuating a dependency and exclusion cycle for Global Majority countries. The analysis also explores the dominance of Western nations and corporations in shaping AI governance frameworks, which often sideline the unique priorities and contexts of the Global Majority. Additionally, this chapter identifies emerging countertrends, such as national and regional AI strategies, as potential avenues for fostering equity and inclusivity in global AI governance. The chapter concludes with actionable recommendations to democratize AI governance for Majority World countries, emphasizing the importance of systemic reforms, resource redistribution, and meaningful participation. It calls for collaborative action to ensure AI governance becomes a catalyst for shared prosperity, addressing global disparities rather than deepening them."}}, {"id": "4bf9989f06051718", "url": "http://arxiv.org/abs/2008.03775v1", "title": "Tactics for Internal Compliance: A Literature Review", "description": "Compliance of organizations with internal and external norms is a highly relevant topic for both practitioners and academics nowadays. However, the substantive, elementary compliance tactics that organizations can use for achieving internal compliance have been described in a fragmented manner and in the literatures of distinct academic disciplines. Using a multidisciplinary structured literature review of 134 publications, this study offers three contributions. First, we present a typology of 4", "provider": "arxiv", "domains": ["ai_governance"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:00:34.378317Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Compliance of organizations with internal and external norms is a highly relevant topic for both practitioners and academics nowadays. However, the substantive, elementary compliance tactics that organizations can use for achieving internal compliance have been described in a fragmented manner and in the literatures of distinct academic disciplines. Using a multidisciplinary structured literature review of 134 publications, this study offers three contributions. First, we present a typology of 45 compliance tactics, which constitutes a comprehensive and rich overview of elementary ways for bringing the organization into compliance. Secondly, we provide an overview of fundamental concepts in the theory of compliance, which forms the basis for the framework we developed for positioning compliance tactics and for analyzing or developing compliance strategies. Thirdly, we present insights for moving from compliance tactics to compliance strategies. In the process, and using the multidisciplinary literature review to take a bird's-eye view, we demonstrate that compliance strategies need to be regarded as a richer concept than perceived hitherto. We also show that opportunities for innovation exist."}}, {"id": "4dfa690a3642db0c", "url": "http://arxiv.org/abs/2305.15425v2", "title": "Language Model Tokenizers Introduce Unfairness Between Languages", "description": "Recent language models have shown impressive multilingual performance, even when not explicitly trained for it. Despite this, there are concerns about the quality of their outputs across different languages. In this paper, we show how disparity in the treatment of different languages arises at the tokenization stage, well before a model is even invoked. The same text translated into different languages can have drastically different tokenization lengths, with differences up to 15 times in some c", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:48.734727Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Recent language models have shown impressive multilingual performance, even when not explicitly trained for it. Despite this, there are concerns about the quality of their outputs across different languages. In this paper, we show how disparity in the treatment of different languages arises at the tokenization stage, well before a model is even invoked. The same text translated into different languages can have drastically different tokenization lengths, with differences up to 15 times in some cases. These disparities persist even for tokenizers that are intentionally trained for multilingual support. Character-level and byte-level models also exhibit over 4 times the difference in the encoding length for some language pairs. This induces unfair treatment for some language communities in regard to the cost of accessing commercial language services, the processing time and latency, as well as the amount of content that can be provided as context to the models. Therefore, we make the case that we should train future language models using multilingually fair subword tokenizers."}}, {"id": "14e686ff2e06d9fc", "url": "http://arxiv.org/abs/2406.09737v2", "title": "A Multivocal Review of MLOps Practices, Challenges and Open Issues", "description": "MLOps has emerged as a key solution to address many socio-technical challenges of bringing ML models to production, such as integrating ML models with non-ML software, continuous monitoring, maintenance, and retraining of deployed models. Despite the utility of MLOps, an integrated body of knowledge regarding MLOps remains elusive because of its extensive scope due to the diversity of ML productionalization challenges it addresses. Whilst the existing literature reviews provide valuable snapshot", "provider": "arxiv", "domains": ["mlops"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:49.389099Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "MLOps has emerged as a key solution to address many socio-technical challenges of bringing ML models to production, such as integrating ML models with non-ML software, continuous monitoring, maintenance, and retraining of deployed models. Despite the utility of MLOps, an integrated body of knowledge regarding MLOps remains elusive because of its extensive scope due to the diversity of ML productionalization challenges it addresses. Whilst the existing literature reviews provide valuable snapshots of specific practices, tools, and research prototypes related to MLOps at various times, they focus on particular facets of MLOps, thus fail to offer a comprehensive and invariant framework that can weave these perspectives into a unified understanding of MLOps. This paper presents a Multivocal Literature Review that systematically analyzes a corpus of 150 peer-reviewed and 48 grey literature to synthesize a unified conceptualization of MLOps and develop a snapshot of its best practices, adoption challenges, and solutions."}}, {"id": "2728858c176b0ebe", "url": "http://arxiv.org/abs/2302.01061v1", "title": "MLOps with enhanced performance control and observability", "description": "The explosion of data and its ever increasing complexity in the last few years, has made MLOps systems more prone to failure, and new tools need to be embedded in such systems to avoid such failure. In this demo, we will introduce crucial tools in the observability module of a MLOps system that target difficult issues like data drfit and model version control for optimum model selection. We believe integrating these features in our MLOps pipeline would go a long way in building a robust system i", "provider": "arxiv", "domains": ["mlops"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:49.524916Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The explosion of data and its ever increasing complexity in the last few years, has made MLOps systems more prone to failure, and new tools need to be embedded in such systems to avoid such failure. In this demo, we will introduce crucial tools in the observability module of a MLOps system that target difficult issues like data drfit and model version control for optimum model selection. We believe integrating these features in our MLOps pipeline would go a long way in building a robust system immune to early stage ML system failures."}}, {"id": "32b62441fef7c002", "url": "http://arxiv.org/abs/2111.06053v1", "title": "Improving Large-scale Language Models and Resources for Filipino", "description": "In this paper, we improve on existing language resources for the low-resource Filipino language in two ways. First, we outline the construction of the TLUnified dataset, a large-scale pretraining corpus that serves as an improvement over smaller existing pretraining datasets for the language in terms of scale and topic variety. Second, we pretrain new Transformer language models following the RoBERTa pretraining technique to supplant existing models trained with small corpora. Our new RoBERTa mo", "provider": "arxiv", "domains": ["nlp", "deep_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:50.508920Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this paper, we improve on existing language resources for the low-resource Filipino language in two ways. First, we outline the construction of the TLUnified dataset, a large-scale pretraining corpus that serves as an improvement over smaller existing pretraining datasets for the language in terms of scale and topic variety. Second, we pretrain new Transformer language models following the RoBERTa pretraining technique to supplant existing models trained with small corpora. Our new RoBERTa models show significant improvements over existing Filipino models in three benchmark datasets with an average gain of 4.47% test accuracy across the three classification tasks of varying difficulty."}}, {"id": "44407168ffd0b8c4", "url": "http://arxiv.org/abs/2405.10385v2", "title": "AmazUtah_NLP at SemEval-2024 Task 9: A MultiChoice Question Answering System for Commonsense Defying Reasoning", "description": "The SemEval 2024 BRAINTEASER task represents a pioneering venture in Natural Language Processing (NLP) by focusing on lateral thinking, a dimension of cognitive reasoning that is often overlooked in traditional linguistic analyses. This challenge comprises of Sentence Puzzle and Word Puzzle subtasks and aims to test language models' capacity for divergent thinking.\n  In this paper, we present our approach to the BRAINTEASER task. We employ a holistic strategy by leveraging cutting-edge pre-train", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:52.377884Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The SemEval 2024 BRAINTEASER task represents a pioneering venture in Natural Language Processing (NLP) by focusing on lateral thinking, a dimension of cognitive reasoning that is often overlooked in traditional linguistic analyses. This challenge comprises of Sentence Puzzle and Word Puzzle subtasks and aims to test language models' capacity for divergent thinking.\n  In this paper, we present our approach to the BRAINTEASER task. We employ a holistic strategy by leveraging cutting-edge pre-trained models in multiple choice architecture, and diversify the training data with Sentence and Word Puzzle datasets. To gain further improvement, we fine-tuned the model with synthetic humor or jokes dataset and the RiddleSense dataset which helped augmenting the model's lateral thinking abilities. Empirical results show that our approach achieve 92.5% accuracy in Sentence Puzzle subtask and 80.2% accuracy in Word Puzzle subtask."}}, {"id": "e2d4f277f68c80fd", "url": "http://arxiv.org/abs/2109.05658v1", "title": "Measurement as governance in and for responsible AI", "description": "Measurement of social phenomena is everywhere, unavoidably, in sociotechnical systems. This is not (only) an academic point: Fairness-related harms emerge when there is a mismatch in the measurement process between the thing we purport to be measuring and the thing we actually measure. However, the measurement process -- where social, cultural, and political values are implicitly encoded in sociotechnical systems -- is almost always obscured. Furthermore, this obscured process is where important", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:52.881743Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Measurement of social phenomena is everywhere, unavoidably, in sociotechnical systems. This is not (only) an academic point: Fairness-related harms emerge when there is a mismatch in the measurement process between the thing we purport to be measuring and the thing we actually measure. However, the measurement process -- where social, cultural, and political values are implicitly encoded in sociotechnical systems -- is almost always obscured. Furthermore, this obscured process is where important governance decisions are encoded: governance about which systems are fair, which individuals belong in which categories, and so on. We can then use the language of measurement, and the tools of construct validity and reliability, to uncover hidden governance decisions. In particular, we highlight two types of construct validity, content validity and consequential validity, that are useful to elicit and characterize the feedback loops between the measurement, social construction, and enforcement of social categories. We then explore the constructs of fairness, robustness, and responsibility in the context of governance in and for responsible AI. Together, these perspectives help us unpack how measurement acts as a hidden governance process in sociotechnical systems. Understanding measurement as governance supports a richer understanding of the governance processes already happening in AI -- responsible or otherwise -- revealing paths to more effective interventions."}}, {"id": "b3875a83a4475509", "url": "http://arxiv.org/abs/2101.11832v2", "title": "Making Responsible AI the Norm rather than the Exception", "description": "This report prepared by the Montreal AI Ethics Institute provides recommendations in response to the National Security Commission on Artificial Intelligence (NSCAI) Key Considerations for Responsible Development and Fielding of Artificial Intelligence document. The report centres on the idea that Responsible AI should be made the Norm rather than an Exception. It does so by utilizing the guiding principles of: (1) alleviating friction in existing workflows, (2) empowering stakeholders to get buy", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:53.031261Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This report prepared by the Montreal AI Ethics Institute provides recommendations in response to the National Security Commission on Artificial Intelligence (NSCAI) Key Considerations for Responsible Development and Fielding of Artificial Intelligence document. The report centres on the idea that Responsible AI should be made the Norm rather than an Exception. It does so by utilizing the guiding principles of: (1) alleviating friction in existing workflows, (2) empowering stakeholders to get buy-in, and (3) conducting an effective translation of abstract standards into actionable engineering practices. After providing some overarching comments on the document from the NSCAI, the report dives into the primary contribution of an actionable framework to help operationalize the ideas presented in the document from the NSCAI. The framework consists of: (1) a learning, knowledge, and information exchange (LKIE), (2) the Three Ways of Responsible AI, (3) an empirically-driven risk-prioritization matrix, and (4) achieving the right level of complexity. All components reinforce each other to move from principles to practice in service of making Responsible AI the norm rather than the exception."}}, {"id": "1b60dbfe151128ac", "url": "http://arxiv.org/abs/2202.00125v1", "title": "Top Ten Behavioral Biases in Project Management: An Overview", "description": "Behavioral science has witnessed an explosion in the number of biases identified by behavioral scientists, to more than 200 at present. This article identifies the 10 most important behavioral biases for project management. First, we argue it is a mistake to equate behavioral bias with cognitive bias, as is common. Cognitive bias is half the story; political bias the other half. Second, we list the top 10 behavioral biases in project management: (1) strategic misrepresentation, (2) optimism bias", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:53.598595Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Behavioral science has witnessed an explosion in the number of biases identified by behavioral scientists, to more than 200 at present. This article identifies the 10 most important behavioral biases for project management. First, we argue it is a mistake to equate behavioral bias with cognitive bias, as is common. Cognitive bias is half the story; political bias the other half. Second, we list the top 10 behavioral biases in project management: (1) strategic misrepresentation, (2) optimism bias, (3) uniqueness bias, (4) the planning fallacy, (5) overconfidence bias, (6) hindsight bias, (7) availability bias, (8) the base rate fallacy, (9) anchoring, and (10) escalation of commitment. Each bias is defined, and its impacts on project management are explained, with examples. Third, base rate neglect is identified as a primary reason that projects underperform. This is supported by presentation of the most comprehensive set of base rates that exist in project management scholarship, from 2,062 projects. Finally, recent findings of power law outcomes in project performance are identified as a possible first stage in discovering a general theory of project management, with more fundamental and more scientific explanations of project outcomes than found in conventional theory."}}, {"id": "21053ea17907d0af", "url": "http://arxiv.org/abs/2210.08984v1", "title": "AI Governance and Ethics Framework for Sustainable AI and Sustainability", "description": "AI is transforming the existing technology landscape at a rapid phase enabling data-informed decision making and autonomous decision making. Unlike any other technology, because of the decision-making ability of AI, ethics and governance became a key concern. There are many emerging AI risks for humanity, such as autonomous weapons, automation-spurred job loss, socio-economic inequality, bias caused by data and algorithms, privacy violations and deepfakes. Social diversity, equity and inclusion ", "provider": "arxiv", "domains": ["ai_ethics", "ai_governance"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:18:54.439029Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "AI is transforming the existing technology landscape at a rapid phase enabling data-informed decision making and autonomous decision making. Unlike any other technology, because of the decision-making ability of AI, ethics and governance became a key concern. There are many emerging AI risks for humanity, such as autonomous weapons, automation-spurred job loss, socio-economic inequality, bias caused by data and algorithms, privacy violations and deepfakes. Social diversity, equity and inclusion are considered key success factors of AI to mitigate risks, create values and drive social justice. Sustainability became a broad and complex topic entangled with AI. Many organizations (government, corporate, not-for-profits, charities and NGOs) have diversified strategies driving AI for business optimization and social-and-environmental justice. Partnerships and collaborations become important more than ever for equity and inclusion of diversified and distributed people, data and capabilities. Therefore, in our journey towards an AI-enabled sustainable future, we need to address AI ethics and governance as a priority. These AI ethics and governance should be underpinned by human ethics."}}, {"id": "c236133d6bbd45db", "url": "http://arxiv.org/abs/1807.02477v1", "title": "Development of a sensory-neural network for medical diagnosing", "description": "Performance of a sensory-neural network developed for diagnosing of diseases is described. Information about patient's condition is provided by answers to the questionnaire. Questions correspond to sensors generating signals when patients acknowledge symptoms. These signals excite neurons in which characteristics of the diseases are represented by synaptic weights associated with indicators of symptoms. The disease corresponding to the most excited neuron is proposed as the result of diagnosing.", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:46.740116Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Performance of a sensory-neural network developed for diagnosing of diseases is described. Information about patient's condition is provided by answers to the questionnaire. Questions correspond to sensors generating signals when patients acknowledge symptoms. These signals excite neurons in which characteristics of the diseases are represented by synaptic weights associated with indicators of symptoms. The disease corresponding to the most excited neuron is proposed as the result of diagnosing. Its reliability is estimated by the likelihood defined by the ratio of excitation of the most excited neuron and the complete neural network."}}, {"id": "fb649a0702b09c49", "url": "http://arxiv.org/abs/2304.09590v1", "title": "Parallel Neural Networks in Golang", "description": "This paper describes the design and implementation of parallel neural networks (PNNs) with the novel programming language Golang. We follow in our approach the classical Single-Program Multiple-Data (SPMD) model where a PNN is composed of several sequential neural networks, which are trained with a proportional share of the training dataset. We used for this purpose the MNIST dataset, which contains binary images of handwritten digits. Our analysis focusses on different activation functions and ", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:46.839933Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper describes the design and implementation of parallel neural networks (PNNs) with the novel programming language Golang. We follow in our approach the classical Single-Program Multiple-Data (SPMD) model where a PNN is composed of several sequential neural networks, which are trained with a proportional share of the training dataset. We used for this purpose the MNIST dataset, which contains binary images of handwritten digits. Our analysis focusses on different activation functions and optimizations in the form of stochastic gradients and initialization of weights and biases. We conduct a thorough performance analysis, where network configurations and different performance factors are analyzed and interpreted. Golang and its inherent parallelization support proved very well for parallel neural network simulation by considerable decreased processing times compared to sequential variants."}}, {"id": "e93be84731f52655", "url": "http://arxiv.org/abs/2307.10652v5", "title": "Exploring the Landscape of Natural Language Processing Research", "description": "As an efficient approach to understand, generate, and process natural language texts, research in natural language processing (NLP) has exhibited a rapid spread and wide adoption in recent years. Given the increasing research work in this area, several NLP-related approaches have been surveyed in the research community. However, a comprehensive study that categorizes established topics, identifies trends, and outlines areas for future research remains absent. Contributing to closing this gap, we", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:47.388340Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "As an efficient approach to understand, generate, and process natural language texts, research in natural language processing (NLP) has exhibited a rapid spread and wide adoption in recent years. Given the increasing research work in this area, several NLP-related approaches have been surveyed in the research community. However, a comprehensive study that categorizes established topics, identifies trends, and outlines areas for future research remains absent. Contributing to closing this gap, we have systematically classified and analyzed research papers in the ACL Anthology. As a result, we present a structured overview of the research landscape, provide a taxonomy of fields of study in NLP, analyze recent developments in NLP, summarize our findings, and highlight directions for future work."}}, {"id": "b140c79d311ff978", "url": "http://arxiv.org/abs/2403.13369v2", "title": "Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting", "description": "Automatic extraction of medical information from clinical documents poses several challenges: high costs of required clinical expertise, limited interpretability of model predictions, restricted computational resources and privacy regulations. Recent advances in domain-adaptation and prompting methods showed promising results with minimal training data using lightweight masked language models, which are suited for well-established interpretability methods. We are first to present a systematic ev", "provider": "arxiv", "domains": ["ai_ethics", "nlp"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:47.589775Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Automatic extraction of medical information from clinical documents poses several challenges: high costs of required clinical expertise, limited interpretability of model predictions, restricted computational resources and privacy regulations. Recent advances in domain-adaptation and prompting methods showed promising results with minimal training data using lightweight masked language models, which are suited for well-established interpretability methods. We are first to present a systematic evaluation of these methods in a low-resource setting, by performing multi-class section classification on German doctor's letters. We conduct extensive class-wise evaluations supported by Shapley values, to validate the quality of our small training data set and to ensure the interpretability of model predictions. We demonstrate that a lightweight, domain-adapted pretrained model, prompted with just 20 shots, outperforms a traditional classification model by 30.5% accuracy. Our results serve as a process-oriented guideline for clinical information extraction projects working with low-resource."}}, {"id": "b04add4477980e3c", "url": "http://arxiv.org/abs/1810.01732v1", "title": "2018 Low-Power Image Recognition Challenge", "description": "The Low-Power Image Recognition Challenge (LPIRC, https://rebootingcomputing.ieee.org/lpirc) is an annual competition started in 2015. The competition identifies the best technologies that can classify and detect objects in images efficiently (short execution time and low energy consumption) and accurately (high precision). Over the four years, the winners' scores have improved more than 24 times. As computer vision is widely used in many battery-powered systems (such as drones and mobile phones", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:49.312032Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The Low-Power Image Recognition Challenge (LPIRC, https://rebootingcomputing.ieee.org/lpirc) is an annual competition started in 2015. The competition identifies the best technologies that can classify and detect objects in images efficiently (short execution time and low energy consumption) and accurately (high precision). Over the four years, the winners' scores have improved more than 24 times. As computer vision is widely used in many battery-powered systems (such as drones and mobile phones), the need for low-power computer vision will become increasingly important. This paper summarizes LPIRC 2018 by describing the three different tracks and the winners' solutions."}}, {"id": "3922796e7ed10f33", "url": "http://arxiv.org/abs/2411.02844v1", "title": "Correlation of Object Detection Performance with Visual Saliency and Depth Estimation", "description": "As object detection techniques continue to evolve, understanding their relationships with complementary visual tasks becomes crucial for optimising model architectures and computational resources. This paper investigates the correlations between object detection accuracy and two fundamental visual tasks: depth prediction and visual saliency prediction. Through comprehensive experiments using state-of-the-art models (DeepGaze IIE, Depth Anything, DPT-Large, and Itti's model) on COCO and Pascal VO", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:50.195819Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "As object detection techniques continue to evolve, understanding their relationships with complementary visual tasks becomes crucial for optimising model architectures and computational resources. This paper investigates the correlations between object detection accuracy and two fundamental visual tasks: depth prediction and visual saliency prediction. Through comprehensive experiments using state-of-the-art models (DeepGaze IIE, Depth Anything, DPT-Large, and Itti's model) on COCO and Pascal VOC datasets, we find that visual saliency shows consistently stronger correlations with object detection accuracy (mA$\u03c1$ up to 0.459 on Pascal VOC) compared to depth prediction (mA$\u03c1$ up to 0.283). Our analysis reveals significant variations in these correlations across object categories, with larger objects showing correlation values up to three times higher than smaller objects. These findings suggest incorporating visual saliency features into object detection architectures could be more beneficial than depth information, particularly for specific object categories. The observed category-specific variations also provide insights for targeted feature engineering and dataset design improvements, potentially leading to more efficient and accurate object detection systems."}}, {"id": "e7c985532b52786e", "url": "http://arxiv.org/abs/2501.14802v1", "title": "DNN-Powered MLOps Pipeline Optimization for Large Language Models: A Framework for Automated Deployment and Resource Management", "description": "The exponential growth in the size and complexity of Large Language Models (LLMs) has introduced unprecedented challenges in their deployment and operational management. Traditional MLOps approaches often fail to efficiently handle the scale, resource requirements, and dynamic nature of these models. This research presents a novel framework that leverages Deep Neural Networks (DNNs) to optimize MLOps pipelines specifically for LLMs. Our approach introduces an intelligent system that automates de", "provider": "arxiv", "domains": ["mlops", "nlp", "generative_ai"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:51.153459Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The exponential growth in the size and complexity of Large Language Models (LLMs) has introduced unprecedented challenges in their deployment and operational management. Traditional MLOps approaches often fail to efficiently handle the scale, resource requirements, and dynamic nature of these models. This research presents a novel framework that leverages Deep Neural Networks (DNNs) to optimize MLOps pipelines specifically for LLMs. Our approach introduces an intelligent system that automates deployment decisions, resource allocation, and pipeline optimization while maintaining optimal performance and cost efficiency. Through extensive experimentation across multiple cloud environments and deployment scenarios, we demonstrate significant improvements: 40% enhancement in resource utilization, 35% reduction in deployment latency, and 30% decrease in operational costs compared to traditional MLOps approaches. The framework's ability to adapt to varying workloads and automatically optimize deployment strategies represents a significant advancement in automated MLOps management for large-scale language models. Our framework introduces several novel components including a multi-stream neural architecture for processing heterogeneous operational metrics, an adaptive resource allocation system that continuously learns from deployment patterns, and a sophisticated deployment orchestration mechanism that automatically selects optimal strategies based on model characteristics and environmental conditions. The system demonstrates robust performance across various deployment scenarios, including multi-cloud environments, high-throughput production systems, and cost-sensitive deployments. Through rigorous evaluation using production workloads from multiple organizations, we validate our approach's effectiveness in reducing operational complexity while improving system reliability and cost efficiency."}}, {"id": "ba063e18219eccee", "url": "http://arxiv.org/abs/2310.00034v2", "title": "PB-LLM: Partially Binarized Large Language Models", "description": "This paper explores network binarization, a radical form of quantization, compressing model weights to a single bit, specifically for Large Language Models (LLMs) compression. Due to previous binarization methods collapsing LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can achieve extreme low-bit quantization while maintaining the linguistic reasoning capacity of quantized LLMs. Specifically, our exploration first uncovers the ineffectiveness of naive applications of", "provider": "arxiv", "domains": ["generative_ai", "nlp", "reinforcement_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:52.695554Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper explores network binarization, a radical form of quantization, compressing model weights to a single bit, specifically for Large Language Models (LLMs) compression. Due to previous binarization methods collapsing LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can achieve extreme low-bit quantization while maintaining the linguistic reasoning capacity of quantized LLMs. Specifically, our exploration first uncovers the ineffectiveness of naive applications of existing binarization algorithms and highlights the imperative role of salient weights in achieving low-bit quantization. Thus, PB-LLM filters a small ratio of salient weights during binarization, allocating them to higher-bit storage, i.e., partially-binarization. PB-LLM is extended to recover the capacities of quantized LMMs, by analyzing from the perspective of post-training quantization (PTQ) and quantization-aware training (QAT). Under PTQ, combining the concepts from GPTQ, we reconstruct the binarized weight matrix guided by the Hessian matrix and successfully recover the reasoning capacity of PB-LLM in low-bit. Under QAT, we freeze the salient weights during training, explore the derivation of optimal scaling factors crucial for minimizing the quantization error, and propose a scaling mechanism based on this derived scaling strategy for residual binarized weights. Those explorations and the developed methodologies significantly contribute to rejuvenating the performance of low-bit quantized LLMs and present substantial advancements in the field of network binarization for LLMs.The code is available at https://github.com/hahnyuan/BinaryLLM."}}, {"id": "83bc588fcd5f98b8", "url": "http://arxiv.org/abs/2406.04710v2", "title": "Morescient GAI for Software Engineering (Extended Version)", "description": "The ability of Generative AI (GAI) technology to automatically check, synthesize and modify software engineering artifacts promises to revolutionize all aspects of software engineering. Using GAI for software engineering tasks is consequently one of the most rapidly expanding fields of software engineering research, with over a hundred LLM-based code models having been published since 2021. However, the overwhelming majority of existing code models share a major weakness - they are exclusively t", "provider": "arxiv", "domains": ["generative_ai"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:55.008047Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The ability of Generative AI (GAI) technology to automatically check, synthesize and modify software engineering artifacts promises to revolutionize all aspects of software engineering. Using GAI for software engineering tasks is consequently one of the most rapidly expanding fields of software engineering research, with over a hundred LLM-based code models having been published since 2021. However, the overwhelming majority of existing code models share a major weakness - they are exclusively trained on the syntactic facet of software, significantly lowering their trustworthiness in tasks dependent on software semantics. To address this problem, a new class of \"Morescient\" GAI is needed that is \"aware\" of (i.e., trained on) both the semantic and static facets of software. This, in turn, will require a new generation of software observation platforms capable of generating large quantities of execution observations in a structured and readily analyzable way. In this paper, we present a vision and roadmap for how such \"Morescient\" GAI models can be engineered, evolved and disseminated according to the principles of open science."}}, {"id": "de4f44892c5a2171", "url": "http://arxiv.org/abs/2509.11056v1", "title": "BERT4beam: Large AI Model Enabled Generalized Beamforming Optimization", "description": "Artificial intelligence (AI) is anticipated to emerge as a pivotal enabler for the forthcoming sixth-generation (6G) wireless communication systems. However, current research efforts regarding large AI models for wireless communications primarily focus on fine-tuning pre-trained large language models (LLMs) for specific tasks. This paper investigates the large-scale AI model designed for beamforming optimization to adapt and generalize to diverse tasks defined by system utilities and scales. We ", "provider": "arxiv", "domains": ["generative_ai", "nlp"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:55.377802Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Artificial intelligence (AI) is anticipated to emerge as a pivotal enabler for the forthcoming sixth-generation (6G) wireless communication systems. However, current research efforts regarding large AI models for wireless communications primarily focus on fine-tuning pre-trained large language models (LLMs) for specific tasks. This paper investigates the large-scale AI model designed for beamforming optimization to adapt and generalize to diverse tasks defined by system utilities and scales. We propose a novel framework based on bidirectional encoder representations from transformers (BERT), termed BERT4beam. We aim to formulate the beamforming optimization problem as a token-level sequence learning task, perform tokenization of the channel state information, construct the BERT model, and conduct task-specific pre-training and fine-tuning strategies. Based on the framework, we propose two BERT-based approaches for single-task and multi-task beamforming optimization, respectively. Both approaches are generalizable for varying user scales. Moreover, the former can adapt to varying system utilities and antenna configurations by re-configuring the input and output module of the BERT model, while the latter, termed UBERT, can directly generalize to diverse tasks, due to a finer-grained tokenization strategy. Extensive simulation results demonstrate that the two proposed approaches can achieve near-optimal performance and outperform existing AI models across various beamforming optimization tasks, showcasing strong adaptability and generalizability."}}, {"id": "dda0ebdc2b8f0299", "url": "http://arxiv.org/abs/1910.12695v2", "title": "AI Ethics in Industry: A Research Framework", "description": "Artificial Intelligence (AI) systems exert a growing influence on our society. As they become more ubiquitous, their potential negative impacts also become evident through various real-world incidents. Following such early incidents, academic and public discussion on AI ethics has highlighted the need for implementing ethics in AI system development. However, little currently exists in the way of frameworks for understanding the practical implementation of AI ethics. In this paper, we discuss a ", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "intermediate", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:55.963704Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Artificial Intelligence (AI) systems exert a growing influence on our society. As they become more ubiquitous, their potential negative impacts also become evident through various real-world incidents. Following such early incidents, academic and public discussion on AI ethics has highlighted the need for implementing ethics in AI system development. However, little currently exists in the way of frameworks for understanding the practical implementation of AI ethics. In this paper, we discuss a research framework for implementing AI ethics in industrial settings. The framework presents a starting point for empirical studies into AI ethics but is still being developed further based on its practical utilization."}}, {"id": "6f5cce837cf72508", "url": "http://arxiv.org/abs/2110.04837v1", "title": "Using Edge Cases to Disentangle Fairness and Solidarity in AI Ethics", "description": "Principles of fairness and solidarity in AI ethics regularly overlap, creating obscurity in practice: acting in accordance with one can appear indistinguishable from deciding according to the rules of the other. However, there exist irregular cases where the two concepts split, and so reveal their disparate meanings and uses. This paper explores two cases in AI medical ethics, one that is irregular and the other more conventional, to fully distinguish fairness and solidarity. Then the distinctio", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:56.026424Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Principles of fairness and solidarity in AI ethics regularly overlap, creating obscurity in practice: acting in accordance with one can appear indistinguishable from deciding according to the rules of the other. However, there exist irregular cases where the two concepts split, and so reveal their disparate meanings and uses. This paper explores two cases in AI medical ethics, one that is irregular and the other more conventional, to fully distinguish fairness and solidarity. Then the distinction is applied to the frequently cited COMPAS versus ProPublica dispute in judicial ethics. The application provides a broader model for settling contemporary and topical debates about fairness and solidarity. It also implies a deeper and disorienting truth about AI ethics principles and their justification."}}, {"id": "c49a06889c06c44f", "url": "http://arxiv.org/abs/2304.11861v2", "title": "Towards a Praxis for Intercultural Ethics in Explainable AI", "description": "Explainable AI (XAI) is often promoted with the idea of helping users understand how machine learning models function and produce predictions. Still, most of these benefits are reserved for those with specialized domain knowledge, such as machine learning developers. Recent research has argued that making AI explainable can be a viable way of making AI more useful in real-world contexts, especially within low-resource domains in the Global South. While AI has transcended borders, a limited amoun", "provider": "arxiv", "domains": ["ml_basics", "ai_ethics", "nlp"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["privacy", "explainability"], "quality_score": 0.53, "discovered_at": "2026-02-09T15:39:56.092589Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Explainable AI (XAI) is often promoted with the idea of helping users understand how machine learning models function and produce predictions. Still, most of these benefits are reserved for those with specialized domain knowledge, such as machine learning developers. Recent research has argued that making AI explainable can be a viable way of making AI more useful in real-world contexts, especially within low-resource domains in the Global South. While AI has transcended borders, a limited amount of work focuses on democratizing the concept of explainable AI to the \"majority world\", leaving much room to explore and develop new approaches within this space that cater to the distinct needs of users within culturally and socially-diverse regions. This article introduces the concept of an intercultural ethics approach to AI explainability. It examines how cultural nuances impact the adoption and use of technology, the factors that impede how technical concepts such as AI are explained, and how integrating an intercultural ethics approach in the development of XAI can improve user understanding and facilitate efficient usage of these methods."}}, {"id": "ab71dcdd3c90a877", "url": "http://arxiv.org/abs/1703.09039v2", "title": "Efficient Processing of Deep Neural Networks: A Tutorial and Survey", "description": "Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of", "provider": "arxiv", "domains": ["deep_learning", "computer_vision"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.527, "discovered_at": "2026-02-09T15:39:46.888642Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems.\n  This article aims to provide a comprehensive tutorial and survey about the recent advances towards the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic co-designs, being proposed in academia and industry.\n  The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the trade-offs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities."}}, {"id": "bbf24870d0a0c46e", "url": "https://github.com/dipakkr/A-to-Z-Resources-for-Students", "title": "dipakkr/A-to-Z-Resources-for-Students", "description": "\u2705  Curated list of resources for college students ", "provider": "github", "domains": ["generative_ai", "deep_learning", "ml_basics", "nlp", "ai_governance"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 1.7, "prerequisites": [], "tags": ["large language models", "prompt engineering", "fine-tuning"], "quality_score": 0.524, "discovered_at": "2026-02-09T15:00:29.325098Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"stars": 21368, "language": null, "topics": ["android", "awesome", "awesome-list", "conferences", "hackathon", "react", "students", "udacity"], "updated_at": "2026-02-09T09:56:37Z"}}, {"id": "86a2760f42226186", "url": "http://arxiv.org/abs/2205.04675v2", "title": "Spatial Monitoring and Insect Behavioural Analysis Using Computer Vision for Precision Pollination", "description": "Insects are the most important global pollinator of crops and play a key role in maintaining the sustainability of natural ecosystems. Insect pollination monitoring and management are therefore essential for improving crop production and food security. Computer vision facilitated pollinator monitoring can intensify data collection over what is feasible using manual approaches. The new data it generates may provide a detailed understanding of insect distributions and facilitate fine-grained analy", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.524, "discovered_at": "2026-02-09T15:00:31.003338Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Insects are the most important global pollinator of crops and play a key role in maintaining the sustainability of natural ecosystems. Insect pollination monitoring and management are therefore essential for improving crop production and food security. Computer vision facilitated pollinator monitoring can intensify data collection over what is feasible using manual approaches. The new data it generates may provide a detailed understanding of insect distributions and facilitate fine-grained analysis sufficient to predict their pollination efficacy and underpin precision pollination. Current computer vision facilitated insect tracking in complex outdoor environments is restricted in spatial coverage and often constrained to a single insect species. This limits its relevance to agriculture. Therefore, in this article we introduce a novel system to facilitate markerless data capture for insect counting, insect motion tracking, behaviour analysis and pollination prediction across large agricultural areas. Our system is comprised of edge computing multi-point video recording, offline automated multispecies insect counting, tracking and behavioural analysis. We implement and test our system on a commercial berry farm to demonstrate its capabilities. Our system successfully tracked four insect varieties, at nine monitoring stations within polytunnels, obtaining an F-score above 0.8 for each variety. The system enabled calculation of key metrics to assess the relative pollination impact of each insect variety. With this technological advancement, detailed, ongoing data collection for precision pollination becomes achievable. This is important to inform growers and apiarists managing crop pollination, as it allows data-driven decisions to be made to improve food production and food security."}}, {"id": "ecb3ef609f113c01", "url": "http://arxiv.org/abs/2110.12183v1", "title": "Attend and Guide (AG-Net): A Keypoints-driven Attention-based Deep Network for Image Recognition", "description": "This paper presents a novel keypoints-based attention mechanism for visual recognition in still images. Deep Convolutional Neural Networks (CNNs) for recognizing images with distinctive classes have shown great success, but their performance in discriminating fine-grained changes is not at the same level. We address this by proposing an end-to-end CNN model, which learns meaningful features linking fine-grained changes using our novel attention mechanism. It captures the spatial structures in im", "provider": "arxiv", "domains": ["deep_learning", "computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.522, "discovered_at": "2026-02-09T15:39:49.256310Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper presents a novel keypoints-based attention mechanism for visual recognition in still images. Deep Convolutional Neural Networks (CNNs) for recognizing images with distinctive classes have shown great success, but their performance in discriminating fine-grained changes is not at the same level. We address this by proposing an end-to-end CNN model, which learns meaningful features linking fine-grained changes using our novel attention mechanism. It captures the spatial structures in images by identifying semantic regions (SRs) and their spatial distributions, and is proved to be the key to modelling subtle changes in images. We automatically identify these SRs by grouping the detected keypoints in a given image. The ``usefulness'' of these SRs for image recognition is measured using our innovative attentional mechanism focusing on parts of the image that are most relevant to a given task. This framework applies to traditional and fine-grained image recognition tasks and does not require manually annotated regions (e.g. bounding-box of body parts, objects, etc.) for learning and prediction. Moreover, the proposed keypoints-driven attention mechanism can be easily integrated into the existing CNN models. The framework is evaluated on six diverse benchmark datasets. The model outperforms the state-of-the-art approaches by a considerable margin using Distracted Driver V1 (Acc: 3.39%), Distracted Driver V2 (Acc: 6.58%), Stanford-40 Actions (mAP: 2.15%), People Playing Musical Instruments (mAP: 16.05%), Food-101 (Acc: 6.30%) and Caltech-256 (Acc: 2.59%) datasets."}}, {"id": "d208dd3fc9f2ec9a", "url": "http://arxiv.org/abs/1906.10015v2", "title": "A Review on Neural Network Models of Schizophrenia and Autism Spectrum Disorder", "description": "This survey presents the most relevant neural network models of autism spectrum disorder and schizophrenia, from the first connectionist models to recent deep network architectures. We analyzed and compared the most representative symptoms with its neural model counterpart, detailing the alteration introduced in the network that generates each of the symptoms, and identifying their strengths and weaknesses. We additionally cross-compared Bayesian and free-energy approaches, as they are widely ap", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.521, "discovered_at": "2026-02-09T15:00:30.571131Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This survey presents the most relevant neural network models of autism spectrum disorder and schizophrenia, from the first connectionist models to recent deep network architectures. We analyzed and compared the most representative symptoms with its neural model counterpart, detailing the alteration introduced in the network that generates each of the symptoms, and identifying their strengths and weaknesses. We additionally cross-compared Bayesian and free-energy approaches, as they are widely applied to modeling psychiatric disorders and share basic mechanisms with neural networks. Models of schizophrenia mainly focused on hallucinations and delusional thoughts using neural dysconnections or inhibitory imbalance as the predominating alteration. Models of autism rather focused on perceptual difficulties, mainly excessive attention to environment details, implemented as excessive inhibitory connections or increased sensory precision. We found an excessive tight view of the psychopathologies around one specific and simplified effect, usually constrained to the technical idiosyncrasy of the used network architecture. Recent theories and evidence on sensorimotor integration and body perception combined with modern neural network architectures could offer a broader and novel spectrum to approach these psychopathologies. This review emphasizes the power of artificial neural networks for modeling some symptoms of neurological disorders but also calls for further developing these techniques in the field of computational psychiatry."}}, {"id": "39ffaf06f89645a2", "url": "http://arxiv.org/abs/2101.11436v1", "title": "Challenges Encountered in Turkish Natural Language Processing Studies", "description": "Natural language processing is a branch of computer science that combines artificial intelligence with linguistics. It aims to analyze a language element such as writing or speaking with software and convert it into information. Considering that each language has its own grammatical rules and vocabulary diversity, the complexity of the studies in this field is somewhat understandable. For instance, Turkish is a very interesting language in many ways. Examples of this are agglutinative word struc", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.521, "discovered_at": "2026-02-09T15:39:47.332728Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Natural language processing is a branch of computer science that combines artificial intelligence with linguistics. It aims to analyze a language element such as writing or speaking with software and convert it into information. Considering that each language has its own grammatical rules and vocabulary diversity, the complexity of the studies in this field is somewhat understandable. For instance, Turkish is a very interesting language in many ways. Examples of this are agglutinative word structure, consonant/vowel harmony, a large number of productive derivational morphemes (practically infinite vocabulary), derivation and syntactic relations, a complex emphasis on vocabulary and phonological rules. In this study, the interesting features of Turkish in terms of natural language processing are mentioned. In addition, summary info about natural language processing techniques, systems and various sources developed for Turkish are given."}}, {"id": "fdcde3d758bc94e5", "url": "http://arxiv.org/abs/2504.09138v1", "title": "White-Box AI Model: Next Frontier of Wireless Communications", "description": "White-box AI (WAI), or explainable AI (XAI) model, a novel tool to achieve the reasoning behind decisions and predictions made by the AI algorithms, makes it more understandable and transparent. It offers a new approach to address key challenges of interpretability and mathematical validation in traditional black-box models. In this paper, WAI-aided wireless communication systems are proposed and investigated thoroughly to utilize the promising capabilities. First, we introduce the fundamental p", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.521, "discovered_at": "2026-02-09T15:39:55.457208Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "White-box AI (WAI), or explainable AI (XAI) model, a novel tool to achieve the reasoning behind decisions and predictions made by the AI algorithms, makes it more understandable and transparent. It offers a new approach to address key challenges of interpretability and mathematical validation in traditional black-box models. In this paper, WAI-aided wireless communication systems are proposed and investigated thoroughly to utilize the promising capabilities. First, we introduce the fundamental principles of WAI. Then, a detailed comparison between WAI and traditional black-box model is conducted in terms of optimization objectives and architecture design, with a focus on deep neural networks (DNNs) and transformer networks. Furthermore, in contrast to the traditional black-box methods, WAI leverages theory-driven causal modeling and verifiable optimization paths, thereby demonstrating potential advantages in areas such as signal processing and resource allocation. Finally, we outline future research directions for the integration of WAI in wireless communication systems."}}, {"id": "983c8a493fafca13", "url": "http://arxiv.org/abs/1711.00146v1", "title": "A multitask deep learning model for real-time deployment in embedded systems", "description": "We propose an approach to Multitask Learning (MTL) to make deep learning models faster and lighter for applications in which multiple tasks need to be solved simultaneously, which is particularly useful in embedded, real-time systems. We develop a multitask model for both Object Detection and Semantic Segmentation and analyze the challenges that appear during its training. Our multitask network is 1.6x faster, lighter and uses less memory than deploying the single-task models in parallel. We con", "provider": "arxiv", "domains": ["deep_learning", "computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.52, "discovered_at": "2026-02-09T15:00:30.198098Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We propose an approach to Multitask Learning (MTL) to make deep learning models faster and lighter for applications in which multiple tasks need to be solved simultaneously, which is particularly useful in embedded, real-time systems. We develop a multitask model for both Object Detection and Semantic Segmentation and analyze the challenges that appear during its training. Our multitask network is 1.6x faster, lighter and uses less memory than deploying the single-task models in parallel. We conclude that MTL has the potential to give superior performance in exchange of a more complex training process that introduces challenges not present in single-task models."}}, {"id": "0fce0f39cfa8f835", "url": "http://arxiv.org/abs/1702.07254v3", "title": "Sobolev Norm Learning Rates for Regularized Least-Squares Algorithm", "description": "Learning rates for least-squares regression are typically expressed in terms of $L_2$-norms. In this paper we extend these rates to norms stronger than the $L_2$-norm without requiring the regression function to be contained in the hypothesis space. In the special case of Sobolev reproducing kernel Hilbert spaces used as hypotheses spaces, these stronger norms coincide with fractional Sobolev norms between the used Sobolev space and $L_2$. As a consequence, not only the target function but also ", "provider": "arxiv", "domains": ["ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.52, "discovered_at": "2026-02-09T15:00:31.936954Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Learning rates for least-squares regression are typically expressed in terms of $L_2$-norms. In this paper we extend these rates to norms stronger than the $L_2$-norm without requiring the regression function to be contained in the hypothesis space. In the special case of Sobolev reproducing kernel Hilbert spaces used as hypotheses spaces, these stronger norms coincide with fractional Sobolev norms between the used Sobolev space and $L_2$. As a consequence, not only the target function but also some of its derivatives can be estimated without changing the algorithm. From a technical point of view, we combine the well-known integral operator techniques with an embedding property, which so far has only been used in combination with empirical process arguments. This combination results in new finite sample bounds with respect to the stronger norms. From these finite sample bounds our rates easily follow. Finally, we prove the asymptotic optimality of our results in many cases."}}, {"id": "a453fcb41a0074c0", "url": "http://arxiv.org/abs/1411.1792v1", "title": "How transferable are features in deep neural networks?", "description": "Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experime", "provider": "arxiv", "domains": ["deep_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["neural networks"], "quality_score": 0.52, "discovered_at": "2026-02-09T15:39:46.790002Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset."}}, {"id": "841466884f5a2a89", "url": "http://arxiv.org/abs/2011.09170v1", "title": "TJU-DHD: A Diverse High-Resolution Dataset for Object Detection", "description": "Vehicles, pedestrians, and riders are the most important and interesting objects for the perception modules of self-driving vehicles and video surveillance. However, the state-of-the-art performance of detecting such important objects (esp. small objects) is far from satisfying the demand of practical systems. Large-scale, rich-diversity, and high-resolution datasets play an important role in developing better object detection methods to satisfy the demand. Existing public large-scale datasets s", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.518, "discovered_at": "2026-02-09T15:00:31.612452Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Vehicles, pedestrians, and riders are the most important and interesting objects for the perception modules of self-driving vehicles and video surveillance. However, the state-of-the-art performance of detecting such important objects (esp. small objects) is far from satisfying the demand of practical systems. Large-scale, rich-diversity, and high-resolution datasets play an important role in developing better object detection methods to satisfy the demand. Existing public large-scale datasets such as MS COCO collected from websites do not focus on the specific scenarios. Moreover, the popular datasets (e.g., KITTI and Citypersons) collected from the specific scenarios are limited in the number of images and instances, the resolution, and the diversity. To attempt to solve the problem, we build a diverse high-resolution dataset (called TJU-DHD). The dataset contains 115,354 high-resolution images (52% images have a resolution of 1624$\\times$1200 pixels and 48% images have a resolution of at least 2,560$\\times$1,440 pixels) and 709,330 labeled objects in total with a large variance in scale and appearance. Meanwhile, the dataset has a rich diversity in season variance, illumination variance, and weather variance. In addition, a new diverse pedestrian dataset is further built. With the four different detectors (i.e., the one-stage RetinaNet, anchor-free FCOS, two-stage FPN, and Cascade R-CNN), experiments about object detection and pedestrian detection are conducted. We hope that the newly built dataset can help promote the research on object detection and pedestrian detection in these two scenes. The dataset is available at https://github.com/tjubiit/TJU-DHD."}}, {"id": "c482237e3c6e3f42", "url": "http://arxiv.org/abs/2402.01393v3", "title": "ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data", "description": "We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models -- the ALERT module -- that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any ", "provider": "arxiv", "domains": ["ml_basics", "deep_learning", "nlp", "computer_vision"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.517, "discovered_at": "2026-02-09T15:39:44.174216Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models -- the ALERT module -- that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any downstream model with always up-to-date features at any sampling rate, (3) exploiting the input sparsity in a patch-based approach inspired by Vision Transformer to optimize the efficiency of the method. These embeddings are then processed by a transformer model trained for object and gesture recognition. Using this approach, we achieve performances at the state-of-the-art with a lower latency than competitors. We also demonstrate that our asynchronous model can operate at any desired sampling rate."}}, {"id": "bfc5624b2903e8b7", "url": "http://arxiv.org/abs/2501.07451v2", "title": "A Survey on Dynamic Neural Networks: from Computer Vision to Multi-modal Sensor Fusion", "description": "Model compression is essential in the deployment of large Computer Vision models on embedded devices. However, static optimization techniques (e.g. pruning, quantization, etc.) neglect the fact that different inputs have different complexities, thus requiring different amount of computations. Dynamic Neural Networks allow to condition the number of computations to the specific input. The current literature on the topic is very extensive and fragmented. We present a comprehensive survey that synt", "provider": "arxiv", "domains": ["deep_learning", "computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.515, "discovered_at": "2026-02-09T15:39:48.894183Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Model compression is essential in the deployment of large Computer Vision models on embedded devices. However, static optimization techniques (e.g. pruning, quantization, etc.) neglect the fact that different inputs have different complexities, thus requiring different amount of computations. Dynamic Neural Networks allow to condition the number of computations to the specific input. The current literature on the topic is very extensive and fragmented. We present a comprehensive survey that synthesizes and unifies existing Dynamic Neural Networks research in the context of Computer Vision. Additionally, we provide a logical taxonomy based on which component of the network is adaptive: the output, the computation graph or the input. Furthermore, we argue that Dynamic Neural Networks are particularly beneficial in the context of Sensor Fusion for better adaptivity, noise reduction and information prioritization. We present preliminary works in this direction. We complement this survey with a curated repository listing all the surveyed papers, each with a brief summary of the solution and the code base when available: https://github.com/DTU-PAS/awesome-dynn-for-cv ."}}, {"id": "627fa273a8595d43", "url": "http://arxiv.org/abs/2301.02562v1", "title": "Super Sparse 3D Object Detection", "description": "As the perception range of LiDAR expands, LiDAR-based 3D object detection contributes ever-increasingly to the long-range perception in autonomous driving. Mainstream 3D object detectors often build dense feature maps, where the cost is quadratic to the perception range, making them hardly scale up to the long-range settings. To enable efficient long-range detection, we first propose a fully sparse object detector termed FSD. FSD is built upon the general sparse voxel encoder and a novel sparse ", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.515, "discovered_at": "2026-02-09T15:39:50.096006Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "As the perception range of LiDAR expands, LiDAR-based 3D object detection contributes ever-increasingly to the long-range perception in autonomous driving. Mainstream 3D object detectors often build dense feature maps, where the cost is quadratic to the perception range, making them hardly scale up to the long-range settings. To enable efficient long-range detection, we first propose a fully sparse object detector termed FSD. FSD is built upon the general sparse voxel encoder and a novel sparse instance recognition (SIR) module. SIR groups the points into instances and applies highly-efficient instance-wise feature extraction. The instance-wise grouping sidesteps the issue of the center feature missing, which hinders the design of the fully sparse architecture. To further enjoy the benefit of fully sparse characteristic, we leverage temporal information to remove data redundancy and propose a super sparse detector named FSD++. FSD++ first generates residual points, which indicate the point changes between consecutive frames. The residual points, along with a few previous foreground points, form the super sparse input data, greatly reducing data redundancy and computational overhead. We comprehensively analyze our method on the large-scale Waymo Open Dataset, and state-of-the-art performance is reported. To showcase the superiority of our method in long-range detection, we also conduct experiments on Argoverse 2 Dataset, where the perception range ($200m$) is much larger than Waymo Open Dataset ($75m$). Code is open-sourced at https://github.com/tusen-ai/SST."}}, {"id": "46a5c5625c5e672e", "url": "http://arxiv.org/abs/2206.02849v1", "title": "A Bird's-Eye Tutorial of Graph Attention Architectures", "description": "Graph Neural Networks (GNNs) have shown tremendous strides in performance for graph-structured problems especially in the domains of natural language processing, computer vision and recommender systems. Inspired by the success of the transformer architecture, there has been an ever-growing body of work on attention variants of GNNs attempting to advance the state of the art in many of these problems. Incorporating \"attention\" into graph mining has been viewed as a way to overcome the noisiness, ", "provider": "arxiv", "domains": ["deep_learning", "nlp", "computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.513, "discovered_at": "2026-02-09T15:00:29.939093Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Graph Neural Networks (GNNs) have shown tremendous strides in performance for graph-structured problems especially in the domains of natural language processing, computer vision and recommender systems. Inspired by the success of the transformer architecture, there has been an ever-growing body of work on attention variants of GNNs attempting to advance the state of the art in many of these problems. Incorporating \"attention\" into graph mining has been viewed as a way to overcome the noisiness, heterogenity and complexity associated with graph-structured data as well as to encode soft-inductive bias. It is hence crucial and advantageous to study these variants from a bird's-eye view to assess their strengths and weaknesses. We provide a systematic and focused tutorial centered around attention based GNNs in a hope to benefit researchers dealing with graph-structured problems. Our tutorial looks at GNN variants from the point of view of the attention function and iteratively builds the reader's understanding of different graph attention variants."}}, {"id": "53c0b77f98bd9f36", "url": "http://arxiv.org/abs/2408.14600v1", "title": "PVAFN: Point-Voxel Attention Fusion Network with Multi-Pooling Enhancing for 3D Object Detection", "description": "The integration of point and voxel representations is becoming more common in LiDAR-based 3D object detection. However, this combination often struggles with capturing semantic information effectively. Moreover, relying solely on point features within regions of interest can lead to information loss and limitations in local feature representation. To tackle these challenges, we propose a novel two-stage 3D object detector, called Point-Voxel Attention Fusion Network (PVAFN). PVAFN leverages an a", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.513, "discovered_at": "2026-02-09T15:00:31.682706Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The integration of point and voxel representations is becoming more common in LiDAR-based 3D object detection. However, this combination often struggles with capturing semantic information effectively. Moreover, relying solely on point features within regions of interest can lead to information loss and limitations in local feature representation. To tackle these challenges, we propose a novel two-stage 3D object detector, called Point-Voxel Attention Fusion Network (PVAFN). PVAFN leverages an attention mechanism to improve multi-modal feature fusion during the feature extraction phase. In the refinement stage, it utilizes a multi-pooling strategy to integrate both multi-scale and region-specific information effectively. The point-voxel attention mechanism adaptively combines point cloud and voxel-based Bird's-Eye-View (BEV) features, resulting in richer object representations that help to reduce false detections. Additionally, a multi-pooling enhancement module is introduced to boost the model's perception capabilities. This module employs cluster pooling and pyramid pooling techniques to efficiently capture key geometric details and fine-grained shape structures, thereby enhancing the integration of local and global features. Extensive experiments on the KITTI and Waymo datasets demonstrate that the proposed PVAFN achieves competitive performance. The code and models will be available."}}, {"id": "69493baeaf411b5e", "url": "http://arxiv.org/abs/2304.13037v3", "title": "VeML: An End-to-End Machine Learning Lifecycle for Large-scale and High-dimensional Data", "description": "An end-to-end machine learning (ML) lifecycle consists of many iterative processes, from data preparation and ML model design to model training and then deploying the trained model for inference. When building an end-to-end lifecycle for an ML problem, many ML pipelines must be designed and executed that produce a huge number of lifecycle versions. Therefore, this paper introduces VeML, a Version management system dedicated to end-to-end ML Lifecycle. Our system tackles several crucial problems ", "provider": "arxiv", "domains": ["ml_basics", "ai_project_management", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.511, "discovered_at": "2026-02-09T15:00:33.872097Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "An end-to-end machine learning (ML) lifecycle consists of many iterative processes, from data preparation and ML model design to model training and then deploying the trained model for inference. When building an end-to-end lifecycle for an ML problem, many ML pipelines must be designed and executed that produce a huge number of lifecycle versions. Therefore, this paper introduces VeML, a Version management system dedicated to end-to-end ML Lifecycle. Our system tackles several crucial problems that other systems have not solved. First, we address the high cost of building an ML lifecycle, especially for large-scale and high-dimensional dataset. We solve this problem by proposing to transfer the lifecycle of similar datasets managed in our system to the new training data. We design an algorithm based on the core set to compute similarity for large-scale, high-dimensional data efficiently. Another critical issue is the model accuracy degradation by the difference between training data and testing data during the ML lifetime, which leads to lifecycle rebuild. Our system helps to detect this mismatch without getting labeled data from testing data and rebuild the ML lifecycle for a new data version. To demonstrate our contributions, we conduct experiments on real-world, large-scale datasets of driving images and spatiotemporal sensor data and show promising results."}}, {"id": "0ff1d61d7f889c51", "url": "http://arxiv.org/abs/2311.01169v1", "title": "Resource-aware Research on Universe and Matter: Call-to-Action in Digital Transformation", "description": "Given the urgency to reduce fossil fuel energy production to make climate tipping points less likely, we call for resource-aware knowledge gain in the research areas on Universe and Matter with emphasis on the digital transformation. A portfolio of measures is described in detail and then summarized according to the timescales required for their implementation. The measures will both contribute to sustainable research and accelerate scientific progress through increased awareness of resource usa", "provider": "arxiv", "domains": ["ai_strategy"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.51, "discovered_at": "2026-02-09T15:39:55.762854Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Given the urgency to reduce fossil fuel energy production to make climate tipping points less likely, we call for resource-aware knowledge gain in the research areas on Universe and Matter with emphasis on the digital transformation. A portfolio of measures is described in detail and then summarized according to the timescales required for their implementation. The measures will both contribute to sustainable research and accelerate scientific progress through increased awareness of resource usage. This work is based on a three-days workshop on sustainability in digital transformation held in May 2023."}}, {"id": "7ca263025f2f61a3", "url": "http://arxiv.org/abs/2108.07700v1", "title": "In Oxford Handbook on AI Governance: The Role of Workers in AI Ethics and Governance", "description": "While the role of states, corporations, and international organizations in AI governance has been extensively theorized, the role of workers has received comparatively little attention. This chapter looks at the role that workers play in identifying and mitigating harms from AI technologies. Harms are the causally assessed impacts of technologies. They arise despite technical reliability and are not a result of technical negligence but rather of normative uncertainty around questions of safety a", "provider": "arxiv", "domains": ["ai_governance", "ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.507, "discovered_at": "2026-02-09T15:18:54.372103Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "While the role of states, corporations, and international organizations in AI governance has been extensively theorized, the role of workers has received comparatively little attention. This chapter looks at the role that workers play in identifying and mitigating harms from AI technologies. Harms are the causally assessed impacts of technologies. They arise despite technical reliability and are not a result of technical negligence but rather of normative uncertainty around questions of safety and fairness in complex social systems. There is high consensus in the AI ethics community on the benefits of reducing harms but less consensus on mechanisms for determining or addressing harms. This lack of consensus has resulted in a number of collective actions by workers protesting how harms are identified and addressed in their workplace. We theorize the role of workers within AI governance and construct a model of harm reporting processes in AI workplaces. The harm reporting process involves three steps, identification, the governance decision, and the response. Workers draw upon three types of claims to argue for jurisdiction over questions of AI governance, subjection, control over the product of labor, and proximate knowledge of systems. Examining the past decade of AI related worker activism allows us to understand how different types of workers are positioned within a workplace that produces AI systems, how their position informs their claims, and the place of collective action in staking their claims. This chapter argues that workers occupy a unique role in identifying and mitigating harms caused by AI systems."}}, {"id": "982858993c6b4d1e", "url": "http://arxiv.org/abs/2412.12024v1", "title": "Learning to Navigate in Mazes with Novel Layouts using Abstract Top-down Maps", "description": "Learning navigation capabilities in different environments has long been one of the major challenges in decision-making. In this work, we focus on zero-shot navigation ability using given abstract $2$-D top-down maps. Like human navigation by reading a paper map, the agent reads the map as an image when navigating in a novel layout, after learning to navigate on a set of training maps. We propose a model-based reinforcement learning approach for this multi-task learning problem, where it jointly", "provider": "arxiv", "domains": ["reinforcement_learning", "ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.506, "discovered_at": "2026-02-09T15:00:32.831205Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Learning navigation capabilities in different environments has long been one of the major challenges in decision-making. In this work, we focus on zero-shot navigation ability using given abstract $2$-D top-down maps. Like human navigation by reading a paper map, the agent reads the map as an image when navigating in a novel layout, after learning to navigate on a set of training maps. We propose a model-based reinforcement learning approach for this multi-task learning problem, where it jointly learns a hypermodel that takes top-down maps as input and predicts the weights of the transition network. We use the DeepMind Lab environment and customize layouts using generated maps. Our method can adapt better to novel environments in zero-shot and is more robust to noise."}}, {"id": "7ea9d9876f01d334", "url": "http://arxiv.org/abs/2001.07935v2", "title": "CodeReef: an open platform for portable MLOps, reusable automation actions and reproducible benchmarking", "description": "We present CodeReef - an open platform to share all the components necessary to enable cross-platform MLOps (MLSysOps), i.e. automating the deployment of ML models across diverse systems in the most efficient way. We also introduce the CodeReef solution - a way to package and share models as non-virtualized, portable, customizable and reproducible archive files. Such ML packages include JSON meta description of models with all dependencies, Python APIs, CLI actions and portable workflows necessa", "provider": "arxiv", "domains": ["mlops"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.505, "discovered_at": "2026-02-09T15:00:31.789069Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We present CodeReef - an open platform to share all the components necessary to enable cross-platform MLOps (MLSysOps), i.e. automating the deployment of ML models across diverse systems in the most efficient way. We also introduce the CodeReef solution - a way to package and share models as non-virtualized, portable, customizable and reproducible archive files. Such ML packages include JSON meta description of models with all dependencies, Python APIs, CLI actions and portable workflows necessary to automatically build, benchmark, test and customize models across diverse platforms, AI frameworks, libraries, compilers and datasets. We demonstrate several CodeReef solutions to automatically build, run and measure object detection based on SSD-Mobilenets, TensorFlow and COCO dataset from the latest MLPerf inference benchmark across a wide range of platforms from Raspberry Pi, Android phones and IoT devices to data centers. Our long-term goal is to help researchers share their new techniques as production-ready packages along with research papers to participate in collaborative and reproducible benchmarking, compare the different ML/software/hardware stacks and select the most efficient ones on a Pareto frontier using online CodeReef dashboards."}}, {"id": "18693b34b6255768", "url": "http://arxiv.org/abs/1806.07996v1", "title": "Novel Convolution Kernels for Computer Vision and Shape Analysis based on Electromagnetism", "description": "Computer vision is a growing field with a lot of new applications in automation and robotics, since it allows the analysis of images and shapes for the generation of numerical or analytical information. One of the most used method of information extraction is image filtering through convolution kernels, with each kernel specialized for specific applications. The objective of this paper is to present a novel convolution kernels, based on principles of electromagnetic potentials and fields, for a ", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.505, "discovered_at": "2026-02-09T15:39:48.274861Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Computer vision is a growing field with a lot of new applications in automation and robotics, since it allows the analysis of images and shapes for the generation of numerical or analytical information. One of the most used method of information extraction is image filtering through convolution kernels, with each kernel specialized for specific applications. The objective of this paper is to present a novel convolution kernels, based on principles of electromagnetic potentials and fields, for a general use in computer vision and to demonstrate its usage for shape and stroke analysis. Such filtering possesses unique geometrical properties that can be interpreted using well understood physics theorems. Therefore, this paper focuses on the development of the electromagnetic kernels and on their application on images for shape and stroke analysis. It also presents several interesting features of electromagnetic kernels, such as resolution, size and orientation independence, robustness to noise and deformation, long distance stroke interaction and ability to work with 3D images"}}, {"id": "d37bacb29507d9ee", "url": "http://arxiv.org/abs/2202.09061v4", "title": "VLP: A Survey on Vision-Language Pre-training", "description": "In the past few years, the emergence of pre-training models has brought uni-modal fields such as computer vision (CV) and natural language processing (NLP) to a new era. Substantial works have shown they are beneficial for downstream uni-modal tasks and avoid training a new model from scratch. So can such pre-trained models be applied to multi-modal tasks? Researchers have explored this problem and made significant progress. This paper surveys recent advances and new frontiers in vision-language", "provider": "arxiv", "domains": ["nlp", "computer_vision"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.502, "discovered_at": "2026-02-09T15:00:31.178504Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In the past few years, the emergence of pre-training models has brought uni-modal fields such as computer vision (CV) and natural language processing (NLP) to a new era. Substantial works have shown they are beneficial for downstream uni-modal tasks and avoid training a new model from scratch. So can such pre-trained models be applied to multi-modal tasks? Researchers have explored this problem and made significant progress. This paper surveys recent advances and new frontiers in vision-language pre-training (VLP), including image-text and video-text pre-training. To give readers a better overall grasp of VLP, we first review its recent advances from five aspects: feature extraction, model architecture, pre-training objectives, pre-training datasets, and downstream tasks. Then, we summarize the specific VLP models in detail. Finally, we discuss the new frontiers in VLP. To the best of our knowledge, this is the first survey focused on VLP. We hope that this survey can shed light on future research in the VLP field."}}, {"id": "7ce705e528abcabf", "url": "http://arxiv.org/abs/2211.03705v1", "title": "A Survey on Computer Vision based Human Analysis in the COVID-19 Era", "description": "The emergence of COVID-19 has had a global and profound impact, not only on society as a whole, but also on the lives of individuals. Various prevention measures were introduced around the world to limit the transmission of the disease, including face masks, mandates for social distancing and regular disinfection in public spaces, and the use of screening applications. These developments also triggered the need for novel and improved computer vision techniques capable of (i) providing support to", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.497, "discovered_at": "2026-02-09T15:00:31.326459Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The emergence of COVID-19 has had a global and profound impact, not only on society as a whole, but also on the lives of individuals. Various prevention measures were introduced around the world to limit the transmission of the disease, including face masks, mandates for social distancing and regular disinfection in public spaces, and the use of screening applications. These developments also triggered the need for novel and improved computer vision techniques capable of (i) providing support to the prevention measures through an automated analysis of visual data, on the one hand, and (ii) facilitating normal operation of existing vision-based services, such as biometric authentication schemes, on the other. Especially important here, are computer vision techniques that focus on the analysis of people and faces in visual data and have been affected the most by the partial occlusions introduced by the mandates for facial masks. Such computer vision based human analysis techniques include face and face-mask detection approaches, face recognition techniques, crowd counting solutions, age and expression estimation procedures, models for detecting face-hand interactions and many others, and have seen considerable attention over recent years. The goal of this survey is to provide an introduction to the problems induced by COVID-19 into such research and to present a comprehensive review of the work done in the computer vision based human analysis field. Particular attention is paid to the impact of facial masks on the performance of various methods and recent solutions to mitigate this problem. Additionally, a detailed review of existing datasets useful for the development and evaluation of methods for COVID-19 related applications is also provided. Finally, to help advance the field further, a discussion on the main open challenges and future research direction is given."}}, {"id": "7243f93750bef385", "url": "http://arxiv.org/abs/2009.07262v2", "title": "Report prepared by the Montreal AI Ethics Institute (MAIEI) on Publication Norms for Responsible AI", "description": "The history of science and technology shows that seemingly innocuous developments in scientific theories and research have enabled real-world applications with significant negative consequences for humanity. In order to ensure that the science and technology of AI is developed in a humane manner, we must develop research publication norms that are informed by our growing understanding of AI's potential threats and use cases. Unfortunately, it's difficult to create a set of publication norms for ", "provider": "arxiv", "domains": ["ai_ethics", "ai_strategy"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.497, "discovered_at": "2026-02-09T15:00:33.708558Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The history of science and technology shows that seemingly innocuous developments in scientific theories and research have enabled real-world applications with significant negative consequences for humanity. In order to ensure that the science and technology of AI is developed in a humane manner, we must develop research publication norms that are informed by our growing understanding of AI's potential threats and use cases. Unfortunately, it's difficult to create a set of publication norms for responsible AI because the field of AI is currently fragmented in terms of how this technology is researched, developed, funded, etc. To examine this challenge and find solutions, the Montreal AI Ethics Institute (MAIEI) co-hosted two public consultations with the Partnership on AI in May 2020. These meetups examined potential publication norms for responsible AI, with the goal of creating a clear set of recommendations and ways forward for publishers.\n  In its submission, MAIEI provides six initial recommendations, these include: 1) create tools to navigate publication decisions, 2) offer a page number extension, 3) develop a network of peers, 4) require broad impact statements, 5) require the publication of expected results, and 6) revamp the peer-review process. After considering potential concerns regarding these recommendations, including constraining innovation and creating a \"black market\" for AI research, MAIEI outlines three ways forward for publishers, these include: 1) state clearly and consistently the need for established norms, 2) coordinate and build trust as a community, and 3) change the approach."}}, {"id": "a2eeb03d1fc42dbb", "url": "http://arxiv.org/abs/2309.07064v2", "title": "A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digital Forensics and Incident Response", "description": "In the dynamic landscape of digital forensics, the integration of Artificial Intelligence (AI) and Machine Learning (ML) stands as a transformative technology, poised to amplify the efficiency and precision of digital forensics investigations. However, the use of ML and AI in digital forensics is still in its nascent stages. As a result, this paper gives a thorough and in-depth analysis that goes beyond a simple survey and review. The goal is to look closely at how AI and ML techniques are used ", "provider": "arxiv", "domains": ["ml_basics", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.496, "discovered_at": "2026-02-09T15:00:33.518544Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In the dynamic landscape of digital forensics, the integration of Artificial Intelligence (AI) and Machine Learning (ML) stands as a transformative technology, poised to amplify the efficiency and precision of digital forensics investigations. However, the use of ML and AI in digital forensics is still in its nascent stages. As a result, this paper gives a thorough and in-depth analysis that goes beyond a simple survey and review. The goal is to look closely at how AI and ML techniques are used in digital forensics and incident response. This research explores cutting-edge research initiatives that cross domains such as data collection and recovery, the intricate reconstruction of cybercrime timelines, robust big data analysis, pattern recognition, safeguarding the chain of custody, and orchestrating responsive strategies to hacking incidents. This endeavour digs far beneath the surface to unearth the intricate ways AI-driven methodologies are shaping these crucial facets of digital forensics practice. While the promise of AI in digital forensics is evident, the challenges arising from increasing database sizes and evolving criminal tactics necessitate ongoing collaborative research and refinement within the digital forensics profession. This study examines the contributions, limitations, and gaps in the existing research, shedding light on the potential and limitations of AI and ML techniques. By exploring these different research areas, we highlight the critical need for strategic planning, continual research, and development to unlock AI's full potential in digital forensics and incident response. Ultimately, this paper underscores the significance of AI and ML integration in digital forensics, offering insights into their benefits, drawbacks, and broader implications for tackling modern cyber threats."}}, {"id": "4996ec509045933c", "url": "http://arxiv.org/abs/1904.13353v2", "title": "Object Contour and Edge Detection with RefineContourNet", "description": "A ResNet-based multi-path refinement CNN is used for object contour detection. For this task, we prioritise the effective utilization of the high-level abstraction capability of a ResNet, which leads to state-of-the-art results for edge detection. Keeping our focus in mind, we fuse the high, mid and low-level features in that specific order, which differs from many other approaches. It uses the tensor with the highest-levelled features as the starting point to combine it layer-by-layer with feat", "provider": "arxiv", "domains": ["computer_vision", "deep_learning"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.495, "discovered_at": "2026-02-09T15:00:31.578424Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "A ResNet-based multi-path refinement CNN is used for object contour detection. For this task, we prioritise the effective utilization of the high-level abstraction capability of a ResNet, which leads to state-of-the-art results for edge detection. Keeping our focus in mind, we fuse the high, mid and low-level features in that specific order, which differs from many other approaches. It uses the tensor with the highest-levelled features as the starting point to combine it layer-by-layer with features of a lower abstraction level until it reaches the lowest level. We train this network on a modified PASCAL VOC 2012 dataset for object contour detection and evaluate on a refined PASCAL-val dataset reaching an excellent performance and an Optimal Dataset Scale (ODS) of 0.752. Furthermore, by fine-training on the BSDS500 dataset we reach state-of-the-art results for edge-detection with an ODS of 0.824."}}, {"id": "c251d8f9f64fce3d", "url": "http://arxiv.org/abs/2308.02033v1", "title": "AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI", "description": "As AI technology advances rapidly, concerns over the risks of bigness in digital markets are also growing. The EU's Digital Markets Act (DMA) aims to address these risks. Still, the current framework may not adequately cover generative AI systems that could become gateways for AI-based services. This paper argues for integrating certain AI software as core platform services and classifying certain developers as gatekeepers under the DMA. We also propose an assessment of gatekeeper obligations to", "provider": "arxiv", "domains": ["generative_ai"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.495, "discovered_at": "2026-02-09T15:00:32.131394Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "As AI technology advances rapidly, concerns over the risks of bigness in digital markets are also growing. The EU's Digital Markets Act (DMA) aims to address these risks. Still, the current framework may not adequately cover generative AI systems that could become gateways for AI-based services. This paper argues for integrating certain AI software as core platform services and classifying certain developers as gatekeepers under the DMA. We also propose an assessment of gatekeeper obligations to ensure they cover generative AI services. As the EU considers generative AI-specific rules and possible DMA amendments, this paper provides insights towards diversity and openness in generative AI services."}}, {"id": "62c5233abd2780f4", "url": "http://arxiv.org/abs/2306.06371v1", "title": "A Comprehensive Review of State-of-The-Art Methods for Java Code Generation from Natural Language Text", "description": "Java Code Generation consists in generating automatically Java code from a Natural Language Text. This NLP task helps in increasing programmers' productivity by providing them with immediate solutions to the simplest and most repetitive tasks. Code generation is a challenging task because of the hard syntactic rules and the necessity of a deep understanding of the semantic aspect of the programming language. Many works tried to tackle this task using either RNN-based, or Transformer-based models", "provider": "arxiv", "domains": ["deep_learning", "nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.493, "discovered_at": "2026-02-09T15:00:30.632588Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Java Code Generation consists in generating automatically Java code from a Natural Language Text. This NLP task helps in increasing programmers' productivity by providing them with immediate solutions to the simplest and most repetitive tasks. Code generation is a challenging task because of the hard syntactic rules and the necessity of a deep understanding of the semantic aspect of the programming language. Many works tried to tackle this task using either RNN-based, or Transformer-based models. The latter achieved remarkable advancement in the domain and they can be divided into three groups: (1) encoder-only models, (2) decoder-only models, and (3) encoder-decoder models. In this paper, we provide a comprehensive review of the evolution and progress of deep learning models in Java code generation task. We focus on the most important methods and present their merits and limitations, as well as the objective functions used by the community. In addition, we provide a detailed description of datasets and evaluation metrics used in the literature. Finally, we discuss results of different models on CONCODE dataset, then propose some future directions."}}, {"id": "7bc1892bed2a7f2c", "url": "http://arxiv.org/abs/1801.06595v1", "title": "Modelo de maturidade em gerenciamento de riscos em projetos (Project Risk Management Model Maturity)", "description": "The globalization feeded by the technology explosion that begans in the end of the last century, started the world to change faster every day. The only today's certain is the tomorrow's uncertain. Risk is defined as uncertain where one or many causes composed of ocurrence probality can generate an impact or consequence (threat if negative and oportunity if positive, to a determinated goal). The Risk Management is composed of culture, procedure and process of an organization or individual care of", "provider": "arxiv", "domains": ["ai_project_management"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.488, "discovered_at": "2026-02-09T15:00:33.791452Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The globalization feeded by the technology explosion that begans in the end of the last century, started the world to change faster every day. The only today's certain is the tomorrow's uncertain. Risk is defined as uncertain where one or many causes composed of ocurrence probality can generate an impact or consequence (threat if negative and oportunity if positive, to a determinated goal). The Risk Management is composed of culture, procedure and process of an organization or individual care of uncertain, aiming to minimize threats e maximizing the oportunities, to reach a desired goal. The \"Risk maturity model in projects\" proposed on this document, wants to measure the organizations capacity and skills to manage the riks involved in projects when adopting a generic risk management methodology."}}, {"id": "085e1e58cb63d75b", "url": "http://arxiv.org/abs/2510.12403v1", "title": "Robot Learning: A Tutorial", "description": "Robot learning is at an inflection point, driven by rapid advancements in machine learning and the growing availability of large-scale robotics data. This shift from classical, model-based methods to data-driven, learning-based paradigms is unlocking unprecedented capabilities in autonomous systems. This tutorial navigates the landscape of modern robot learning, charting a course from the foundational principles of Reinforcement Learning and Behavioral Cloning to generalist, language-conditioned", "provider": "arxiv", "domains": ["ml_basics", "reinforcement_learning"], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.487, "discovered_at": "2026-02-09T15:00:30.399652Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Robot learning is at an inflection point, driven by rapid advancements in machine learning and the growing availability of large-scale robotics data. This shift from classical, model-based methods to data-driven, learning-based paradigms is unlocking unprecedented capabilities in autonomous systems. This tutorial navigates the landscape of modern robot learning, charting a course from the foundational principles of Reinforcement Learning and Behavioral Cloning to generalist, language-conditioned models capable of operating across diverse tasks and even robot embodiments. This work is intended as a guide for researchers and practitioners, and our goal is to equip the reader with the conceptual understanding and practical tools necessary to contribute to developments in robot learning, with ready-to-use examples implemented in $\\texttt{lerobot}$."}}, {"id": "8156e5647853657d", "url": "http://arxiv.org/abs/1508.00310v2", "title": "Statistical Emulators for Pricing and Hedging Longevity Risk Products", "description": "We propose the use of statistical emulators for the purpose of valuing mortality-linked contracts in stochastic mortality models. Such models typically require (nested) evaluation of expected values of nonlinear functionals of multi-dimensional stochastic processes. Except in the simplest cases, no closed-form expressions are available, necessitating numerical approximation. Rather than building ad hoc analytic approximations, we advocate the use of modern statistical tools from machine learning", "provider": "arxiv", "domains": ["ml_basics"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.47, "discovered_at": "2026-02-09T15:00:34.336857Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We propose the use of statistical emulators for the purpose of valuing mortality-linked contracts in stochastic mortality models. Such models typically require (nested) evaluation of expected values of nonlinear functionals of multi-dimensional stochastic processes. Except in the simplest cases, no closed-form expressions are available, necessitating numerical approximation. Rather than building ad hoc analytic approximations, we advocate the use of modern statistical tools from machine learning to generate a flexible, non-parametric surrogate for the true mappings. This method allows performance guarantees regarding approximation accuracy and removes the need for nested simulation. We illustrate our approach with case studies involving (i) a Lee-Carter model with mortality shocks, (ii) index-based static hedging with longevity basis risk; (iii) a Cairns-Blake-Dowd stochastic survival probability model."}}, {"id": "d9ec4df839d89474", "url": "http://arxiv.org/abs/1907.02664v2", "title": "Data Encoding for Byzantine-Resilient Distributed Optimization", "description": "We study distributed optimization in the presence of Byzantine adversaries, where both data and computation are distributed among $m$ worker machines, $t$ of which may be corrupt. The compromised nodes may collaboratively and arbitrarily deviate from their pre-specified programs, and a designated (master) node iteratively computes the model/parameter vector for generalized linear models. In this work, we primarily focus on two iterative algorithms: Proximal Gradient Descent (PGD) and Coordinate ", "provider": "arxiv", "domains": ["ml_basics"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.468, "discovered_at": "2026-02-09T15:00:33.087254Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We study distributed optimization in the presence of Byzantine adversaries, where both data and computation are distributed among $m$ worker machines, $t$ of which may be corrupt. The compromised nodes may collaboratively and arbitrarily deviate from their pre-specified programs, and a designated (master) node iteratively computes the model/parameter vector for generalized linear models. In this work, we primarily focus on two iterative algorithms: Proximal Gradient Descent (PGD) and Coordinate Descent (CD). Gradient descent (GD) is a special case of these algorithms. PGD is typically used in the data-parallel setting, where data is partitioned across different samples, whereas, CD is used in the model-parallelism setting, where data is partitioned across the parameter space.\n  In this paper, we propose a method based on data encoding and error correction over real numbers to combat adversarial attacks. We can tolerate up to $t\\leq \\lfloor\\frac{m-1}{2}\\rfloor$ corrupt worker nodes, which is information-theoretically optimal. We give deterministic guarantees, and our method does not assume any probability distribution on the data. We develop a {\\em sparse} encoding scheme which enables computationally efficient data encoding and decoding. We demonstrate a trade-off between the corruption threshold and the resource requirements (storage, computational, and communication complexity). As an example, for $t\\leq\\frac{m}{3}$, our scheme incurs only a {\\em constant} overhead on these resources, over that required by the plain distributed PGD/CD algorithms which provide no adversarial protection. To the best of our knowledge, ours is the first paper that makes CD secure against adversarial attacks.\n  Our encoding scheme extends efficiently to the data streaming model and for stochastic gradient descent (SGD). We also give experimental results to show the efficacy of our proposed schemes."}}, {"id": "e83f5fed4afc29d5", "url": "http://arxiv.org/abs/1811.05660v1", "title": "MT-CGCNN: Integrating Crystal Graph Convolutional Neural Network with Multitask Learning for Material Property Prediction", "description": "Developing accurate, transferable and computationally inexpensive machine learning models can rapidly accelerate the discovery and development of new materials. Some of the major challenges involved in developing such models are, (i) limited availability of materials data as compared to other fields, (ii) lack of universal descriptor of materials to predict its various properties. The limited availability of materials data can be addressed through transfer learning, while the generic representat", "provider": "arxiv", "domains": ["ml_basics", "deep_learning", "computer_vision", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.459, "discovered_at": "2026-02-09T15:39:44.410118Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Developing accurate, transferable and computationally inexpensive machine learning models can rapidly accelerate the discovery and development of new materials. Some of the major challenges involved in developing such models are, (i) limited availability of materials data as compared to other fields, (ii) lack of universal descriptor of materials to predict its various properties. The limited availability of materials data can be addressed through transfer learning, while the generic representation was recently addressed by Xie and Grossman [1], where they developed a crystal graph convolutional neural network (CGCNN) that provides a unified representation of crystals. In this work, we develop a new model (MT-CGCNN) by integrating CGCNN with transfer learning based on multi-task (MT) learning. We demonstrate the effectiveness of MT-CGCNN by simultaneous prediction of various material properties such as Formation Energy, Band Gap and Fermi Energy for a wide range of inorganic crystals (46774 materials). MT-CGCNN is able to reduce the test error when employed on correlated properties by upto 8%. The model prediction has lower test error compared to CGCNN, even when the training data is reduced by 10%. We also demonstrate our model's better performance through prediction of end user scenario related to metal/non-metal classification. These results encourage further development of machine learning approaches which leverage multi-task learning to address the aforementioned challenges in the discovery of new materials. We make MT-CGCNN's source code available to encourage reproducible research."}}, {"id": "4659e75d573c669f", "url": "http://arxiv.org/abs/2508.06572v2", "title": "Teaching Introduction to Programming in the times of AI: A case study of a course re-design", "description": "The integration of AI tools into programming education has become increasingly prevalent in recent years, transforming the way programming is taught and learned. This paper provides a review of the state-of-the-art AI tools available for teaching and learning programming, particularly in the context of introductory courses. It highlights the challenges on course design, learning objectives, course delivery and formative and summative assessment, as well as the misuse of such tools by the student", "provider": "arxiv", "domains": ["ai_project_management"], "content_type": "course", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.458, "discovered_at": "2026-02-09T15:00:32.168811Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The integration of AI tools into programming education has become increasingly prevalent in recent years, transforming the way programming is taught and learned. This paper provides a review of the state-of-the-art AI tools available for teaching and learning programming, particularly in the context of introductory courses. It highlights the challenges on course design, learning objectives, course delivery and formative and summative assessment, as well as the misuse of such tools by the students. We discuss ways of re-designing an existing course, re-shaping assignments and pedagogy to address the current AI technologies challenges. This example can serve as a guideline for policies for institutions and teachers involved in teaching programming, aiming to maximize the benefits of AI tools while addressing the associated challenges and concerns."}}, {"id": "45f7d7029bdf4434", "url": "http://arxiv.org/abs/2302.08893v4", "title": "Active learning for data streams: a survey", "description": "Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this ", "provider": "arxiv", "domains": ["ml_basics", "nlp"], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.455, "discovered_at": "2026-02-09T15:00:29.196505Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many active learning strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based active learning. Pool-based active learning involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. However, the growing availability of data streams has led to an increase in the number of approaches that focus on online active learning, which involves continuously selecting and labeling observations as they arrive in a stream. This work aims to provide an overview of the most recently proposed approaches for selecting the most informative observations from data streams in real time. We review the various techniques that have been proposed and discuss their strengths and limitations, as well as the challenges and opportunities that exist in this area of research."}}, {"id": "ef5edf2eda2366ee", "url": "http://arxiv.org/abs/2107.13411v1", "title": "Predicting the Future from First Person (Egocentric) Vision: A Survey", "description": "Egocentric videos can bring a lot of information about how humans perceive the world and interact with the environment, which can be beneficial for the analysis of human behaviour. The research in egocentric video analysis is developing rapidly thanks to the increasing availability of wearable devices and the opportunities offered by new large-scale egocentric datasets. As computer vision techniques continue to develop at an increasing pace, the tasks related to the prediction of future are star", "provider": "arxiv", "domains": ["computer_vision", "reinforcement_learning", "nlp"], "content_type": "interactive_notebook", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["video analysis"], "quality_score": 0.455, "discovered_at": "2026-02-09T15:39:48.953849Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Egocentric videos can bring a lot of information about how humans perceive the world and interact with the environment, which can be beneficial for the analysis of human behaviour. The research in egocentric video analysis is developing rapidly thanks to the increasing availability of wearable devices and the opportunities offered by new large-scale egocentric datasets. As computer vision techniques continue to develop at an increasing pace, the tasks related to the prediction of future are starting to evolve from the need of understanding the present. Predicting future human activities, trajectories and interactions with objects is crucial in applications such as human-robot interaction, assistive wearable technologies for both industrial and daily living scenarios, entertainment and virtual or augmented reality. This survey summarises the evolution of studies in the context of future prediction from egocentric vision making an overview of applications, devices, existing problems, commonly used datasets, models and input modalities. Our analysis highlights that methods for future prediction from egocentric vision can have a significant impact in a range of applications and that further research efforts should be devoted to the standardisation of tasks and the proposal of datasets considering real-world scenarios such as the ones with an industrial vocation."}}, {"id": "8fb8cf888fa6a968", "url": "http://arxiv.org/abs/2509.23577v1", "title": "ML-Asset Management: Curation, Discovery, and Utilization", "description": "Machine learning (ML) assets, such as models, datasets, and metadata, are central to modern ML workflows. Despite their explosive growth in practice, these assets are often underutilized due to fragmented documentation, siloed storage, inconsistent licensing, and lack of unified discovery mechanisms, making ML-asset management an urgent challenge. This tutorial offers a comprehensive overview of ML-asset management activities across its lifecycle, including curation, discovery, and utilization. ", "provider": "arxiv", "domains": ["ml_basics", "ai_governance"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.435, "discovered_at": "2026-02-09T15:00:33.833176Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Machine learning (ML) assets, such as models, datasets, and metadata, are central to modern ML workflows. Despite their explosive growth in practice, these assets are often underutilized due to fragmented documentation, siloed storage, inconsistent licensing, and lack of unified discovery mechanisms, making ML-asset management an urgent challenge. This tutorial offers a comprehensive overview of ML-asset management activities across its lifecycle, including curation, discovery, and utilization. We provide a categorization of ML assets, and major management issues, survey state-of-the-art techniques, and identify emerging opportunities at each stage. We further highlight system-level challenges related to scalability, lineage, and unified indexing. Through live demonstrations of systems, this tutorial equips both researchers and practitioners with actionable insights and practical tools for advancing ML-asset management in real-world and domain-specific settings."}}, {"id": "3587bedc86fbb60d", "url": "http://arxiv.org/abs/2307.03198v2", "title": "A multilevel framework for AI governance", "description": "To realize the potential benefits and mitigate potential risks of AI, it is necessary to develop a framework of governance that conforms to ethics and fundamental human values. Although several organizations have issued guidelines and ethical frameworks for trustworthy AI, without a mediating governance structure, these ethical principles will not translate into practice. In this paper, we propose a multilevel governance approach that involves three groups of interdependent stakeholders: governm", "provider": "arxiv", "domains": ["ai_governance", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.432, "discovered_at": "2026-02-09T15:00:34.255833Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "To realize the potential benefits and mitigate potential risks of AI, it is necessary to develop a framework of governance that conforms to ethics and fundamental human values. Although several organizations have issued guidelines and ethical frameworks for trustworthy AI, without a mediating governance structure, these ethical principles will not translate into practice. In this paper, we propose a multilevel governance approach that involves three groups of interdependent stakeholders: governments, corporations, and citizens. We examine their interrelationships through dimensions of trust, such as competence, integrity, and benevolence. The levels of governance combined with the dimensions of trust in AI provide practical insights that can be used to further enhance user experiences and inform public policy related to AI."}}, {"id": "911f23c02f3189b3", "url": "http://arxiv.org/abs/2401.15284v6", "title": "Beyond principlism: Practical strategies for ethical AI use in research practices", "description": "The rapid adoption of generative artificial intelligence (AI) in scientific research, particularly large language models (LLMs), has outpaced the development of ethical guidelines, leading to a \"Triple-Too\" problem: too many high-level ethical initiatives, too abstract principles lacking contextual and practical relevance, and too much focus on restrictions and risks over benefits and utilities. Existing approaches--principlism (reliance on abstract ethical principles), formalism (rigid applicat", "provider": "arxiv", "domains": ["ai_ethics", "nlp", "generative_ai", "ai_governance"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": ["privacy"], "quality_score": 0.43, "discovered_at": "2026-02-09T15:00:33.312272Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The rapid adoption of generative artificial intelligence (AI) in scientific research, particularly large language models (LLMs), has outpaced the development of ethical guidelines, leading to a \"Triple-Too\" problem: too many high-level ethical initiatives, too abstract principles lacking contextual and practical relevance, and too much focus on restrictions and risks over benefits and utilities. Existing approaches--principlism (reliance on abstract ethical principles), formalism (rigid application of rules), and technological solutionism (overemphasis on technological fixes)--offer little practical guidance for addressing ethical challenges of AI in scientific research practices. To bridge the gap between abstract principles and day-to-day research practices, a user-centered, realism-inspired approach is proposed here. It outlines five specific goals for ethical AI use: 1) understanding model training and output, including bias mitigation strategies; 2) respecting privacy, confidentiality, and copyright; 3) avoiding plagiarism and policy violations; 4) applying AI beneficially compared to alternatives; and 5) using AI transparently and reproducibly. Each goal is accompanied by actionable strategies and realistic cases of misuse and corrective measures. I argue that ethical AI application requires evaluating its utility against existing alternatives rather than isolated performance metrics. Additionally, I propose documentation guidelines to enhance transparency and reproducibility in AI-assisted research. Moving forward, we need targeted professional development, training programs, and balanced enforcement mechanisms to promote responsible AI use while fostering innovation. By refining these ethical guidelines and adapting them to emerging AI capabilities, we can accelerate scientific progress without compromising research integrity."}}, {"id": "55db98f8d7e2644d", "url": "http://arxiv.org/abs/2104.09630v2", "title": "Quaternion Generative Adversarial Networks", "description": "Latest Generative Adversarial Networks (GANs) are gathering outstanding results through a large-scale training, thus employing models composed of millions of parameters requiring extensive computational capabilities. Building such huge models undermines their replicability and increases the training instability. Moreover, multi-channel data, such as images or audio, are usually processed by realvalued convolutional networks that flatten and concatenate the input, often losing intra-channel spati", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.425, "discovered_at": "2026-02-09T15:00:32.415403Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Latest Generative Adversarial Networks (GANs) are gathering outstanding results through a large-scale training, thus employing models composed of millions of parameters requiring extensive computational capabilities. Building such huge models undermines their replicability and increases the training instability. Moreover, multi-channel data, such as images or audio, are usually processed by realvalued convolutional networks that flatten and concatenate the input, often losing intra-channel spatial relations. To address these issues related to complexity and information loss, we propose a family of quaternion-valued generative adversarial networks (QGANs). QGANs exploit the properties of quaternion algebra, e.g., the Hamilton product, that allows to process channels as a single entity and capture internal latent relations, while reducing by a factor of 4 the overall number of parameters. We show how to design QGANs and to extend the proposed approach even to advanced models.We compare the proposed QGANs with real-valued counterparts on several image generation benchmarks. Results show that QGANs are able to obtain better FID scores than real-valued GANs and to generate visually pleasing images. Furthermore, QGANs save up to 75% of the training parameters. We believe these results may pave the way to novel, more accessible, GANs capable of improving performance and saving computational resources."}}, {"id": "2a123a504b8b7b35", "url": "http://arxiv.org/abs/2208.00766v1", "title": "Tutorial on the development of AI models for medical image analysis", "description": "The idea of using computers to read medical scans was introduced as early as 1966. However, limits to machine learning technology meant progress was slow initially. The Alexnet breakthrough in 2012 sparked new interest in the topic, which resulted in the release of 100s of medical AI solutions on the market. In spite of success for some diseases and modalities, many challenges remain. Research typically focuses on the development of specific applications or techniques, clinical evaluation, or me", "provider": "arxiv", "domains": ["ml_basics"], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.412, "discovered_at": "2026-02-09T15:00:31.399172Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The idea of using computers to read medical scans was introduced as early as 1966. However, limits to machine learning technology meant progress was slow initially. The Alexnet breakthrough in 2012 sparked new interest in the topic, which resulted in the release of 100s of medical AI solutions on the market. In spite of success for some diseases and modalities, many challenges remain. Research typically focuses on the development of specific applications or techniques, clinical evaluation, or meta analysis of clinical studies or techniques through surveys or challenges. However, limited attention has been given to the development process of improving real world performance. In this tutorial, we address the latter and discuss some techniques to conduct the development process in order to make this as efficient as possible."}}, {"id": "f31e3b22ad343b24", "url": "http://arxiv.org/abs/2508.06547v1", "title": "A tutorial note on collecting simulated data for vision-language-action models", "description": "Traditional robotic systems typically decompose intelligence into independent modules for computer vision, natural language processing, and motion control. Vision-Language-Action (VLA) models fundamentally transform this approach by employing a single neural network that can simultaneously process visual observations, understand human instructions, and directly output robot actions -- all within a unified framework. However, these systems are highly dependent on high-quality training datasets th", "provider": "arxiv", "domains": ["deep_learning", "nlp", "computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.412, "discovered_at": "2026-02-09T15:39:52.892353Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Traditional robotic systems typically decompose intelligence into independent modules for computer vision, natural language processing, and motion control. Vision-Language-Action (VLA) models fundamentally transform this approach by employing a single neural network that can simultaneously process visual observations, understand human instructions, and directly output robot actions -- all within a unified framework. However, these systems are highly dependent on high-quality training datasets that can capture the complex relationships between visual observations, language instructions, and robotic actions. This tutorial reviews three representative systems: the PyBullet simulation framework for flexible customized data generation, the LIBERO benchmark suite for standardized task definition and evaluation, and the RT-X dataset collection for large-scale multi-robot data acquisition. We demonstrated dataset generation approaches in PyBullet simulation and customized data collection within LIBERO, and provide an overview of the characteristics and roles of the RT-X dataset for large-scale multi-robot data acquisition."}}, {"id": "2e83205e19c0805b", "url": "http://arxiv.org/abs/1610.01076v1", "title": "Tutorial on Answering Questions about Images with Deep Learning", "description": "Together with the development of more accurate methods in Computer Vision and Natural Language Understanding, holistic architectures that answer on questions about the content of real-world images have emerged. In this tutorial, we build a neural-based approach to answer questions about images. We base our tutorial on two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the models that we present here can achieve a competitive performance on both datasets, in fact, they are am", "provider": "arxiv", "domains": ["deep_learning", "computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.411, "discovered_at": "2026-02-09T15:00:30.229209Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Together with the development of more accurate methods in Computer Vision and Natural Language Understanding, holistic architectures that answer on questions about the content of real-world images have emerged. In this tutorial, we build a neural-based approach to answer questions about images. We base our tutorial on two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the models that we present here can achieve a competitive performance on both datasets, in fact, they are among the best methods that use a combination of LSTM with a global, full frame CNN representation of an image. We hope that after reading this tutorial, the reader will be able to use Deep Learning frameworks, such as Keras and introduced Kraino, to build various architectures that will lead to a further performance improvement on this challenging task."}}, {"id": "0a74842ec4fd0f5d", "url": "http://arxiv.org/abs/2111.07555v1", "title": "Confucius, Cyberpunk and Mr. Science: Comparing AI ethics between China and the EU", "description": "The exponential development and application of artificial intelligence triggered an unprecedented global concern for potential social and ethical issues. Stakeholders from different industries, international foundations, governmental organisations and standards institutions quickly improvised and created various codes of ethics attempting to regulate AI. A major concern is the large homogeneity and presumed consensualism around these principles. While it is true that some ethical doctrines, such", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.41, "discovered_at": "2026-02-09T15:00:33.592552Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The exponential development and application of artificial intelligence triggered an unprecedented global concern for potential social and ethical issues. Stakeholders from different industries, international foundations, governmental organisations and standards institutions quickly improvised and created various codes of ethics attempting to regulate AI. A major concern is the large homogeneity and presumed consensualism around these principles. While it is true that some ethical doctrines, such as the famous Kantian deontology, aspire to universalism, they are however not universal in practice. In fact, ethical pluralism is more about differences in which relevant questions to ask rather than different answers to a common question. When people abide by different moral doctrines, they tend to disagree on the very approach to an issue. Even when people from different cultures happen to agree on a set of common principles, it does not necessarily mean that they share the same understanding of these concepts and what they entail. In order to better understand the philosophical roots and cultural context underlying ethical principles in AI, we propose to analyse and compare the ethical principles endorsed by the Chinese National New Generation Artificial Intelligence Governance Professional Committee (CNNGAIGPC) and those elaborated by the European High-level Expert Group on AI (HLEGAI). China and the EU have very different political systems and diverge in their cultural heritages. In our analysis, we wish to highlight that principles that seem similar a priori may actually have different meanings, derived from different approaches and reflect distinct goals."}}, {"id": "5874e7eebe01323f", "url": "http://arxiv.org/abs/2510.11595v1", "title": "Reproducibility: The New Frontier in AI Governance", "description": "AI policymakers are responsible for delivering effective governance mechanisms that can provide safe, aligned and trustworthy AI development. However, the information environment offered to policymakers is characterised by an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and creating deep uncertainty and divides on which risks should be prioritised from a governance perspective. We posit that the current publication speeds in AI combined with the lack of strong scientific", "provider": "arxiv", "domains": ["reinforcement_learning", "ai_governance"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.41, "discovered_at": "2026-02-09T15:00:34.133829Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "AI policymakers are responsible for delivering effective governance mechanisms that can provide safe, aligned and trustworthy AI development. However, the information environment offered to policymakers is characterised by an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and creating deep uncertainty and divides on which risks should be prioritised from a governance perspective. We posit that the current publication speeds in AI combined with the lack of strong scientific standards, via weak reproducibility protocols, effectively erodes the power of policymakers to enact meaningful policy and governance protocols. Our paper outlines how AI research could adopt stricter reproducibility guidelines to assist governance endeavours and improve consensus on the AI risk landscape. We evaluate the forthcoming reproducibility crisis within AI research through the lens of crises in other scientific domains; providing a commentary on how adopting preregistration, increased statistical power and negative result publication reproducibility protocols can enable effective AI governance. While we maintain that AI governance must be reactive due to AI's significant societal implications we argue that policymakers and governments must consider reproducibility protocols as a core tool in the governance arsenal and demand higher standards for AI research. Code to replicate data and figures: https://github.com/IFMW01/reproducibility-the-new-frontier-in-ai-governance"}}, {"id": "cb811a0d9e7684e5", "url": "http://arxiv.org/abs/2404.16205v1", "title": "AIS 2024 Challenge on Video Quality Assessment of User-Generated Content: Methods and Results", "description": "This paper reviews the AIS 2024 Video Quality Assessment (VQA) Challenge, focused on User-Generated Content (UGC). The aim of this challenge is to gather deep learning-based methods capable of estimating the perceptual quality of UGC videos. The user-generated videos from the YouTube UGC Dataset include diverse content (sports, games, lyrics, anime, etc.), quality and resolutions. The proposed methods must process 30 FHD frames under 1 second. In the challenge, a total of 102 participants regist", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.2, "prerequisites": [], "tags": [], "quality_score": 0.409, "discovered_at": "2026-02-09T15:00:32.252154Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper reviews the AIS 2024 Video Quality Assessment (VQA) Challenge, focused on User-Generated Content (UGC). The aim of this challenge is to gather deep learning-based methods capable of estimating the perceptual quality of UGC videos. The user-generated videos from the YouTube UGC Dataset include diverse content (sports, games, lyrics, anime, etc.), quality and resolutions. The proposed methods must process 30 FHD frames under 1 second. In the challenge, a total of 102 participants registered, and 15 submitted code and models. The performance of the top-5 submissions is reviewed and provided here as a survey of diverse deep models for efficient video quality assessment of user-generated content."}}, {"id": "9586eb5247cafc0e", "url": "http://arxiv.org/abs/2504.16770v1", "title": "DeBiasMe: De-biasing Human-AI Interactions with Metacognitive AIED (AI in Education) Interventions", "description": "While generative artificial intelligence (Gen AI) increasingly transforms academic environments, a critical gap exists in understanding and mitigating human biases in AI interactions, such as anchoring and confirmation bias. This position paper advocates for metacognitive AI literacy interventions to help university students critically engage with AI and address biases across the Human-AI interaction workflows. The paper presents the importance of considering (1) metacognitive support with delib", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.405, "discovered_at": "2026-02-09T15:18:50.247521Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "While generative artificial intelligence (Gen AI) increasingly transforms academic environments, a critical gap exists in understanding and mitigating human biases in AI interactions, such as anchoring and confirmation bias. This position paper advocates for metacognitive AI literacy interventions to help university students critically engage with AI and address biases across the Human-AI interaction workflows. The paper presents the importance of considering (1) metacognitive support with deliberate friction focusing on human bias; (2) bi-directional Human-AI interaction intervention addressing both input formulation and output interpretation; and (3) adaptive scaffolding that responds to diverse user engagement patterns. These frameworks are illustrated through ongoing work on \"DeBiasMe,\" AIED (AI in Education) interventions designed to enhance awareness of cognitive biases while empowering user agency in AI interactions. The paper invites multiple stakeholders to engage in discussions on design and evaluation methods for scaffolding mechanisms, bias visualization, and analysis frameworks. This position contributes to the emerging field of AI-augmented learning by emphasizing the critical role of metacognition in helping students navigate the complex interaction between human, statistical, and systemic biases in AI use while highlighting how cognitive adaptation to AI systems must be explicitly integrated into comprehensive AI literacy frameworks."}}, {"id": "6a196a895659647d", "url": "http://arxiv.org/abs/2312.10864v1", "title": "On-Device Recommender Systems: A Tutorial on The New-Generation Recommendation Paradigm", "description": "Given the sheer volume of contemporary e-commerce applications, recommender systems (RSs) have gained significant attention in both academia and industry. However, traditional cloud-based RSs face inevitable challenges, such as resource-intensive computation, reliance on network access, and privacy breaches. In response, a new paradigm called on-device recommender systems (ODRSs) has emerged recently in various industries like Taobao, Google, and Kuaishou. ODRSs unleash the computational capacit", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.405, "discovered_at": "2026-02-09T15:39:51.380467Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Given the sheer volume of contemporary e-commerce applications, recommender systems (RSs) have gained significant attention in both academia and industry. However, traditional cloud-based RSs face inevitable challenges, such as resource-intensive computation, reliance on network access, and privacy breaches. In response, a new paradigm called on-device recommender systems (ODRSs) has emerged recently in various industries like Taobao, Google, and Kuaishou. ODRSs unleash the computational capacity of user devices with lightweight recommendation models tailored for resource-constrained environments, enabling real-time inference with users' local data. This tutorial aims to systematically introduce methodologies of ODRSs, including (1) an overview of existing research on ODRSs; (2) a comprehensive taxonomy of ODRSs, where the core technical content to be covered span across three major ODRS research directions, including on-device deployment and inference, on-device training, and privacy/security of ODRSs; (3) limitations and future directions of ODRSs. This tutorial expects to lay the foundation and spark new insights for follow-up research and applications concerning this new recommendation paradigm."}}, {"id": "035d205ccb0206a6", "url": "http://arxiv.org/abs/1409.1484v3", "title": "The Evolution of First Person Vision Methods: A Survey", "description": "The emergence of new wearable technologies such as action cameras and smart-glasses has increased the interest of computer vision scientists in the First Person perspective. Nowadays, this field is attracting attention and investments of companies aiming to develop commercial devices with First Person Vision recording capabilities. Due to this interest, an increasing demand of methods to process these videos, possibly in real-time, is expected. Current approaches present a particular combination", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.403, "discovered_at": "2026-02-09T15:00:31.251445Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The emergence of new wearable technologies such as action cameras and smart-glasses has increased the interest of computer vision scientists in the First Person perspective. Nowadays, this field is attracting attention and investments of companies aiming to develop commercial devices with First Person Vision recording capabilities. Due to this interest, an increasing demand of methods to process these videos, possibly in real-time, is expected. Current approaches present a particular combinations of different image features and quantitative methods to accomplish specific objectives like object detection, activity recognition, user machine interaction and so on. This paper summarizes the evolution of the state of the art in First Person Vision video analysis between 1997 and 2014, highlighting, among others, most commonly used features, methods, challenges and opportunities within the field."}}, {"id": "c3f9900d04e3e192", "url": "http://arxiv.org/abs/2506.09954v1", "title": "Vision Generalist Model: A Survey", "description": "Recently, we have witnessed the great success of the generalist model in natural language processing. The generalist model is a general framework trained with massive data and is able to process various downstream tasks simultaneously. Encouraged by their impressive performance, an increasing number of researchers are venturing into the realm of applying these models to computer vision tasks. However, the inputs and outputs of vision tasks are more diverse, and it is difficult to summarize them ", "provider": "arxiv", "domains": ["nlp", "computer_vision"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.403, "discovered_at": "2026-02-09T15:00:31.286742Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Recently, we have witnessed the great success of the generalist model in natural language processing. The generalist model is a general framework trained with massive data and is able to process various downstream tasks simultaneously. Encouraged by their impressive performance, an increasing number of researchers are venturing into the realm of applying these models to computer vision tasks. However, the inputs and outputs of vision tasks are more diverse, and it is difficult to summarize them as a unified representation. In this paper, we provide a comprehensive overview of the vision generalist models, delving into their characteristics and capabilities within the field. First, we review the background, including the datasets, tasks, and benchmarks. Then, we dig into the design of frameworks that have been proposed in existing research, while also introducing the techniques employed to enhance their performance. To better help the researchers comprehend the area, we take a brief excursion into related domains, shedding light on their interconnections and potential synergies. To conclude, we provide some real-world application scenarios, undertake a thorough examination of the persistent challenges, and offer insights into possible directions for future research endeavors."}}, {"id": "b0c79be994d2ebbb", "url": "http://arxiv.org/abs/2602.00751v1", "title": "Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance", "description": "The integration of Artificial Intelligence (AI) into clinical settings presents a software engineering challenge, demanding a shift from isolated models to robust, governable, and reliable systems. However, brittle, prototype-derived architectures often plague industrial applications and a lack of systemic oversight, creating a ``responsibility vacuum'' where safety and accountability are compromised. This paper presents an industry case study of the ``Maria'' platform, a production-grade AI sys", "provider": "arxiv", "domains": ["mlops", "generative_ai", "ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.403, "discovered_at": "2026-02-09T15:39:54.589349Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The integration of Artificial Intelligence (AI) into clinical settings presents a software engineering challenge, demanding a shift from isolated models to robust, governable, and reliable systems. However, brittle, prototype-derived architectures often plague industrial applications and a lack of systemic oversight, creating a ``responsibility vacuum'' where safety and accountability are compromised. This paper presents an industry case study of the ``Maria'' platform, a production-grade AI system in primary healthcare that addresses this gap.\n  Our central hypothesis is that trustworthy clinical AI is achieved through the holistic integration of four foundational engineering pillars. We present a synergistic architecture that combines Clean Architecture for maintainability with an Event-driven architecture for resilience and auditability. We introduce the Agent as the primary unit of modularity, each possessing its own autonomous MLOps lifecycle. Finally, we show how a Human-in-the-Loop governance model is technically integrated not merely as a safety check, but as a critical, event-driven data source for continuous improvement. We present the platform as a reference architecture, offering practical lessons for engineers building maintainable, scalable, and accountable AI-enabled systems in high-stakes domains."}}, {"id": "3699a81a6589fe91", "url": "http://arxiv.org/abs/2407.20663v1", "title": "ArabicNLU 2024: The First Arabic Natural Language Understanding Shared Task", "description": "This paper presents an overview of the Arabic Natural Language Understanding (ArabicNLU 2024) shared task, focusing on two subtasks: Word Sense Disambiguation (WSD) and Location Mention Disambiguation (LMD). The task aimed to evaluate the ability of automated systems to resolve word ambiguity and identify locations mentioned in Arabic text. We provided participants with novel datasets, including a sense-annotated corpus for WSD, called SALMA with approximately 34k annotated tokens, and the IDRIS", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.402, "discovered_at": "2026-02-09T15:00:30.756409Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper presents an overview of the Arabic Natural Language Understanding (ArabicNLU 2024) shared task, focusing on two subtasks: Word Sense Disambiguation (WSD) and Location Mention Disambiguation (LMD). The task aimed to evaluate the ability of automated systems to resolve word ambiguity and identify locations mentioned in Arabic text. We provided participants with novel datasets, including a sense-annotated corpus for WSD, called SALMA with approximately 34k annotated tokens, and the IDRISI-DA dataset with 3,893 annotations and 763 unique location mentions. These are challenging tasks. Out of the 38 registered teams, only three teams participated in the final evaluation phase, with the highest accuracy being 77.8% for WSD and the highest MRR@1 being 95.0% for LMD. The shared task not only facilitated the evaluation and comparison of different techniques, but also provided valuable insights and resources for the continued advancement of Arabic NLU technologies."}}, {"id": "943b5e3668b8a4da", "url": "http://arxiv.org/abs/2402.13302v1", "title": "Enhancing Modern Supervised Word Sense Disambiguation Models by Semantic Lexical Resources", "description": "Supervised models for Word Sense Disambiguation (WSD) currently yield to state-of-the-art results in the most popular benchmarks. Despite the recent introduction of Word Embeddings and Recurrent Neural Networks to design powerful context-related features, the interest in improving WSD models using Semantic Lexical Resources (SLRs) is mostly restricted to knowledge-based approaches. In this paper, we enhance \"modern\" supervised WSD models exploiting two popular SLRs: WordNet and WordNet Domains. ", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.4, "discovered_at": "2026-02-09T15:00:31.362276Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Supervised models for Word Sense Disambiguation (WSD) currently yield to state-of-the-art results in the most popular benchmarks. Despite the recent introduction of Word Embeddings and Recurrent Neural Networks to design powerful context-related features, the interest in improving WSD models using Semantic Lexical Resources (SLRs) is mostly restricted to knowledge-based approaches. In this paper, we enhance \"modern\" supervised WSD models exploiting two popular SLRs: WordNet and WordNet Domains. We propose an effective way to introduce semantic features into the classifiers, and we consider using the SLR structure to augment the training data. We study the effect of different types of semantic features, investigating their interaction with local contexts encoded by means of mixtures of Word Embeddings or Recurrent Neural Networks, and we extend the proposed model into a novel multi-layer architecture for WSD. A detailed experimental comparison in the recent Unified Evaluation Framework (Raganato et al., 2017) shows that the proposed approach leads to supervised models that compare favourably with the state-of-the art."}}, {"id": "19d2e5bebd3b6c6a", "url": "http://arxiv.org/abs/1803.09898v4", "title": "On Fairness of Systemic Risk Measures", "description": "In our previous paper, \"A Unified Approach to Systemic Risk Measures via Acceptance Set\" (\\textit{Mathematical Finance, 2018}), we have introduced a general class of systemic risk measures that allow for random allocations to individual banks before aggregation of their risks. In the present paper, we prove the dual representation of a particular subclass of such systemic risk measures and the existence and uniqueness of the optimal allocation related to them. We also introduce an associated uti", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.4, "discovered_at": "2026-02-09T15:18:54.717917Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In our previous paper, \"A Unified Approach to Systemic Risk Measures via Acceptance Set\" (\\textit{Mathematical Finance, 2018}), we have introduced a general class of systemic risk measures that allow for random allocations to individual banks before aggregation of their risks. In the present paper, we prove the dual representation of a particular subclass of such systemic risk measures and the existence and uniqueness of the optimal allocation related to them. We also introduce an associated utility maximization problem which has the same optimal solution as the systemic risk measure. In addition, the optimizer in the dual formulation provides a \\textit{risk allocation} which is fair from the point of view of the individual financial institutions. The case with exponential utilities which allows for explicit computation is treated in details."}}, {"id": "9284131a95108f8c", "url": "http://arxiv.org/abs/2302.04143v2", "title": "Predicting Thrombectomy Recanalization from CT Imaging Using Deep Learning Models", "description": "For acute ischemic stroke (AIS) patients with large vessel occlusions, clinicians must decide if the benefit of mechanical thrombectomy (MTB) outweighs the risks and potential complications following an invasive procedure. Pre-treatment computed tomography (CT) and angiography (CTA) are widely used to characterize occlusions in the brain vasculature. If a patient is deemed eligible, a modified treatment in cerebral ischemia (mTICI) score will be used to grade how well blood flow is reestablished", "provider": "arxiv", "domains": ["deep_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.4, "discovered_at": "2026-02-09T15:39:46.112271Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "For acute ischemic stroke (AIS) patients with large vessel occlusions, clinicians must decide if the benefit of mechanical thrombectomy (MTB) outweighs the risks and potential complications following an invasive procedure. Pre-treatment computed tomography (CT) and angiography (CTA) are widely used to characterize occlusions in the brain vasculature. If a patient is deemed eligible, a modified treatment in cerebral ischemia (mTICI) score will be used to grade how well blood flow is reestablished throughout and following the MTB procedure. An estimation of the likelihood of successful recanalization can support treatment decision-making. In this study, we proposed a fully automated prediction of a patient's recanalization score using pre-treatment CT and CTA imaging. We designed a spatial cross attention network (SCANet) that utilizes vision transformers to localize to pertinent slices and brain regions. Our top model achieved an average cross-validated ROC-AUC of 77.33 $\\pm$ 3.9\\%. This is a promising result that supports future applications of deep learning on CT and CTA for the identification of eligible AIS patients for MTB."}}, {"id": "83a4f8ee68e1de80", "url": "http://arxiv.org/abs/2409.14702v2", "title": "Rate-Splitting for Cell-Free Massive MIMO: Performance Analysis and Generative AI Approach", "description": "Cell-free (CF) massive multiple-input multipleoutput (MIMO) provides a ubiquitous coverage to user equipments (UEs) but it is also susceptible to interference. Ratesplitting (RS) effectively extracts data by decoding interference, yet its effectiveness is limited by the weakest UE. In this paper, we investigate an RS-based CF massive MIMO system, which combines strengths and mitigates weaknesses of both approaches. Considering imperfect channel state information (CSI) resulting from both pilot c", "provider": "arxiv", "domains": ["generative_ai"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.398, "discovered_at": "2026-02-09T15:18:50.064638Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Cell-free (CF) massive multiple-input multipleoutput (MIMO) provides a ubiquitous coverage to user equipments (UEs) but it is also susceptible to interference. Ratesplitting (RS) effectively extracts data by decoding interference, yet its effectiveness is limited by the weakest UE. In this paper, we investigate an RS-based CF massive MIMO system, which combines strengths and mitigates weaknesses of both approaches. Considering imperfect channel state information (CSI) resulting from both pilot contamination and noise, we derive a closed-form expression for the sum spectral efficiency (SE) of the RS-based CF massive MIMO system under a spatially correlated Rician channel. Moreover, we propose low-complexity heuristic algorithms based on statistical CSI for power-splitting of common messages and power-control of private messages, and genetic algorithm is adopted as a solution for upper bound performance. Furthermore, we formulate a joint optimization problem, aiming to maximize the sum SE of the RS-based CF massive MIMO system by optimizing the power-splitting factor and power-control coefficient. Importantly, we improve a generative AI (GAI) algorithm to address this complex and nonconvexity problem by using a diffusion model to obtain solutions. Simulation results demonstrate its effectiveness and practicality in mitigating interference, especially in dynamic environments."}}, {"id": "9a375f76dc475b91", "url": "http://arxiv.org/abs/1807.03021v2", "title": "Verisimilar Image Synthesis for Accurate Detection and Recognition of Texts in Scenes", "description": "The requirement of large amounts of annotated images has become one grand challenge while training deep neural network models for various visual detection and recognition tasks. This paper presents a novel image synthesis technique that aims to generate a large amount of annotated scene text images for training accurate and robust scene text detection and recognition models. The proposed technique consists of three innovative designs. First, it realizes \"semantic coherent\" synthesis by embedding", "provider": "arxiv", "domains": ["deep_learning", "nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.398, "discovered_at": "2026-02-09T15:39:49.727543Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The requirement of large amounts of annotated images has become one grand challenge while training deep neural network models for various visual detection and recognition tasks. This paper presents a novel image synthesis technique that aims to generate a large amount of annotated scene text images for training accurate and robust scene text detection and recognition models. The proposed technique consists of three innovative designs. First, it realizes \"semantic coherent\" synthesis by embedding texts at semantically sensible regions within the background image, where the semantic coherence is achieved by leveraging the semantic annotations of objects and image regions that have been created in the prior semantic segmentation research. Second, it exploits visual saliency to determine the embedding locations within each semantic sensible region, which coincides with the fact that texts are often placed around homogeneous regions for better visibility in scenes. Third, it designs an adaptive text appearance model that determines the color and brightness of embedded texts by learning from the feature of real scene text images adaptively. The proposed technique has been evaluated over five public datasets and the experiments show its superior performance in training accurate and robust scene text detection and recognition models."}}, {"id": "d2003d4866453798", "url": "http://arxiv.org/abs/1812.09648v1", "title": "Chinese Herbal Recognition based on Competitive Attentional Fusion of Multi-hierarchies Pyramid Features", "description": "Convolution neural netwotks (CNNs) are successfully applied in image recognition task. In this study, we explore the approach of automatic herbal recognition with CNNs and build the standard Chinese herbs datasets firstly. According to the characteristics of herbal images, we proposed the competitive attentional fusion pyramid networks to model the features of herbal image, which mdoels the relationship of feature maps from different levels, and re-weights multi-level channels with channel-wise ", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.396, "discovered_at": "2026-02-09T15:00:31.506212Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Convolution neural netwotks (CNNs) are successfully applied in image recognition task. In this study, we explore the approach of automatic herbal recognition with CNNs and build the standard Chinese herbs datasets firstly. According to the characteristics of herbal images, we proposed the competitive attentional fusion pyramid networks to model the features of herbal image, which mdoels the relationship of feature maps from different levels, and re-weights multi-level channels with channel-wise attention mechanism. In this way, we can dynamically adjust the weight of feature maps from various layers, according to the visual characteristics of each herbal image. Moreover, we also introduce the spatial attention to recalibrate the misaligned features caused by sampling in features amalgamation. Extensive experiments are conducted on our proposed datasets and validate the superior performance of our proposed models. The Chinese herbs datasets will be released upon acceptance to facilitate the research of Chinese herbal recognition."}}, {"id": "6535f2164c3393d6", "url": "http://arxiv.org/abs/2005.07866v1", "title": "Byzantine-Resilient SGD in High Dimensions on Heterogeneous Data", "description": "We study distributed stochastic gradient descent (SGD) in the master-worker architecture under Byzantine attacks. We consider the heterogeneous data model, where different workers may have different local datasets, and we do not make any probabilistic assumptions on data generation. At the core of our algorithm, we use the polynomial-time outlier-filtering procedure for robust mean estimation proposed by Steinhardt et al. (ITCS 2018) to filter-out corrupt gradients. In order to be able to apply ", "provider": "arxiv", "domains": ["ml_basics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.396, "discovered_at": "2026-02-09T15:00:33.046760Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We study distributed stochastic gradient descent (SGD) in the master-worker architecture under Byzantine attacks. We consider the heterogeneous data model, where different workers may have different local datasets, and we do not make any probabilistic assumptions on data generation. At the core of our algorithm, we use the polynomial-time outlier-filtering procedure for robust mean estimation proposed by Steinhardt et al. (ITCS 2018) to filter-out corrupt gradients. In order to be able to apply their filtering procedure in our {\\em heterogeneous} data setting where workers compute {\\em stochastic} gradients, we derive a new matrix concentration result, which may be of independent interest.\n  We provide convergence analyses for smooth strongly-convex and non-convex objectives. We derive our results under the bounded variance assumption on local stochastic gradients and a {\\em deterministic} condition on datasets, namely, gradient dissimilarity; and for both these quantities, we provide concrete bounds in the statistical heterogeneous data model. We give a trade-off between the mini-batch size for stochastic gradients and the approximation error. Our algorithm can tolerate up to $\\frac{1}{4}$ fraction Byzantine workers. It can find approximate optimal parameters in the strongly-convex setting exponentially fast and reach to an approximate stationary point in the non-convex setting with a linear speed, thus, matching the convergence rates of vanilla SGD in the Byzantine-free setting.\n  We also propose and analyze a Byzantine-resilient SGD algorithm with gradient compression, where workers send $k$ random coordinates of their gradients. Under mild conditions, we show a $\\frac{d}{k}$-factor saving in communication bits as well as decoding complexity over our compression-free algorithm without affecting its convergence rate (order-wise) and the approximation error."}}, {"id": "515666304886d698", "url": "http://arxiv.org/abs/2408.00025v3", "title": "Need of AI in Modern Education: in the Eyes of Explainable AI (xAI)", "description": "Modern Education is not \\textit{Modern} without AI. However, AI's complex nature makes understanding and fixing problems challenging. Research worldwide shows that a parent's income greatly influences a child's education. This led us to explore how AI, especially complex models, makes important decisions using Explainable AI tools. Our research uncovered many complexities linked to parental income and offered reasonable explanations for these decisions. However, we also found biases in AI that g", "provider": "arxiv", "domains": ["ai_ethics"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.394, "discovered_at": "2026-02-09T15:00:33.436353Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Modern Education is not \\textit{Modern} without AI. However, AI's complex nature makes understanding and fixing problems challenging. Research worldwide shows that a parent's income greatly influences a child's education. This led us to explore how AI, especially complex models, makes important decisions using Explainable AI tools. Our research uncovered many complexities linked to parental income and offered reasonable explanations for these decisions. However, we also found biases in AI that go against what we want from AI in education: clear transparency and equal access for everyone. These biases can impact families and children's schooling, highlighting the need for better AI solutions that offer fair opportunities to all. This chapter tries to shed light on the complex ways AI operates, especially concerning biases. These are the foundational steps towards better educational policies, which include using AI in ways that are more reliable, accountable, and beneficial for everyone involved."}}, {"id": "1d170051602cc407", "url": "http://arxiv.org/abs/2104.04068v2", "title": "Embedding Sustainability in Complex Projects: A Pedagogic Practice Simulation Approach", "description": "Sustainability is focussed on avoiding the long-term depletion of natural resources. Under the terms of a government plan to tackle climate change, a driver for improved sustainability is the cut of greenhouse gas emissions in the UK to almost zero by 2050. With this type of change, new themes are continuously being developed which drive complex projects, such as the development of new power generation methods, which encompass challenging lead times and demanding requirements. Consideration of t", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.394, "discovered_at": "2026-02-09T15:00:33.745780Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Sustainability is focussed on avoiding the long-term depletion of natural resources. Under the terms of a government plan to tackle climate change, a driver for improved sustainability is the cut of greenhouse gas emissions in the UK to almost zero by 2050. With this type of change, new themes are continuously being developed which drive complex projects, such as the development of new power generation methods, which encompass challenging lead times and demanding requirements. Consideration of the implementation of strategies and key concepts, which may engender sustainability within complex projects therefore presents an opportunity for further critical debate, review, and application through a project management lens. Sustainability incorporation in project management has been documented in academic literature, with this emerging field providing new challenges. For example, project management education can provide a holistic base for the inculcation of sustainability factors to a range of industries, including complex projects. Likewise, practitioner interest and approaches to sustainability in project management are being driven by the recently Chartered Association for Project Management (APM). Whilst this body makes a significant contribution to the UK economy across many sectors, it also addresses ongoing sustainability challenges. Therefore, by drawing on research and practitioner developments, the authors argue that by connecting with the next generation through practice simulation approaches, and embedding sustainability issues within project management tools and methods, improved focus on sustainability in complex project management may be achieved."}}, {"id": "e0414d96339f9efa", "url": "http://arxiv.org/abs/2507.11773v1", "title": "Small Data Explainer -- The impact of small data methods in everyday life", "description": "The emergence of breakthrough artificial intelligence (AI) techniques has led to a renewed focus on how small data settings, i.e., settings with limited information, can benefit from such developments. This includes societal issues such as how best to include under-represented groups in data-driven policy and decision making, or the health benefits of assistive technologies such as wearables. We provide a conceptual overview, in particular contrasting small data with big data, and identify commo", "provider": "arxiv", "domains": ["ai_governance"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.394, "discovered_at": "2026-02-09T15:18:51.969106Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The emergence of breakthrough artificial intelligence (AI) techniques has led to a renewed focus on how small data settings, i.e., settings with limited information, can benefit from such developments. This includes societal issues such as how best to include under-represented groups in data-driven policy and decision making, or the health benefits of assistive technologies such as wearables. We provide a conceptual overview, in particular contrasting small data with big data, and identify common themes from exemplary case studies and application areas. Potential solutions are described in a more detailed technical overview of current data analysis and modelling techniques, highlighting contributions from different disciplines, such as knowledge-driven modelling from statistics and data-driven modelling from computer science. By linking application settings, conceptual contributions and specific techniques, we highlight what is already feasible and suggest what an agenda for fully leveraging small data might look like."}}, {"id": "6d190397ba4c1961", "url": "http://arxiv.org/abs/1910.08604v3", "title": "Digital Democracy: Episode IV -- A New Hope, How a Corporation for Public Software Could Transform Digital Engagement for Government and Civil Society", "description": "Though successive generations of digital technology have become increasingly powerful in the past twenty years, digital democracy has yet to realize its potential for deliberative transformation. The undemocratic exploitation of massive social media systems continued this trend, but it only worsened an existing problem of modern democracies, which were already struggling to develop deliberative infrastructure independent of digital technologies. There have been many creative conceptions of civic", "provider": "arxiv", "domains": ["reinforcement_learning"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.392, "discovered_at": "2026-02-09T15:00:33.479302Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Though successive generations of digital technology have become increasingly powerful in the past twenty years, digital democracy has yet to realize its potential for deliberative transformation. The undemocratic exploitation of massive social media systems continued this trend, but it only worsened an existing problem of modern democracies, which were already struggling to develop deliberative infrastructure independent of digital technologies. There have been many creative conceptions of civic tech, but implementation has lagged behind innovation. This essay argues for implementing one such vision of digital democracy through the establishment of a public corporation. Modeled on the Corporation for Public Broadcasting in the U.S., this entity would foster the creation of new digital technology by providing a stable source of funding to nonprofit technologists, interest groups, civic organizations, government, researchers, private companies, and the public. Funded entities would produce and maintain software infrastructure for public benefit. The concluding sections identify what circumstances might create and sustain such an entity."}}, {"id": "aa39c9f045fa4920", "url": "http://arxiv.org/abs/1603.06047v2", "title": "The Circle of Investment: Connecting the Dots of the Portfolio Management Cycle...", "description": "We will look at the entire cycle of the investment process relating to all aspects of, formulating an investment hypothesis, constructing a portfolio based on that, executing the trades to implement it, on-going risk management, periodically measuring the performance of the portfolio, and rebalancing the portfolio either due to an increase in the risk parameters or due to a deviation from the intended asset allocation. We provide several illustrative analogies that are meant to intuitively expla", "provider": "arxiv", "domains": ["ai_project_management"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.392, "discovered_at": "2026-02-09T15:39:57.326367Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We will look at the entire cycle of the investment process relating to all aspects of, formulating an investment hypothesis, constructing a portfolio based on that, executing the trades to implement it, on-going risk management, periodically measuring the performance of the portfolio, and rebalancing the portfolio either due to an increase in the risk parameters or due to a deviation from the intended asset allocation. We provide several illustrative analogies that are meant to intuitively explain the pleasures and the pitfalls that can arise while managing a portfolio. If we consider the entire investment management procedure as being akin to connecting the dots of a circle, then the Circle of Investment can be represented as a dotted circle with many dots falling approximately on the circumference and with no clue about the exact location of the centre or the length of the radius. We represent the investment process as a dotted circle since there is a lot of ambiguity in the various steps involved. The circle also indicates the repetitive nature of many steps that are continuously carried out while investing. This work introduces two new points pertaining to this dotted circle and improves the ability, to understand how far-off this dotted circle is, from a more well-defined circle and, to create a well-formed circle. The two innovations we introduce are:\n  1. The first, relating to the limitations that apply to any finding in the social sciences, would be the additional point we introduce that lies near the centre of the circle. We title this as, 'The Uncertainty Principle of the Social Sciences'.\n  2. The second, relating to establishing confidence levels in a systematic manner for each view we associate with a security or group of securities as required by the Black-Litterman framework, would be the new point we present near the circumference of the circle."}}, {"id": "a16bb6e40f7d7c85", "url": "http://arxiv.org/abs/2101.09193v3", "title": "Dense outlier detection and open-set recognition based on training with noisy negative images", "description": "Deep convolutional models often produce inadequate predictions for inputs foreign to the training distribution. Consequently, the problem of detecting outlier images has recently been receiving a lot of attention. Unlike most previous work, we address this problem in the dense prediction context in order to be able to locate outlier objects in front of in-distribution background. Our approach is based on two reasonable assumptions. First, we assume that the inlier dataset is related to some narr", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.39, "discovered_at": "2026-02-09T15:39:49.665165Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Deep convolutional models often produce inadequate predictions for inputs foreign to the training distribution. Consequently, the problem of detecting outlier images has recently been receiving a lot of attention. Unlike most previous work, we address this problem in the dense prediction context in order to be able to locate outlier objects in front of in-distribution background. Our approach is based on two reasonable assumptions. First, we assume that the inlier dataset is related to some narrow application field (e.g.~road driving). Second, we assume that there exists a general-purpose dataset which is much more diverse than the inlier dataset (e.g.~ImageNet-1k). We consider pixels from the general-purpose dataset as noisy negative training samples since most (but not all) of them are outliers. We encourage the model to recognize borders between known and unknown by pasting jittered negative patches over inlier training images. Our experiments target two dense open-set recognition benchmarks (WildDash 1 and Fishyscapes) and one dense open-set recognition dataset (StreetHazard). Extensive performance evaluation indicates competitive potential of the proposed approach."}}, {"id": "595c693586942449", "url": "http://arxiv.org/abs/2201.06363v1", "title": "An Approach for System Analysis with MBSE and Graph Data Engineering", "description": "Model-Based Systems Engineering aims at creating a model of a system under development, covering the complete system with a level of detail that allows to define and understand its behavior and enables to define any interface and workpackage based on the model. Once such a model is established, further benefits can be reaped, such as the analysis of complex technical correlations within the system. Various insights can be gained by displaying the model as a formal graph and querying it. To enabl", "provider": "arxiv", "domains": ["data_engineering"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.386, "discovered_at": "2026-02-09T15:39:55.081610Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Model-Based Systems Engineering aims at creating a model of a system under development, covering the complete system with a level of detail that allows to define and understand its behavior and enables to define any interface and workpackage based on the model. Once such a model is established, further benefits can be reaped, such as the analysis of complex technical correlations within the system. Various insights can be gained by displaying the model as a formal graph and querying it. To enable such queries, a graph schema needs to be designed, which allows to transfer the model into a graph database. In the course of this paper, we discuss the design of a graph schema and MBSE modelling approach, enabling deep going system analysis and anomaly resolution in complex embedded systems. The schema and modelling approach are designed to answer questions such as what happens if there is an electrical short in a component? Which other components are now offline and which data cannot be gathered anymore? Or if a condition cannot be met, which alternative routes can be established to reach a certain state of the system. We build on the use case of qualification and operations of a small spacecraft. Structural and behavioral elements of the MBSE model are transferred to a graph database where analyses are conducted on the system. The schema is implemented by an adapter for MagicDraw to Neo4j. A selection of complex analyses are shown on the example of the MOVE-II space mission."}}, {"id": "5566459751e416ad", "url": "http://arxiv.org/abs/2504.12358v1", "title": "Towards an AI Observatory for the Nuclear Sector: A tool for anticipatory governance", "description": "AI models are rapidly becoming embedded in all aspects of nuclear energy research and work but the safety, security, and safeguards consequences of this embedding are not well understood. In this paper, we call for the creation of an anticipatory system of governance for AI in the nuclear sector as well as the creation of a global AI observatory as a means for operationalizing anticipatory governance. The paper explores the contours of the nuclear AI observatory and an anticipatory system of gov", "provider": "arxiv", "domains": ["nlp"], "content_type": "paper", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.385, "discovered_at": "2026-02-09T15:00:34.177912Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "AI models are rapidly becoming embedded in all aspects of nuclear energy research and work but the safety, security, and safeguards consequences of this embedding are not well understood. In this paper, we call for the creation of an anticipatory system of governance for AI in the nuclear sector as well as the creation of a global AI observatory as a means for operationalizing anticipatory governance. The paper explores the contours of the nuclear AI observatory and an anticipatory system of governance by drawing on work in science and technology studies, public policy, and foresight studies."}}, {"id": "a60b6ccaff960ed1", "url": "http://arxiv.org/abs/2404.16484v1", "title": "Real-Time 4K Super-Resolution of Compressed AVIF Images. AIS 2024 Challenge Survey", "description": "This paper introduces a novel benchmark as part of the AIS 2024 Real-Time Image Super-Resolution (RTSR) Challenge, which aims to upscale compressed images from 540p to 4K resolution (4x factor) in real-time on commercial GPUs. For this, we use a diverse test set containing a variety of 4K images ranging from digital art to gaming and photography. The images are compressed using the modern AVIF codec, instead of JPEG. All the proposed methods improve PSNR fidelity over Lanczos interpolation, and ", "provider": "arxiv", "domains": ["ml_basics"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.384, "discovered_at": "2026-02-09T15:00:33.353804Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This paper introduces a novel benchmark as part of the AIS 2024 Real-Time Image Super-Resolution (RTSR) Challenge, which aims to upscale compressed images from 540p to 4K resolution (4x factor) in real-time on commercial GPUs. For this, we use a diverse test set containing a variety of 4K images ranging from digital art to gaming and photography. The images are compressed using the modern AVIF codec, instead of JPEG. All the proposed methods improve PSNR fidelity over Lanczos interpolation, and process images under 10ms. Out of the 160 participants, 25 teams submitted their code and models. The solutions present novel designs tailored for memory-efficiency and runtime on edge devices. This survey describes the best solutions for real-time SR of compressed high-resolution images."}}, {"id": "2d8a625e01a9d0b8", "url": "http://arxiv.org/abs/2010.16064v1", "title": "A 20 Gbps Data Transmitting ASIC with PAM4 for Particle Physics Experiments", "description": "We present the design principle and test results of a data transmitting ASIC, GBS20, for particle physics experiments. The goal of GBS20 will be an ASIC that employs two serializers each from the 10.24 Gbps lpGBT SerDes, sharing the PLL also from lpGBT. A PAM4 encoder plus a VCSEL driver will be implemented in the same die to use the same clock system, eliminating the need of CDRs in the PAM4 encoder. This way the transmitter module, GBT20, developed using the GBS20 ASIC, will have the exact lpG", "provider": "mit", "domains": [], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.38, "discovered_at": "2026-02-09T15:18:51.903138Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We present the design principle and test results of a data transmitting ASIC, GBS20, for particle physics experiments. The goal of GBS20 will be an ASIC that employs two serializers each from the 10.24 Gbps lpGBT SerDes, sharing the PLL also from lpGBT. A PAM4 encoder plus a VCSEL driver will be implemented in the same die to use the same clock system, eliminating the need of CDRs in the PAM4 encoder. This way the transmitter module, GBT20, developed using the GBS20 ASIC, will have the exact lpGBT data interface and transmission protocol, with an output up to 20.48 Gbps over one fiber. With PAM4 embedded FPGAs at the receiving end, GBT20 will halve the fibers needed in a system and better use the input bandwidth of the FPGA. A prototype, GBS20v0 is fabricated using a commercial 65 nm CMOS technology. This prototype has two serializers and a PAM4 encoder sharing the lpGBT PLL, but no user data input. An internal PRBS generator provides data to the serializers. GBS20v0 is tested barely up to 20.48 Gbps. With lessons learned from this prototype, we are designing the second prototype, GBS20v1, that will have 16 user data input channels each at 1.28 Gbps. We present the design concept of the GBS20 ASIC and the GBT20 module, the preliminary test results, and lessons learned from GBS20v0 and the design of GBS20v1 which will be not only a test chip but also a user chip with 16 input data channels."}}, {"id": "9b7d3c9dd05a1c04", "url": "http://arxiv.org/abs/2107.14072v2", "title": "What Does TERRA-REF's High Resolution, Multi Sensor Plant Sensing Public Domain Data Offer the Computer Vision Community?", "description": "A core objective of the TERRA-REF project was to generate an open-access reference dataset for the evaluation of sensing technologies to study plants under field conditions. The TERRA-REF program deployed a suite of high-resolution, cutting edge technology sensors on a gantry system with the aim of scanning 1 hectare (10$^4$) at around 1 mm$^2$ spatial resolution multiple times per week. The system contains co-located sensors including a stereo-pair RGB camera, a thermal imager, a laser scanner ", "provider": "arxiv", "domains": ["computer_vision"], "content_type": "paper", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": null, "prerequisites": [], "tags": [], "quality_score": 0.377, "discovered_at": "2026-02-09T15:00:31.071828Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "A core objective of the TERRA-REF project was to generate an open-access reference dataset for the evaluation of sensing technologies to study plants under field conditions. The TERRA-REF program deployed a suite of high-resolution, cutting edge technology sensors on a gantry system with the aim of scanning 1 hectare (10$^4$) at around 1 mm$^2$ spatial resolution multiple times per week. The system contains co-located sensors including a stereo-pair RGB camera, a thermal imager, a laser scanner to capture 3D structure, and two hyperspectral cameras covering wavelengths of 300-2500nm. This sensor data is provided alongside over sixty types of traditional plant phenotype measurements that can be used to train new machine learning models. Associated weather and environmental measurements, information about agronomic management and experimental design, and the genomic sequences of hundreds of plant varieties have been collected and are available alongside the sensor and plant phenotype data.\n  Over the course of four years and ten growing seasons, the TERRA-REF system generated over 1 PB of sensor data and almost 45 million files. The subset that has been released to the public domain accounts for two seasons and about half of the total data volume. This provides an unprecedented opportunity for investigations far beyond the core biological scope of the project.\n  The focus of this paper is to provide the Computer Vision and Machine Learning communities an overview of the available data and some potential applications of this one of a kind data."}}, {"id": "a6fa17883939481d", "url": "http://arxiv.org/abs/physics/0604112v1", "title": "Lab-Tutorials for teaching quantum physics (Lab-Tutorials fuer den Quantenphysik Unterricht)", "description": "English abstract: In the \"Intuitive Quantum Physics\" course, we use graphical interpretations of mathematical equations and qualitative reasoning to develop and teach a simplified model of quantum physics. Our course contains three units: Wave physics, Development of a conceptual toolbox, and quantum physics. It also contains three key themes: wave-particle duality, the Schroedinger equation, and tunneling of quantum particles. Students learn most new material in lab-tutorials in which students ", "provider": "arxiv", "domains": [], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.35, "discovered_at": "2026-02-09T15:00:29.969361Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "English abstract: In the \"Intuitive Quantum Physics\" course, we use graphical interpretations of mathematical equations and qualitative reasoning to develop and teach a simplified model of quantum physics. Our course contains three units: Wave physics, Development of a conceptual toolbox, and quantum physics. It also contains three key themes: wave-particle duality, the Schroedinger equation, and tunneling of quantum particles. Students learn most new material in lab-tutorials in which students work in small groups (3 to 3 people) on specially designed worksheets. Lecture reinforces the lab-tutorial content and focuses more on issues about the nature of science. Data show that students are able to learn some of the most difficult concepts in the course, and also that students learn to believe that there is a conceptually accessible structure to the physics in the course.\n  German abstract: Im Kurs \"Intuitive Quantum Physics\" werden graphische Interpretationen mathematischer Gleichungen und qualitatives Denken durch ein vereinfachtes Modell der Quantenphysik gelehrt. Unser Kurs besteht aus drei wichtigen Abschnitten: Wellenphysik, Aufbau eines Werkzeugkastens (\"Toolbox\") und Quantenphysik, sowie drei Schluesselthemen: Welle-Teilchen-Dualitaet, die Schroedinger-Gleichung und Tunneln von Quantenteilchen. Wir unterrichten vorwiegend mit Lab-Tutorials, in denen StudentInnen in kleinen Gruppen (3 bis 4 Personen) anwendungsspezifische Arbeitsblaetter durcharbeiten. In den Diskussionen werden auch Auseinandersetzungen ueber das \"Bild der Physik\", bei uns \"Nature of Science\" genannt, gefuehrt. Ueberpruefungen haben ergeben, dass StudentInnen nicht nur die schwierigsten Konzepte des Kurses lernen koennen sondern auch lernen, dass die Quantenphysik begrifflich verstaendlich ist."}}, {"id": "aaf54657549d45f7", "url": "http://arxiv.org/abs/2203.16791v2", "title": "The Parking Lot Planet", "description": "We give conditions for an exoplanetary system to function as an ideal amusement park/vacation resort (with its separate parking lot, of course); in case of massive human interplanetary colonization. Our considerations stem from the fact that an amusement park needs a parking lot of roughly the same surface area, thus the best option for its construction would be a system with at least 2 planets close to each other for easy tourist transportation. We also discuss the likelihood of finding such a ", "provider": "arxiv", "domains": [], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.35, "discovered_at": "2026-02-09T15:18:50.575635Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We give conditions for an exoplanetary system to function as an ideal amusement park/vacation resort (with its separate parking lot, of course); in case of massive human interplanetary colonization. Our considerations stem from the fact that an amusement park needs a parking lot of roughly the same surface area, thus the best option for its construction would be a system with at least 2 planets close to each other for easy tourist transportation. We also discuss the likelihood of finding such a system out there to cut down on construction costs."}}, {"id": "455ab40d5f396bf7", "url": "http://arxiv.org/abs/2409.08956v1", "title": "Discovery Opportunities with Gravitational Waves -- TASI 2024 Lecture Notes", "description": "Recent advancements in gravitational wave astronomy hold the promise of a completely new way to explore our Universe. These lecture notes aim to provide a concise but self-contained introduction to key concepts of gravitational wave physics, with a focus on the opportunities to explore fundamental physics in transient gravitational wave signals and stochastic gravitational wave background searches.CERN-TH-2024-152", "provider": "arxiv", "domains": [], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.35, "discovered_at": "2026-02-09T15:18:52.445027Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Recent advancements in gravitational wave astronomy hold the promise of a completely new way to explore our Universe. These lecture notes aim to provide a concise but self-contained introduction to key concepts of gravitational wave physics, with a focus on the opportunities to explore fundamental physics in transient gravitational wave signals and stochastic gravitational wave background searches.CERN-TH-2024-152"}}, {"id": "41abe87830d3a6e0", "url": "http://arxiv.org/abs/2406.10598v1", "title": "Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge", "description": "As computer-based applications are becoming more integrated into our daily lives, the importance of Speech Emotion Recognition (SER) has increased significantly. Promoting research with innovative approaches in SER, the Odyssey 2024 Speech Emotion Recognition Challenge was organized as part of the Odyssey 2024 Speaker and Language Recognition Workshop. In this paper we describe the Double Multi-Head Attention Multimodal System developed for this challenge. Pre-trained self-supervised models were", "provider": "arxiv", "domains": [], "content_type": "course", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.35, "discovered_at": "2026-02-09T16:08:20.078052Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "As computer-based applications are becoming more integrated into our daily lives, the importance of Speech Emotion Recognition (SER) has increased significantly. Promoting research with innovative approaches in SER, the Odyssey 2024 Speech Emotion Recognition Challenge was organized as part of the Odyssey 2024 Speaker and Language Recognition Workshop. In this paper we describe the Double Multi-Head Attention Multimodal System developed for this challenge. Pre-trained self-supervised models were used to extract informative acoustic and text features. An early fusion strategy was adopted, where a Multi-Head Attention layer transforms these mixed features into complementary contextualized representations. A second attention mechanism is then applied to pool these representations into an utterance-level vector. Our proposed system achieved the third position in the categorical task ranking with a 34.41% Macro-F1 score, where 31 teams participated in total."}}, {"id": "d785bd281d45dac0", "url": "http://arxiv.org/abs/0903.3183v2", "title": "Physics education research: Resources for middle school science teachers", "description": "This resource letter intends to provide middle school science teachers with a collection of resources to aid them in planning and implementing a physical science curriculum. The resources are in the form of books, websites, journals, and organizations.", "provider": "arxiv", "domains": [], "content_type": "course", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.35, "discovered_at": "2026-02-09T16:08:22.705946Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This resource letter intends to provide middle school science teachers with a collection of resources to aid them in planning and implementing a physical science curriculum. The resources are in the form of books, websites, journals, and organizations."}}, {"id": "1548671026bd1d83", "url": "http://arxiv.org/abs/2101.01406v1", "title": "Tutorial I: Learning the Principles of Mobile Radio Propagation through Smartphone and CRFO", "description": "In this tutorial, we present three simple smartphone based experiments for understanding the basic concepts of mobile communications such as pathloss, Shadow fading, and small scale fading. We also explain the use of Collaborative Radio Frequency Observatory (CRFO), an online platform, for visualizing radio coverage maps.", "provider": "arxiv", "domains": [], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.34, "discovered_at": "2026-02-09T15:18:53.190853Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this tutorial, we present three simple smartphone based experiments for understanding the basic concepts of mobile communications such as pathloss, Shadow fading, and small scale fading. We also explain the use of Collaborative Radio Frequency Observatory (CRFO), an online platform, for visualizing radio coverage maps."}}, {"id": "dc5af7ed37ebd777", "url": "http://arxiv.org/abs/1110.5626v1", "title": "Constraints on dark energy from H II starburst galaxy apparent magnitude versus redshift data", "description": "In this paper we use H II starburst galaxy apparent magnitude versus redshift data from Siegel et al. (2005) to constrain dark energy cosmological model parameters. These constraints are generally consistent with those derived using other data sets, but are not as restrictive as the tightest currently available constraints.", "provider": "arxiv", "domains": [], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.34, "discovered_at": "2026-02-09T16:08:24.862161Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this paper we use H II starburst galaxy apparent magnitude versus redshift data from Siegel et al. (2005) to constrain dark energy cosmological model parameters. These constraints are generally consistent with those derived using other data sets, but are not as restrictive as the tightest currently available constraints."}}, {"id": "9c0548c4d925788a", "url": "http://arxiv.org/abs/1910.11775v2", "title": "Physics Briefing Book", "description": "The European Particle Physics Strategy Update (EPPSU) process takes a bottom-up approach, whereby the community is first invited to submit proposals (also called inputs) for projects that it would like to see realised in the near-term, mid-term and longer-term future. National inputs as well as inputs from National Laboratories are also an important element of the process. All these inputs are then reviewed by the Physics Preparatory Group (PPG), whose role is to organize a Symposium around the ", "provider": "arxiv", "domains": [], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.34, "discovered_at": "2026-02-09T16:08:25.293057Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The European Particle Physics Strategy Update (EPPSU) process takes a bottom-up approach, whereby the community is first invited to submit proposals (also called inputs) for projects that it would like to see realised in the near-term, mid-term and longer-term future. National inputs as well as inputs from National Laboratories are also an important element of the process. All these inputs are then reviewed by the Physics Preparatory Group (PPG), whose role is to organize a Symposium around the submitted ideas and to prepare a community discussion on the importance and merits of the various proposals. The results of these discussions are then concisely summarised in this Briefing Book, prepared by the Conveners, assisted by Scientific Secretaries, and with further contributions provided by the Contributors listed on the title page. This constitutes the basis for the considerations of the European Strategy Group (ESG), consisting of scientific delegates from CERN Member States, Associate Member States, directors of major European laboratories, representatives of various European organizations as well as invitees from outside the European Community. The ESG has the mission to formulate the European Strategy Update for the consideration and approval of the CERN Council."}}, {"id": "e21f3a58d72e2ff3", "url": "http://arxiv.org/abs/2305.17247v1", "title": "The Araucaria Project: Improving the cosmic distance scale", "description": "The book consists of a number of short articles that present achievements of the Araucaria members, collaborators, and friends, in various aspects of distance determinations and related topics. It celebrates the 20-year anniversary of the Araucaria Project, acknowledges the people who worked for its success, and popularises our methods and results among broader readership.\n  This book is a part of a project that has received funding from the European Union's Horizon 2020 research and innovation ", "provider": "arxiv", "domains": [], "content_type": "interactive_notebook", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.34, "discovered_at": "2026-02-09T16:08:26.078703Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The book consists of a number of short articles that present achievements of the Araucaria members, collaborators, and friends, in various aspects of distance determinations and related topics. It celebrates the 20-year anniversary of the Araucaria Project, acknowledges the people who worked for its success, and popularises our methods and results among broader readership.\n  This book is a part of a project that has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 695099."}}, {"id": "17382ed7b223b39f", "url": "http://arxiv.org/abs/1404.0191v2", "title": "A quantitative perspective on ethics in large team science", "description": "The gradual crowding out of singleton and small team science by large team endeavors is challenging key features of research culture. It is therefore important for the future of scientific practice to reflect upon the individual scientist's ethical responsibilities within teams. To facilitate this reflection we show labor force trends in the US revealing a skewed growth in academic ranks and increased levels of competition for promotion within the system; we analyze teaming trends across discipl", "provider": "arxiv", "domains": [], "content_type": "interactive_notebook", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.34, "discovered_at": "2026-02-09T16:08:26.411843Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "The gradual crowding out of singleton and small team science by large team endeavors is challenging key features of research culture. It is therefore important for the future of scientific practice to reflect upon the individual scientist's ethical responsibilities within teams. To facilitate this reflection we show labor force trends in the US revealing a skewed growth in academic ranks and increased levels of competition for promotion within the system; we analyze teaming trends across disciplines and national borders demonstrating why it is becoming difficult to distribute credit and to avoid conflicts of interest; and we use more than a century of Nobel prize data to show how science is outgrowing its old institutions of singleton awards. Of particular concern within the large team environment is the weakening of the mentor-mentee relation, which undermines the cultivation of virtue ethics across scientific generations. These trends and emerging organizational complexities call for a universal set of behavioral norms that transcend team heterogeneity and hierarchy. To this end, our expository analysis provides a survey of ethical issues in team settings to inform science ethics education and science policy."}}, {"id": "dc5d244531166688", "url": "http://arxiv.org/abs/1211.0310v1", "title": "Large Synoptic Survey Telescope: Dark Energy Science Collaboration", "description": "This white paper describes the LSST Dark Energy Science Collaboration (DESC), whose goal is the study of dark energy and related topics in fundamental physics with data from the Large Synoptic Survey Telescope (LSST). It provides an overview of dark energy science and describes the current and anticipated state of the field. It makes the case for the DESC by laying out a robust analytical framework for dark energy science that has been defined by its members and the comprehensive three-year work", "provider": "arxiv", "domains": [], "content_type": "interactive_notebook", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.34, "discovered_at": "2026-02-09T16:08:26.460776Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This white paper describes the LSST Dark Energy Science Collaboration (DESC), whose goal is the study of dark energy and related topics in fundamental physics with data from the Large Synoptic Survey Telescope (LSST). It provides an overview of dark energy science and describes the current and anticipated state of the field. It makes the case for the DESC by laying out a robust analytical framework for dark energy science that has been defined by its members and the comprehensive three-year work plan they have developed for implementing that framework. The analysis working groups cover five key probes of dark energy: weak lensing, large scale structure, galaxy clusters, Type Ia supernovae, and strong lensing. The computing working groups span cosmological simulations, galaxy catalogs, photon simulations and a systematic software and computational framework for LSST dark energy data analysis. The technical working groups make the connection between dark energy science and the LSST system. The working groups have close linkages, especially through the use of the photon simulations to study the impact of instrument design and survey strategy on analysis methodology and cosmological parameter estimation. The white paper describes several high priority tasks identified by each of the 16 working groups. Over the next three years these tasks will help prepare for LSST analysis, make synergistic connections with ongoing cosmological surveys and provide the dark energy community with state of the art analysis tools. Members of the community are invited to join the LSST DESC, according to the membership policies described in the white paper. Applications to sign up for associate membership may be made by submitting the Web form at http://www.slac.stanford.edu/exp/lsst/desc/signup.html with a short statement of the work they wish to pursue that is relevant to the LSST DESC."}}, {"id": "86a51d69679351aa", "url": "http://arxiv.org/abs/2211.15347v1", "title": "A Tutorial on Linear Least Square Estimation", "description": "This is a brief tutorial on the least square estimation technique that is straightforward yet effective for parameter estimation. The tutorial is focused on the linear LSEs instead of nonlinear versions, since most nonlinear LSEs can be approximated non-trivially using its linear counterparts. Linear LSEs can also provide insight into the study of the nonlinear techniques, e.g., Gauss-Newton method and Lavenberg-Marquardt method etc. Linear LSEs are computationally efficient for most occasions, ", "provider": "arxiv", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.3, "discovered_at": "2026-02-09T15:00:29.874229Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This is a brief tutorial on the least square estimation technique that is straightforward yet effective for parameter estimation. The tutorial is focused on the linear LSEs instead of nonlinear versions, since most nonlinear LSEs can be approximated non-trivially using its linear counterparts. Linear LSEs can also provide insight into the study of the nonlinear techniques, e.g., Gauss-Newton method and Lavenberg-Marquardt method etc. Linear LSEs are computationally efficient for most occasions, so they are widely applied in practice. In this tutorial, both the original batch least square estimation and its recursive variants are reviewed comprehensively with detailed mathematical derivations."}}, {"id": "6663a6c35d0542bd", "url": "http://arxiv.org/abs/0907.2974v19", "title": "Service-Oriented Architectures and Web Services: Course Tutorial and Lab Notes", "description": "This document presents a number of quick-step instructions to get started on writing mini-service-oriented web services-based applications using OpenESB 2.31, Tomcat 6, GlassFish 2.x/3.0.1 with BPEL support, and Java 1.6+ primarily in Scientific Linux 6.6 with user quota restrictions. While the tutorial notes are oriented towards the students taking the SOEN487 on service-oriented architectures (SOA) at Computer Science and Software Engineering (CSE) Department, Faculty of Engineering and Comput", "provider": "arxiv", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.3, "discovered_at": "2026-02-09T15:00:29.903052Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This document presents a number of quick-step instructions to get started on writing mini-service-oriented web services-based applications using OpenESB 2.31, Tomcat 6, GlassFish 2.x/3.0.1 with BPEL support, and Java 1.6+ primarily in Scientific Linux 6.6 with user quota restrictions. While the tutorial notes are oriented towards the students taking the SOEN487 on service-oriented architectures (SOA) at Computer Science and Software Engineering (CSE) Department, Faculty of Engineering and Computer Science (ENCS), other may find some of it useful as well outside of CSE or Concordia. The notes are compiled mostly based on the students' needs and feedback."}}, {"id": "cbde5aa2af2b4ad9", "url": "http://arxiv.org/abs/2106.09323v1", "title": "Quantum Software Development Lifecycle", "description": "With recent advances in the development of more powerful quantum computers, the research area of quantum software engineering is emerging, having the goal to provide concepts, principles, and guidelines to develop high-quality quantum applications. In classical software engineering, lifecycles are used to document the process of designing, implementing, maintaining, analyzing, and adapting software. Such lifecycles provide a common understanding of how to develop and operate an application, whic", "provider": "arxiv", "domains": [], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.3, "discovered_at": "2026-02-09T15:00:33.954554Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "With recent advances in the development of more powerful quantum computers, the research area of quantum software engineering is emerging, having the goal to provide concepts, principles, and guidelines to develop high-quality quantum applications. In classical software engineering, lifecycles are used to document the process of designing, implementing, maintaining, analyzing, and adapting software. Such lifecycles provide a common understanding of how to develop and operate an application, which is especially important due to the interdisciplinary nature of quantum computing. Since today`s quantum applications are, in most cases, hybrid, consisting of quantum and classical programs, the lifecycle for quantum applications must involve the development of both kinds of programs. However, the existing lifecycles only target the development of quantum or classical programs in isolation. Additionally, the various programs must be orchestrated, e.g., using workflows. Thus, the development of quantum applications also incorporates the workflow lifecycle. In this chapter, we analyze the software artifacts usually comprising a quantum application and present their corresponding lifecycles. Furthermore, we identify the points of connection between the various lifecycles and integrate them into the overall quantum software development lifecycle. Therefore, the integrated lifecycle serves as a basis for the development and execution of hybrid quantum applications."}}, {"id": "7f0b8d1506f0f784", "url": "http://arxiv.org/abs/1710.04635v2", "title": "Gravitational waves without general relativity: A tutorial", "description": "This tutorial leads the reader through the details of calculating the properties of gravitational waves from orbiting binaries, such as two orbiting black holes. Using analogies with electromagnetic radiation, the tutorial presents a calculation that produces the same dependence on the masses of the orbiting objects, the orbital frequency, and the mass separation as does the linear version of General Relativity (GR). However, the calculation yields polarization, angular distributions, and overal", "provider": "arxiv", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.3, "discovered_at": "2026-02-09T15:18:53.120076Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "This tutorial leads the reader through the details of calculating the properties of gravitational waves from orbiting binaries, such as two orbiting black holes. Using analogies with electromagnetic radiation, the tutorial presents a calculation that produces the same dependence on the masses of the orbiting objects, the orbital frequency, and the mass separation as does the linear version of General Relativity (GR). However, the calculation yields polarization, angular distributions, and overall power results that differ from those of GR. Nevertheless, the calculation produces waveforms that are nearly identical to the pre-binary-merger portions of the signals observed by the Laser Interferometer Gravitational-Wave Observatory (LIGO-Virgo) collaboration. The tutorial should be easily understandable by students who have taken a standard upper-level undergraduate course in electromagnetism."}}, {"id": "b5710eb352f5ae58", "url": "http://arxiv.org/abs/0910.4472v2", "title": "Tutorial on ABC rejection and ABC SMC for parameter estimation and model selection", "description": "In this tutorial we schematically illustrate four algorithms:\n  (1) ABC rejection for parameter estimation\n  (2) ABC SMC for parameter estimation\n  (3) ABC rejection for model selection on the joint space\n  (4) ABC SMC for model selection on the joint space.", "provider": "arxiv", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.3, "discovered_at": "2026-02-09T15:39:51.320553Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "In this tutorial we schematically illustrate four algorithms:\n  (1) ABC rejection for parameter estimation\n  (2) ABC SMC for parameter estimation\n  (3) ABC rejection for model selection on the joint space\n  (4) ABC SMC for model selection on the joint space."}}, {"id": "af0c6b9084e6747d", "url": "http://arxiv.org/abs/2012.06469v1", "title": "DILIE: Deep Internal Learning for Image Enhancement", "description": "We consider the generic deep image enhancement problem where an input image is transformed into a perceptually better-looking image. Recent methods for image enhancement consider the problem by performing style transfer and image restoration. The methods mostly fall into two categories: training data-based and training data-independent (deep internal learning methods). We perform image enhancement in the deep internal learning framework. Our Deep Internal Learning for Image Enhancement framework", "provider": "arxiv", "domains": [], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.3, "discovered_at": "2026-02-09T16:08:18.946446Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "We consider the generic deep image enhancement problem where an input image is transformed into a perceptually better-looking image. Recent methods for image enhancement consider the problem by performing style transfer and image restoration. The methods mostly fall into two categories: training data-based and training data-independent (deep internal learning methods). We perform image enhancement in the deep internal learning framework. Our Deep Internal Learning for Image Enhancement framework enhances content features and style features and uses contextual content loss for preserving image context in the enhanced image. We show results on both hazy and noisy image enhancement. To validate the results, we use structure similarity and perceptual error, which is efficient in measuring the unrealistic deformation present in the images. We show that the proposed framework outperforms the relevant state-of-the-art works for image enhancement."}}, {"id": "0a1b3d9ea2fb8a4b", "url": "http://arxiv.org/abs/2011.03712v1", "title": "DeepCFL: Deep Contextual Features Learning from a Single Image", "description": "Recently, there is a vast interest in developing image feature learning methods that are independent of the training data, such as deep image prior, InGAN, SinGAN, and DCIL. These methods are unsupervised and are used to perform low-level vision tasks such as image restoration, image editing, and image synthesis. In this work, we proposed a new training data-independent framework, called Deep Contextual Features Learning (DeepCFL), to perform image synthesis and image restoration based on the se", "provider": "arxiv", "domains": ["computer_vision", "nlp"], "content_type": "tutorial", "difficulty": "beginner", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.3, "discovered_at": "2026-02-09T16:08:19.196274Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Recently, there is a vast interest in developing image feature learning methods that are independent of the training data, such as deep image prior, InGAN, SinGAN, and DCIL. These methods are unsupervised and are used to perform low-level vision tasks such as image restoration, image editing, and image synthesis. In this work, we proposed a new training data-independent framework, called Deep Contextual Features Learning (DeepCFL), to perform image synthesis and image restoration based on the semantics of the input image. The contextual features are simply the high dimensional vectors representing the semantics of the given image. DeepCFL is a single image GAN framework that learns the distribution of the context vectors from the input image. We show the performance of contextual learning in various challenging scenarios: outpainting, inpainting, and restoration of randomly removed pixels. DeepCFL is applicable when the input source image and the generated target image are not aligned. We illustrate image synthesis using DeepCFL for the task of image resizing."}}, {"id": "ecbead0a914a3518", "url": "http://arxiv.org/abs/2103.10703v1", "title": "Lessons Learned from Educating AI Engineers", "description": "Over the past three years we have built a practice-oriented, bachelor level, educational programme for software engineers to specialize as AI engineers. The experience with this programme and the practical assignments our students execute in industry has given us valuable insights on the profession of AI engineer. In this paper we discuss our programme and the lessons learned for industry and research.", "provider": "arxiv", "domains": [], "content_type": "tutorial", "difficulty": "advanced", "license_type": "unknown", "language": "en", "estimated_hours": 0.1, "prerequisites": [], "tags": [], "quality_score": 0.3, "discovered_at": "2026-02-09T16:08:24.750891Z", "last_verified_at": null, "is_active": true, "raw_metadata": {"full_summary": "Over the past three years we have built a practice-oriented, bachelor level, educational programme for software engineers to specialize as AI engineers. The experience with this programme and the practical assignments our students execute in industry has given us valuable insights on the profession of AI engineer. In this paper we discuss our programme and the lessons learned for industry and research."}}];
const CURRICULUM = {"id": "d77fb39d7937", "title": "Comprehensive AI Best Practices Curriculum", "description": "Auto-generated curriculum with 30 learning paths covering 13 skill domains, built from 269 curated free and open-source resources.", "learning_paths": [{"id": "a2830a9a86f5", "title": "Ai Ethics \u2014 Beginner", "description": "A beginner-level learning path covering ai ethics using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["ai_ethics"], "modules": [{"title": "Module 1: Ai Ethics", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["12de4860bfa96dd0", "c312d42c5d01cbd3", "74cac193ee27792b", "062751c1972b2e5a", "0ea56d77cb1b9075"], "objectives": [{"description": "Understand Tutorial: Safe and Reliable Machine Learning", "bloom_level": "understand"}, {"description": "Understand Privacy-preserving machine learning for healthcare: open challenges and future perspectives", "bloom_level": "understand"}, {"description": "Understand Responsible AI and Its Stakeholders", "bloom_level": "understand"}, {"description": "Understand ABOUT ML: Annotation and Benchmarking on Understanding and Transparency of Machine Learning Lifecycles", "bloom_level": "understand"}, {"description": "Understand Privacy and Copyright Protection in Generative AI: A Lifecycle Perspective", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 1}, {"title": "Module 2: Ai Ethics", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["6a694be1e8ddefd7", "9c2629126655c0db", "c0d8ff32d9ca67cf", "6437037bfb7f0e80", "25a1f05617e698c7"], "objectives": [{"description": "Understand Atlas: A Framework for ML Lifecycle Provenance & Transparency", "bloom_level": "understand"}, {"description": "Understand Principles alone cannot guarantee ethical AI", "bloom_level": "understand"}, {"description": "Understand NTU-NPU System for Voice Privacy 2024 Challenge", "bloom_level": "understand"}, {"description": "Understand Tailoring Requirements Engineering for Responsible AI", "bloom_level": "understand"}, {"description": "Understand The Return on Investment in AI Ethics: A Holistic Framework", "bloom_level": "understand"}], "estimated_hours": 6.2, "order": 2}, {"title": "Module 3: Ai Ethics", "description": "Beginner-level resources \u2014 part 3", "resource_ids": ["e2d4f277f68c80fd", "b3875a83a4475509", "1b60dbfe151128ac", "21053ea17907d0af", "6f5cce837cf72508"], "objectives": [{"description": "Understand Measurement as governance in and for responsible AI", "bloom_level": "understand"}, {"description": "Understand Making Responsible AI the Norm rather than the Exception", "bloom_level": "understand"}, {"description": "Understand Top Ten Behavioral Biases in Project Management: An Overview", "bloom_level": "understand"}, {"description": "Understand AI Governance and Ethics Framework for Sustainable AI and Sustainability", "bloom_level": "understand"}, {"description": "Understand Using Edge Cases to Disentangle Fairness and Solidarity in AI Ethics", "bloom_level": "understand"}], "estimated_hours": 10.0, "order": 3}], "total_estimated_hours": 16.7, "prerequisites": [], "created_at": "2026-02-09T16:12:24.234113Z", "version": "1.0"}, {"id": "80ff27a04cbe", "title": "Ai Ethics \u2014 Intermediate", "description": "A intermediate-level learning path covering ai ethics using curated free and open-source resources.", "target_audience": "Practitioners with foundational knowledge seeking deeper skills", "difficulty": "intermediate", "domains": ["ai_ethics"], "modules": [{"title": "Module 1: Ai Ethics", "description": "Intermediate-level resources \u2014 part 1", "resource_ids": ["dda0ebdc2b8f0299"], "objectives": [{"description": "Apply AI Ethics in Industry: A Research Framework", "bloom_level": "apply"}], "estimated_hours": 2.0, "order": 1}], "total_estimated_hours": 2.0, "prerequisites": ["Complete the Beginner path for Ai Ethics"], "created_at": "2026-02-09T16:12:24.234173Z", "version": "1.0"}, {"id": "69c21b4d710d", "title": "Ai Ethics \u2014 Advanced", "description": "A advanced-level learning path covering ai ethics using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["ai_ethics"], "modules": [{"title": "Module 1: Ai Ethics", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["4592da1aa1edace8", "b140c79d311ff978", "7243f93750bef385", "911f23c02f3189b3", "515666304886d698"], "objectives": [{"description": "Evaluate Competing Visions of Ethical AI: A Case Study of OpenAI", "bloom_level": "evaluate"}, {"description": "Evaluate Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting", "bloom_level": "evaluate"}, {"description": "Evaluate Report prepared by the Montreal AI Ethics Institute (MAIEI) on Publication Norms for Responsible AI", "bloom_level": "evaluate"}, {"description": "Evaluate Beyond principlism: Practical strategies for ethical AI use in research practices", "bloom_level": "evaluate"}, {"description": "Evaluate Need of AI in Modern Education: in the Eyes of Explainable AI (xAI)", "bloom_level": "evaluate"}], "estimated_hours": 6.2, "order": 1}], "total_estimated_hours": 6.2, "prerequisites": ["Complete the Intermediate path for Ai Ethics"], "created_at": "2026-02-09T16:12:24.234226Z", "version": "1.0"}, {"id": "85cbc644a3c1", "title": "Ai Governance \u2014 Beginner", "description": "A beginner-level learning path covering ai governance using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["ai_governance"], "modules": [{"title": "Module 1: Ai Governance", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["e6ebd93e28b6ccc2", "3523df22bb0ae2ea", "580cb4e15b659404", "4b28d484a302b135", "4bf9989f06051718"], "objectives": [{"description": "Understand The role of the Model Validation function to manage and mitigate model risk", "bloom_level": "understand"}, {"description": "Understand freeCodeCamp/freeCodeCamp", "bloom_level": "understand"}, {"description": "Understand Distributed and Decentralised Training: Technical Governance Challenges in a Shifting AI Landscape", "bloom_level": "understand"}, {"description": "Understand The Global Majority in International AI Governance", "bloom_level": "understand"}, {"description": "Understand Tactics for Internal Compliance: A Literature Review", "bloom_level": "understand"}], "estimated_hours": 4.4, "order": 1}, {"title": "Module 2: Ai Governance", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["7ca263025f2f61a3", "3587bedc86fbb60d", "e0414d96339f9efa"], "objectives": [{"description": "Understand In Oxford Handbook on AI Governance: The Role of Workers in AI Ethics and Governance", "bloom_level": "understand"}, {"description": "Understand A multilevel framework for AI governance", "bloom_level": "understand"}, {"description": "Understand Small Data Explainer -- The impact of small data methods in everyday life", "bloom_level": "understand"}], "estimated_hours": 4.1, "order": 2}], "total_estimated_hours": 8.5, "prerequisites": ["Complete the Ai Ethics path"], "created_at": "2026-02-09T16:12:24.234934Z", "version": "1.0"}, {"id": "89965b1fdd8c", "title": "Ai Governance \u2014 Advanced", "description": "A advanced-level learning path covering ai governance using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["ai_governance"], "modules": [{"title": "Module 1: Ai Governance", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["88bc034971012871", "3e6b3793c15d7217"], "objectives": [{"description": "Evaluate The Nuclear Analogy in AI Governance Research", "bloom_level": "evaluate"}, {"description": "Evaluate DLT Compliance Reporting", "bloom_level": "evaluate"}], "estimated_hours": 0.2, "order": 1}], "total_estimated_hours": 0.2, "prerequisites": ["Complete the Ai Ethics path", "Complete the Intermediate path for Ai Governance"], "created_at": "2026-02-09T16:12:24.234973Z", "version": "1.0"}, {"id": "b369563d750f", "title": "Ai Project Management \u2014 Beginner", "description": "A beginner-level learning path covering ai project management using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["ai_project_management"], "modules": [{"title": "Module 1: Ai Project Management", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["7bc1892bed2a7f2c", "aa39c9f045fa4920"], "objectives": [{"description": "Understand Modelo de maturidade em gerenciamento de riscos em projetos (Project Risk Management Model Maturity)", "bloom_level": "understand"}, {"description": "Understand The Circle of Investment: Connecting the Dots of the Portfolio Management Cycle...", "bloom_level": "understand"}], "estimated_hours": 4.0, "order": 1}], "total_estimated_hours": 4.0, "prerequisites": ["Complete the Ai Strategy path"], "created_at": "2026-02-09T16:12:24.235245Z", "version": "1.0"}, {"id": "243fa7274c37", "title": "Ai Project Management \u2014 Intermediate", "description": "A intermediate-level learning path covering ai project management using curated free and open-source resources.", "target_audience": "Practitioners with foundational knowledge seeking deeper skills", "difficulty": "intermediate", "domains": ["ai_project_management"], "modules": [{"title": "Module 1: Ai Project Management", "description": "Intermediate-level resources \u2014 part 1", "resource_ids": ["69905fc02537c60a"], "objectives": [{"description": "Apply A Stochastic Processes Toolkit for Risk Management", "bloom_level": "apply"}], "estimated_hours": 0.1, "order": 1}], "total_estimated_hours": 0.1, "prerequisites": ["Complete the Ai Strategy path", "Complete the Beginner path for Ai Project Management"], "created_at": "2026-02-09T16:12:24.235284Z", "version": "1.0"}, {"id": "5760a1f8b46f", "title": "Ai Project Management \u2014 Advanced", "description": "A advanced-level learning path covering ai project management using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["ai_project_management"], "modules": [{"title": "Module 1: Ai Project Management", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["4659e75d573c669f"], "objectives": [{"description": "Evaluate Teaching Introduction to Programming in the times of AI: A case study of a course re-design", "bloom_level": "evaluate"}], "estimated_hours": 0.1, "order": 1}], "total_estimated_hours": 0.1, "prerequisites": ["Complete the Ai Strategy path", "Complete the Intermediate path for Ai Project Management"], "created_at": "2026-02-09T16:12:24.235313Z", "version": "1.0"}, {"id": "fdded0cf338a", "title": "Ai Roi \u2014 Beginner", "description": "A beginner-level learning path covering ai roi using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["ai_roi"], "modules": [{"title": "Module 1: Ai Roi", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["b3fee3fe12046032"], "objectives": [{"description": "Understand The Cost-Benefit Fallacy: Why Cost-Benefit Analysis Is Broken and How to Fix It", "bloom_level": "understand"}], "estimated_hours": 2.0, "order": 1}], "total_estimated_hours": 2.0, "prerequisites": ["Complete the Ai Strategy path"], "created_at": "2026-02-09T16:12:24.235586Z", "version": "1.0"}, {"id": "fef17dd0fc52", "title": "Ai Roi \u2014 Advanced", "description": "A advanced-level learning path covering ai roi using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["ai_roi"], "modules": [{"title": "Module 1: Ai Roi", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["bd00aab94075c161"], "objectives": [{"description": "Evaluate The Risk-Adjusted Intelligence Dividend: A Quantitative Framework for Measuring AI Return on Investment Integrating ISO 42001 and Regulatory Exposure", "bloom_level": "evaluate"}], "estimated_hours": 2.0, "order": 1}], "total_estimated_hours": 2.0, "prerequisites": ["Complete the Ai Strategy path", "Complete the Intermediate path for Ai Roi"], "created_at": "2026-02-09T16:12:24.235620Z", "version": "1.0"}, {"id": "8dd24946b492", "title": "Ai Strategy \u2014 Advanced", "description": "A advanced-level learning path covering ai strategy using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["ai_strategy"], "modules": [{"title": "Module 1: Ai Strategy", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["0ff1d61d7f889c51"], "objectives": [{"description": "Evaluate Resource-aware Research on Universe and Matter: Call-to-Action in Digital Transformation", "bloom_level": "evaluate"}], "estimated_hours": 2.0, "order": 1}], "total_estimated_hours": 2.0, "prerequisites": ["Complete the Intermediate path for Ai Strategy"], "created_at": "2026-02-09T16:12:24.235789Z", "version": "1.0"}, {"id": "1800f6ea3f41", "title": "Computer Vision \u2014 Beginner", "description": "A beginner-level learning path covering computer vision using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["computer_vision"], "modules": [{"title": "Module 1: Computer Vision", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["295b779723b066a6", "f630ccf6a4cd840d", "324779ac4f4351ff", "262d055285c37413", "77abc58804469141"], "objectives": [{"description": "Understand The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024", "bloom_level": "understand"}, {"description": "Understand Second Croatian Computer Vision Workshop (CCVW 2013)", "bloom_level": "understand"}, {"description": "Understand TerraGen: A Unified Multi-Task Layout Generation Framework for Remote Sensing Data Augmentation", "bloom_level": "understand"}, {"description": "Understand AeroGen: Enhancing Remote Sensing Object Detection with Diffusion-Driven Data Generation", "bloom_level": "understand"}, {"description": "Understand A Survey of Self-Supervised and Few-Shot Object Detection", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 1}, {"title": "Module 2: Computer Vision", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["df517d92ff23bebf", "9c3844ef06608c5b", "5405c88567776272", "b04add4477980e3c", "86a2760f42226186"], "objectives": [{"description": "Understand Oriented object detection in optical remote sensing images using deep learning: a survey", "bloom_level": "understand"}, {"description": "Understand Deep Learning vs. Traditional Computer Vision", "bloom_level": "understand"}, {"description": "Understand The Informed Sampler: A Discriminative Approach to Bayesian Inference in Generative Computer Vision Models", "bloom_level": "understand"}, {"description": "Understand 2018 Low-Power Image Recognition Challenge", "bloom_level": "understand"}, {"description": "Understand Spatial Monitoring and Insect Behavioural Analysis Using Computer Vision for Precision Pollination", "bloom_level": "understand"}], "estimated_hours": 6.2, "order": 2}, {"title": "Module 3: Computer Vision", "description": "Beginner-level resources \u2014 part 3", "resource_ids": ["627fa273a8595d43", "53c0b77f98bd9f36", "18693b34b6255768", "7ce705e528abcabf", "55db98f8d7e2644d"], "objectives": [{"description": "Understand Super Sparse 3D Object Detection", "bloom_level": "understand"}, {"description": "Understand PVAFN: Point-Voxel Attention Fusion Network with Multi-Pooling Enhancing for 3D Object Detection", "bloom_level": "understand"}, {"description": "Understand Novel Convolution Kernels for Computer Vision and Shape Analysis based on Electromagnetism", "bloom_level": "understand"}, {"description": "Understand A Survey on Computer Vision based Human Analysis in the COVID-19 Era", "bloom_level": "understand"}, {"description": "Understand Quaternion Generative Adversarial Networks", "bloom_level": "understand"}], "estimated_hours": 10.0, "order": 3}], "total_estimated_hours": 16.7, "prerequisites": ["Complete the Deep Learning path"], "created_at": "2026-02-09T16:12:24.236042Z", "version": "1.0"}, {"id": "f4c73b8cfcf5", "title": "Computer Vision \u2014 Advanced", "description": "A advanced-level learning path covering computer vision using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["computer_vision"], "modules": [{"title": "Module 1: Computer Vision", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["7f2816dbe3c2d58d", "b8999e0f0287a5e8", "eba90e97da6515f2", "be42ca9e49333d20", "e59c7b8b2194628e"], "objectives": [{"description": "Evaluate WiCV 2019: The Sixth Women In Computer Vision Workshop", "bloom_level": "evaluate"}, {"description": "Evaluate FedCV: A Federated Learning Framework for Diverse Computer Vision Tasks", "bloom_level": "evaluate"}, {"description": "Evaluate Crowdsourcing in Computer Vision", "bloom_level": "evaluate"}, {"description": "Evaluate Semantic-Aware Scene Recognition", "bloom_level": "evaluate"}, {"description": "Evaluate Exploring Depth Contribution for Camouflaged Object Detection", "bloom_level": "evaluate"}], "estimated_hours": 4.3, "order": 1}, {"title": "Module 2: Computer Vision", "description": "Advanced-level resources \u2014 part 2", "resource_ids": ["3922796e7ed10f33", "841466884f5a2a89", "4996ec509045933c", "ef5edf2eda2366ee"], "objectives": [{"description": "Evaluate Correlation of Object Detection Performance with Visual Saliency and Depth Estimation", "bloom_level": "evaluate"}, {"description": "Evaluate TJU-DHD: A Diverse High-Resolution Dataset for Object Detection", "bloom_level": "evaluate"}, {"description": "Evaluate Object Contour and Edge Detection with RefineContourNet", "bloom_level": "evaluate"}, {"description": "Evaluate Predicting the Future from First Person (Egocentric) Vision: A Survey", "bloom_level": "evaluate"}], "estimated_hours": 6.1, "order": 2}], "total_estimated_hours": 10.4, "prerequisites": ["Complete the Deep Learning path", "Complete the Intermediate path for Computer Vision"], "created_at": "2026-02-09T16:12:24.236108Z", "version": "1.0"}, {"id": "16c2b144f2bf", "title": "Data Engineering \u2014 Beginner", "description": "A beginner-level learning path covering data engineering using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["data_engineering"], "modules": [{"title": "Module 1: Data Engineering", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["c18509ff0fb89c5a", "595c693586942449"], "objectives": [{"description": "Understand A Systematic Review of Common Beginner Programming Mistakes in Data Engineering", "bloom_level": "understand"}, {"description": "Understand An Approach for System Analysis with MBSE and Graph Data Engineering", "bloom_level": "understand"}], "estimated_hours": 2.1, "order": 1}], "total_estimated_hours": 2.1, "prerequisites": [], "created_at": "2026-02-09T16:12:24.236367Z", "version": "1.0"}, {"id": "25a21372e979", "title": "Data Engineering \u2014 Advanced", "description": "A advanced-level learning path covering data engineering using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["data_engineering"], "modules": [{"title": "Module 1: Data Engineering", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["e5454532b4e07c26"], "objectives": [{"description": "Evaluate Data Lakes for Digital Humanities", "bloom_level": "evaluate"}], "estimated_hours": 0.1, "order": 1}], "total_estimated_hours": 0.1, "prerequisites": ["Complete the Intermediate path for Data Engineering"], "created_at": "2026-02-09T16:12:24.236403Z", "version": "1.0"}, {"id": "a777747bd731", "title": "Deep Learning \u2014 Beginner", "description": "A beginner-level learning path covering deep learning using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["deep_learning"], "modules": [{"title": "Module 1: Deep Learning", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["569ebe2079d7e701", "f262a6859b0c48af", "c01da586be378d1e", "5765168ebb93e8ba", "b512ede17bcf8fe2"], "objectives": [{"description": "Understand Deep Learning and Computational Physics (Lecture Notes)", "bloom_level": "understand"}, {"description": "Understand ICML Topological Deep Learning Challenge 2024: Beyond the Graph Domain", "bloom_level": "understand"}, {"description": "Understand Saliency for Fine-grained Object Recognition in Domains with Scarce Training Data", "bloom_level": "understand"}, {"description": "Understand fffaraz/awesome-cpp", "bloom_level": "understand"}, {"description": "Understand Memorization in Deep Neural Networks: Does the Loss Function matter?", "bloom_level": "understand"}], "estimated_hours": 3.3, "order": 1}, {"title": "Module 2: Deep Learning", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["dfaec7de21108086", "885cdff08a2ec511", "be4770c7456c2cd3", "cb58526271c9ce0f", "263dce8f0d4aaeba"], "objectives": [{"description": "Understand Learn to Accumulate Evidence from All Training Samples: Theory and Practice", "bloom_level": "understand"}, {"description": "Understand Deep learning observables in computational fluid dynamics", "bloom_level": "understand"}, {"description": "Understand A Tutorial about Random Neural Networks in Supervised Learning", "bloom_level": "understand"}, {"description": "Understand The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory", "bloom_level": "understand"}, {"description": "Understand Deep Learning for MIR Tutorial", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 2}, {"title": "Module 3: Deep Learning", "description": "Beginner-level resources \u2014 part 3", "resource_ids": ["67a9cecd9aa85c17", "1117b9367d23ff3e", "0925bf274bf1ad9f", "fd2a7e2bd5b9cb24", "216a655ceb2d3718"], "objectives": [{"description": "Understand Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation", "bloom_level": "understand"}, {"description": "Understand Modular Mechanistic Networks: On Bridging Mechanistic and Phenomenological Models with Deep Neural Networks in Natural Language Processing", "bloom_level": "understand"}, {"description": "Understand Monocular Human Pose Estimation: A Survey of Deep Learning-based Methods", "bloom_level": "understand"}, {"description": "Understand A Tutorial on Deep Latent Variable Models of Natural Language", "bloom_level": "understand"}, {"description": "Understand Global Adaptive Filtering Layer for Computer Vision", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 3}], "total_estimated_hours": 4.3, "prerequisites": ["Complete the Ml Basics path"], "created_at": "2026-02-09T16:12:24.236641Z", "version": "1.0"}, {"id": "1da07caa0335", "title": "Deep Learning \u2014 Advanced", "description": "A advanced-level learning path covering deep learning using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["deep_learning"], "modules": [{"title": "Module 1: Deep Learning", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["113d0c60ac980f89", "ab71dcdd3c90a877", "943b5e3668b8a4da"], "objectives": [{"description": "Evaluate The Modern Mathematics of Deep Learning", "bloom_level": "evaluate"}, {"description": "Evaluate Efficient Processing of Deep Neural Networks: A Tutorial and Survey", "bloom_level": "evaluate"}, {"description": "Evaluate Enhancing Modern Supervised Word Sense Disambiguation Models by Semantic Lexical Resources", "bloom_level": "evaluate"}], "estimated_hours": 4.1, "order": 1}], "total_estimated_hours": 4.1, "prerequisites": ["Complete the Ml Basics path", "Complete the Intermediate path for Deep Learning"], "created_at": "2026-02-09T16:12:24.236675Z", "version": "1.0"}, {"id": "b150358f2c7b", "title": "Generative Ai \u2014 Beginner", "description": "A beginner-level learning path covering generative ai using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["generative_ai"], "modules": [{"title": "Module 1: Generative Ai", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["0abcb8d6878db0f0", "d3dfeb6d5f0d6e87", "690b3cffe6e544f0", "b3ce7b5fceb9c593", "f3e7a7ec896819f7"], "objectives": [{"description": "Understand mlabonne/llm-course", "bloom_level": "understand"}, {"description": "Understand hiyouga/LlamaFactory", "bloom_level": "understand"}, {"description": "Understand microsoft/Web-Dev-For-Beginners", "bloom_level": "understand"}, {"description": "Understand GitHubDaily/GitHubDaily", "bloom_level": "understand"}, {"description": "Understand NAACL2025 Tutorial: Adaptation of Large Language Models", "bloom_level": "understand"}], "estimated_hours": 3.3000000000000003, "order": 1}, {"title": "Module 2: Generative Ai", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["21457ada3ea75e96", "e02d868af0a25063", "cb8f252ccaaf10b0", "7a0e993dd0f94c94", "5fcb1dcbcbc18c43"], "objectives": [{"description": "Understand Business (mis)Use Cases of Generative AI", "bloom_level": "understand"}, {"description": "Understand Exploring Advanced Large Language Models with LLMsuite", "bloom_level": "understand"}, {"description": "Understand modelcontextprotocol/servers", "bloom_level": "understand"}, {"description": "Understand Foundations of GenIR", "bloom_level": "understand"}, {"description": "Understand Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions", "bloom_level": "understand"}], "estimated_hours": 9.299999999999999, "order": 2}], "total_estimated_hours": 12.6, "prerequisites": ["Complete the Deep Learning path", "Complete the Nlp path"], "created_at": "2026-02-09T16:12:24.236886Z", "version": "1.0"}, {"id": "adf62da1afd4", "title": "Generative Ai \u2014 Advanced", "description": "A advanced-level learning path covering generative ai using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["generative_ai"], "modules": [{"title": "Module 1: Generative Ai", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["8e1f56955ab17438", "ae13b6bfc876727a", "83bc588fcd5f98b8", "de4f44892c5a2171"], "objectives": [{"description": "Evaluate Tutorial Proposal: Speculative Decoding for Efficient LLM Inference", "bloom_level": "evaluate"}, {"description": "Evaluate Exploring utilization of generative AI for research and education in data-driven materials science", "bloom_level": "evaluate"}, {"description": "Evaluate Morescient GAI for Software Engineering (Extended Version)", "bloom_level": "evaluate"}, {"description": "Evaluate BERT4beam: Large AI Model Enabled Generalized Beamforming Optimization", "bloom_level": "evaluate"}], "estimated_hours": 6.1, "order": 1}], "total_estimated_hours": 6.1, "prerequisites": ["Complete the Deep Learning path", "Complete the Nlp path", "Complete the Intermediate path for Generative Ai"], "created_at": "2026-02-09T16:12:24.236927Z", "version": "1.0"}, {"id": "18d4fea6cc19", "title": "Ml Basics \u2014 Beginner", "description": "A beginner-level learning path covering ml basics using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["ml_basics"], "modules": [{"title": "Module 1: Ml Basics", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["7636653251b1bd3a", "8c6a97dc3e6949c7", "23f4a5d4daecec85", "f41ca49032766a2c", "4919f6a8cb375813"], "objectives": [{"description": "Understand josephmisiti/awesome-machine-learning", "bloom_level": "understand"}, {"description": "Understand Developer-Y/cs-video-courses", "bloom_level": "understand"}, {"description": "Understand The Open MatSci ML Toolkit: A Flexible Framework for Machine Learning in Materials Science", "bloom_level": "understand"}, {"description": "Understand DOME: Recommendations for supervised machine learning validation in biology", "bloom_level": "understand"}, {"description": "Understand Learning Curves for Decision Making in Supervised Machine Learning: A Survey", "bloom_level": "understand"}], "estimated_hours": 5.8, "order": 1}, {"title": "Module 2: Ml Basics", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["d46108234f819ab2", "e60d3f47eeb4bebc", "03d0e48887047c09", "ea21c2b0cf8000d0", "e748a9c136de1ee2"], "objectives": [{"description": "Understand Contraction-Based Methods for Stable Identification and Robust Machine Learning: a Tutorial", "bloom_level": "understand"}, {"description": "Understand Physics-Inspired Interpretability Of Machine Learning Models", "bloom_level": "understand"}, {"description": "Understand MEMe: An Accurate Maximum Entropy Method for Efficient Approximations in Large-Scale Machine Learning", "bloom_level": "understand"}, {"description": "Understand Changing Data Sources in the Age of Machine Learning for Official Statistics", "bloom_level": "understand"}, {"description": "Understand Analysis Acoustic Features for Acoustic Scene Classification and Score fusion of multi-classification systems applied to DCASE 2016 challenge", "bloom_level": "understand"}], "estimated_hours": 2.4, "order": 2}, {"title": "Module 3: Ml Basics", "description": "Beginner-level resources \u2014 part 3", "resource_ids": ["38ba961fd499cda5", "0fce0f39cfa8f835", "c482237e3c6e3f42", "69493baeaf411b5e", "a2eeb03d1fc42dbb"], "objectives": [{"description": "Understand Machine Learning Operations: A Survey on MLOps Tool Support", "bloom_level": "understand"}, {"description": "Understand Sobolev Norm Learning Rates for Regularized Least-Squares Algorithm", "bloom_level": "understand"}, {"description": "Understand ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data", "bloom_level": "understand"}, {"description": "Understand VeML: An End-to-End Machine Learning Lifecycle for Large-scale and High-dimensional Data", "bloom_level": "understand"}, {"description": "Understand A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digital Forensics and Incident Response", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 3}], "total_estimated_hours": 8.7, "prerequisites": [], "created_at": "2026-02-09T16:12:24.237125Z", "version": "1.0"}, {"id": "005f5b202821", "title": "Ml Basics \u2014 Advanced", "description": "A advanced-level learning path covering ml basics using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["ml_basics"], "modules": [{"title": "Module 1: Ml Basics", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["56e365ded63b97b1", "e5b36f5a8f482548", "17bc13f60395b48c", "c49a06889c06c44f", "2a123a504b8b7b35"], "objectives": [{"description": "Evaluate Generalizing Machine Learning Evaluation through the Integration of Shannon Entropy and Rough Set Theory", "bloom_level": "evaluate"}, {"description": "Evaluate A Benchmark Study of Machine Learning Models for Online Fake News Detection", "bloom_level": "evaluate"}, {"description": "Evaluate Activation Analysis of a Byte-Based Deep Neural Network for Malware Classification", "bloom_level": "evaluate"}, {"description": "Evaluate Towards a Praxis for Intercultural Ethics in Explainable AI", "bloom_level": "evaluate"}, {"description": "Evaluate Tutorial on the development of AI models for medical image analysis", "bloom_level": "evaluate"}], "estimated_hours": 0.5, "order": 1}], "total_estimated_hours": 0.5, "prerequisites": ["Complete the Intermediate path for Ml Basics"], "created_at": "2026-02-09T16:12:24.237169Z", "version": "1.0"}, {"id": "c10afeba0792", "title": "Mlops \u2014 Beginner", "description": "A beginner-level learning path covering mlops using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["mlops"], "modules": [{"title": "Module 1: Mlops", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["2d35d90c43823111", "afac539bd2a8ee27", "99c08bfd6b91076e", "4d487b6df54665a0", "96a873d477a47c29"], "objectives": [{"description": "Understand bregman-arie/devops-exercises", "bloom_level": "understand"}, {"description": "Understand awesome-selfhosted/awesome-selfhosted", "bloom_level": "understand"}, {"description": "Understand An Analysis of MLOps Architectures: A Systematic Mapping Study", "bloom_level": "understand"}, {"description": "Understand An Empirical Evaluation of Modern MLOps Frameworks", "bloom_level": "understand"}, {"description": "Understand A Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts", "bloom_level": "understand"}], "estimated_hours": 9.4, "order": 1}, {"title": "Module 2: Mlops", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["35ed62652fe81ddf", "f0fca9799240887c", "82417e4eb69b25bb", "fae0fad77a35f6e4", "d762d44d4af1c90b"], "objectives": [{"description": "Understand Embedding the MLOps Lifecycle into OT Reference Models", "bloom_level": "understand"}, {"description": "Understand Exploring MLOps Dynamics: An Experimental Analysis in a Real-World Machine Learning Project", "bloom_level": "understand"}, {"description": "Understand Automating the Training and Deployment of Models in MLOps by Integrating Systems with Machine Learning", "bloom_level": "understand"}, {"description": "Understand Machine Learning Operations (MLOps): Overview, Definition, and Architecture", "bloom_level": "understand"}, {"description": "Understand Navigating MLOps: Insights into Maturity, Lifecycle, Tools, and Careers", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 2}, {"title": "Module 3: Mlops", "description": "Beginner-level resources \u2014 part 3", "resource_ids": ["14e686ff2e06d9fc", "2728858c176b0ebe", "7ea9d9876f01d334", "b0c79be994d2ebbb"], "objectives": [{"description": "Understand A Multivocal Review of MLOps Practices, Challenges and Open Issues", "bloom_level": "understand"}, {"description": "Understand MLOps with enhanced performance control and observability", "bloom_level": "understand"}, {"description": "Understand CodeReef: an open platform for portable MLOps, reusable automation actions and reproducible benchmarking", "bloom_level": "understand"}, {"description": "Understand Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance", "bloom_level": "understand"}], "estimated_hours": 8.0, "order": 3}], "total_estimated_hours": 17.9, "prerequisites": ["Complete the Ml Basics path"], "created_at": "2026-02-09T16:12:24.237719Z", "version": "1.0"}, {"id": "caa4359d9199", "title": "Mlops \u2014 Intermediate", "description": "A intermediate-level learning path covering mlops using curated free and open-source resources.", "target_audience": "Practitioners with foundational knowledge seeking deeper skills", "difficulty": "intermediate", "domains": ["mlops"], "modules": [{"title": "Module 1: Mlops", "description": "Intermediate-level resources \u2014 part 1", "resource_ids": ["d4c99f9641ad12f1"], "objectives": [{"description": "Apply MLOps: A Multiple Case Study in Industry 4.0", "bloom_level": "apply"}], "estimated_hours": 0.1, "order": 1}], "total_estimated_hours": 0.1, "prerequisites": ["Complete the Ml Basics path", "Complete the Beginner path for Mlops"], "created_at": "2026-02-09T16:12:24.237804Z", "version": "1.0"}, {"id": "46e652e1ccbd", "title": "Mlops \u2014 Advanced", "description": "A advanced-level learning path covering mlops using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["mlops"], "modules": [{"title": "Module 1: Mlops", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["4a969de2a3635f3f", "84960b232a76d170", "a042599a0c81ab67", "e7c985532b52786e"], "objectives": [{"description": "Evaluate MLOps: A Review", "bloom_level": "evaluate"}, {"description": "Evaluate Challenges and Experiences of Iranian Developers with MLOps at Enterprise", "bloom_level": "evaluate"}, {"description": "Evaluate MLOps: A Step Forward to Enterprise Machine Learning", "bloom_level": "evaluate"}, {"description": "Evaluate DNN-Powered MLOps Pipeline Optimization for Large Language Models: A Framework for Automated Deployment and Resource Management", "bloom_level": "evaluate"}], "estimated_hours": 2.3, "order": 1}], "total_estimated_hours": 2.3, "prerequisites": ["Complete the Ml Basics path", "Complete the Intermediate path for Mlops"], "created_at": "2026-02-09T16:12:24.237874Z", "version": "1.0"}, {"id": "0fad5406c193", "title": "Nlp \u2014 Beginner", "description": "A beginner-level learning path covering nlp using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["nlp"], "modules": [{"title": "Module 1: Nlp", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["092c9a36970ba68c", "f412a0532b24e917", "4cfc109e8a9b5a2f", "329bc46ce7a1bbd7", "9e0514ef7ec160be"], "objectives": [{"description": "Understand Teaching NLP with Bracelets and Restaurant Menus: An Interactive Workshop for Italian Students", "bloom_level": "understand"}, {"description": "Understand A dissemination workshop for introducing young Italian students to NLP", "bloom_level": "understand"}, {"description": "Understand Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek", "bloom_level": "understand"}, {"description": "Understand WizardLM: Empowering large pre-trained language models to follow complex instructions", "bloom_level": "understand"}, {"description": "Understand Conditional Unigram Tokenization with Parallel Data", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 1}, {"title": "Module 2: Nlp", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["9858f13fc8934b90", "7452d547fadb48e4", "7c460b801ebd68e9", "af03584d9cd46d2d", "4fadafdfd9490046"], "objectives": [{"description": "Understand Evaluating Morphological Alignment of Tokenizers in 70 Languages", "bloom_level": "understand"}, {"description": "Understand How do language models learn facts? Dynamics, curricula and hallucinations", "bloom_level": "understand"}, {"description": "Understand Towards the Study of Morphological Processing of the Tangkhul Language", "bloom_level": "understand"}, {"description": "Understand An Automated Multiple-Choice Question Generation Using Natural Language Processing Techniques", "bloom_level": "understand"}, {"description": "Understand PyThaiNLP: Thai Natural Language Processing in Python", "bloom_level": "understand"}], "estimated_hours": 6.2, "order": 2}, {"title": "Module 3: Nlp", "description": "Beginner-level resources \u2014 part 3", "resource_ids": ["4153472d9fa06ffc", "4dfa690a3642db0c", "32b62441fef7c002", "44407168ffd0b8c4", "39ffaf06f89645a2"], "objectives": [{"description": "Understand MorphTok: Morphologically Grounded Tokenization for Indian Languages", "bloom_level": "understand"}, {"description": "Understand Language Model Tokenizers Introduce Unfairness Between Languages", "bloom_level": "understand"}, {"description": "Understand Improving Large-scale Language Models and Resources for Filipino", "bloom_level": "understand"}, {"description": "Understand AmazUtah_NLP at SemEval-2024 Task 9: A MultiChoice Question Answering System for Commonsense Defying Reasoning", "bloom_level": "understand"}, {"description": "Understand Challenges Encountered in Turkish Natural Language Processing Studies", "bloom_level": "understand"}], "estimated_hours": 10.0, "order": 3}], "total_estimated_hours": 16.7, "prerequisites": ["Complete the Deep Learning path"], "created_at": "2026-02-09T16:12:24.238199Z", "version": "1.0"}, {"id": "29b721232297", "title": "Nlp \u2014 Intermediate", "description": "A intermediate-level learning path covering nlp using curated free and open-source resources.", "target_audience": "Practitioners with foundational knowledge seeking deeper skills", "difficulty": "intermediate", "domains": ["nlp"], "modules": [{"title": "Module 1: Nlp", "description": "Intermediate-level resources \u2014 part 1", "resource_ids": ["8b8f8903342a15b2"], "objectives": [{"description": "Apply SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks", "bloom_level": "apply"}], "estimated_hours": 0.1, "order": 1}], "total_estimated_hours": 0.1, "prerequisites": ["Complete the Deep Learning path", "Complete the Beginner path for Nlp"], "created_at": "2026-02-09T16:12:24.238230Z", "version": "1.0"}, {"id": "7941456bc091", "title": "Nlp \u2014 Advanced", "description": "A advanced-level learning path covering nlp using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["nlp"], "modules": [{"title": "Module 1: Nlp", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["0beafe0a81307d77", "89227f71807541bd", "0b936146360e893f", "4f0c70b677a0ccf6", "888c1a45d3452807"], "objectives": [{"description": "Evaluate An Open Natural Language Processing Development Framework for EHR-based Clinical Research: A case demonstration using the National COVID Cohort Collaborative (N3C)", "bloom_level": "evaluate"}, {"description": "Evaluate Resources for Turkish Natural Language Processing: A critical survey", "bloom_level": "evaluate"}, {"description": "Evaluate GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek", "bloom_level": "evaluate"}, {"description": "Evaluate Large Multimodal Models: Notes on CVPR 2023 Tutorial", "bloom_level": "evaluate"}, {"description": "Evaluate IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials", "bloom_level": "evaluate"}], "estimated_hours": 0.6000000000000001, "order": 1}, {"title": "Module 2: Nlp", "description": "Advanced-level resources \u2014 part 2", "resource_ids": ["0e3f22993e8f0d56", "926a5ac41b59492f", "e93be84731f52655", "d37bacb29507d9ee", "c3f9900d04e3e192"], "objectives": [{"description": "Evaluate The Interplay between Lexical Resources and Natural Language Processing", "bloom_level": "evaluate"}, {"description": "Evaluate Object Detection with Multimodal Large Vision-Language Models: An In-depth Review", "bloom_level": "evaluate"}, {"description": "Evaluate Exploring the Landscape of Natural Language Processing Research", "bloom_level": "evaluate"}, {"description": "Evaluate VLP: A Survey on Vision-Language Pre-training", "bloom_level": "evaluate"}, {"description": "Evaluate Vision Generalist Model: A Survey", "bloom_level": "evaluate"}], "estimated_hours": 6.2, "order": 2}, {"title": "Module 3: Nlp", "description": "Advanced-level resources \u2014 part 3", "resource_ids": ["5566459751e416ad"], "objectives": [{"description": "Evaluate Towards an AI Observatory for the Nuclear Sector: A tool for anticipatory governance", "bloom_level": "evaluate"}], "estimated_hours": 2.0, "order": 3}], "total_estimated_hours": 8.8, "prerequisites": ["Complete the Deep Learning path", "Complete the Intermediate path for Nlp"], "created_at": "2026-02-09T16:12:24.238303Z", "version": "1.0"}, {"id": "a9558c54fcc6", "title": "Reinforcement Learning \u2014 Beginner", "description": "A beginner-level learning path covering reinforcement learning using curated free and open-source resources.", "target_audience": "Newcomers with no prior experience in this domain", "difficulty": "beginner", "domains": ["reinforcement_learning"], "modules": [{"title": "Module 1: Reinforcement Learning", "description": "Beginner-level resources \u2014 part 1", "resource_ids": ["385cb48c0a1c68b2", "59ed652e61705a23", "f2d726b29f059232", "e14be50b90ceb2fa", "22e616695896713a"], "objectives": [{"description": "Understand A New Strategy for the Exploration of Venus", "bloom_level": "understand"}, {"description": "Understand ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning", "bloom_level": "understand"}, {"description": "Understand Exploring Hierarchy-Aware Inverse Reinforcement Learning", "bloom_level": "understand"}, {"description": "Understand A Tutorial on Meta-Reinforcement Learning", "bloom_level": "understand"}, {"description": "Understand Stabilizing Extreme Q-learning by Maclaurin Expansion", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 1}, {"title": "Module 2: Reinforcement Learning", "description": "Beginner-level resources \u2014 part 2", "resource_ids": ["df9ce4fe3b6240d0", "6c8891ba2ea27b5b", "7912874316b9da40", "4db6d95b4928de7c", "73f5db2959ca3dd8"], "objectives": [{"description": "Understand Tutorial and Survey on Probabilistic Graphical Model and Variational Inference in Deep Reinforcement Learning", "bloom_level": "understand"}, {"description": "Understand Characterizing Policy Divergence for Personalized Meta-Reinforcement Learning", "bloom_level": "understand"}, {"description": "Understand Emotion in Reinforcement Learning Agents and Robots: A Survey", "bloom_level": "understand"}, {"description": "Understand Continuous-time q-learning for mean-field control problems", "bloom_level": "understand"}, {"description": "Understand Convex Q Learning in a Stochastic Environment: Extended Version", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 2}, {"title": "Module 3: Reinforcement Learning", "description": "Beginner-level resources \u2014 part 3", "resource_ids": ["c0fd179f031d8ea9", "d8287dda74789e77", "74afd64fe39afabc", "204d68c9134cf197", "2c2b104ee8f75006"], "objectives": [{"description": "Understand Lookahead-Bounded Q-Learning", "bloom_level": "understand"}, {"description": "Understand Reinforcement Learning with Stepwise Fairness Constraints", "bloom_level": "understand"}, {"description": "Understand A Brief Survey of Deep Reinforcement Learning", "bloom_level": "understand"}, {"description": "Understand MERL: Multi-Head Reinforcement Learning", "bloom_level": "understand"}, {"description": "Understand Compression and Localization in Reinforcement Learning for ATARI Games", "bloom_level": "understand"}], "estimated_hours": 0.5, "order": 3}], "total_estimated_hours": 1.5, "prerequisites": ["Complete the Ml Basics path"], "created_at": "2026-02-09T16:12:24.238645Z", "version": "1.0"}, {"id": "16c4f5428ec0", "title": "Reinforcement Learning \u2014 Intermediate", "description": "A intermediate-level learning path covering reinforcement learning using curated free and open-source resources.", "target_audience": "Practitioners with foundational knowledge seeking deeper skills", "difficulty": "intermediate", "domains": ["reinforcement_learning"], "modules": [{"title": "Module 1: Reinforcement Learning", "description": "Intermediate-level resources \u2014 part 1", "resource_ids": ["c8bed4e399590cde", "d6aba3e232717055"], "objectives": [{"description": "Apply Causal-Paced Deep Reinforcement Learning", "bloom_level": "apply"}, {"description": "Apply Training Agents using Upside-Down Reinforcement Learning", "bloom_level": "apply"}], "estimated_hours": 0.2, "order": 1}], "total_estimated_hours": 0.2, "prerequisites": ["Complete the Ml Basics path", "Complete the Beginner path for Reinforcement Learning"], "created_at": "2026-02-09T16:12:24.238687Z", "version": "1.0"}, {"id": "5bb7a626f135", "title": "Reinforcement Learning \u2014 Advanced", "description": "A advanced-level learning path covering reinforcement learning using curated free and open-source resources.", "target_audience": "Experienced professionals aiming for expert-level mastery", "difficulty": "advanced", "domains": ["reinforcement_learning"], "modules": [{"title": "Module 1: Reinforcement Learning", "description": "Advanced-level resources \u2014 part 1", "resource_ids": ["4bedaf1c79629481", "c42bc6523470c1e4", "f9b845057c6d6e97"], "objectives": [{"description": "Evaluate Accelerating Training in Pommerman with Imitation and Reinforcement Learning", "bloom_level": "evaluate"}, {"description": "Evaluate Inverse Reinforcement Learning with Multiple Planning Horizons", "bloom_level": "evaluate"}, {"description": "Evaluate How to discretize continuous state-action spaces in Q-learning: A symbolic control approach", "bloom_level": "evaluate"}], "estimated_hours": 0.30000000000000004, "order": 1}], "total_estimated_hours": 0.3, "prerequisites": ["Complete the Ml Basics path", "Complete the Intermediate path for Reinforcement Learning"], "created_at": "2026-02-09T16:12:24.238722Z", "version": "1.0"}], "generated_at": "2026-02-09T16:12:24.247409Z", "source_catalog_hash": "eaa9598c9a4c5aa2", "metadata": {"domains_covered": ["ai_ethics", "ai_governance", "ai_project_management", "ai_roi", "ai_strategy", "computer_vision", "data_engineering", "deep_learning", "generative_ai", "ml_basics", "mlops", "nlp", "reinforcement_learning"], "total_resources": 269, "total_paths": 30}};

// Populate stats
document.getElementById('total-resources').textContent = RESOURCES.length;
document.getElementById('total-paths').textContent = CURRICULUM.learning_paths ? CURRICULUM.learning_paths.length : 0;
const totalHours = CURRICULUM.learning_paths ? CURRICULUM.learning_paths.reduce((sum, p) => sum + (p.total_estimated_hours || 0), 0) : 0;
document.getElementById('total-hours').textContent = totalHours.toFixed(0);
const allDomains = [...new Set(RESOURCES.flatMap(r => r.domains || []))].sort();
document.getElementById('total-domains').textContent = allDomains.length;

// Populate domain filters
const domainSelect = document.getElementById('domain-filter');
const pathDomainSelect = document.getElementById('path-domain-filter');
allDomains.forEach(d => {
  const label = d.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase());
  domainSelect.add(new Option(label, d));
  pathDomainSelect.add(new Option(label, d));
});

// Populate type filter
const allTypes = [...new Set(RESOURCES.map(r => r.content_type))].sort();
const typeSelect = document.getElementById('type-filter');
allTypes.forEach(t => {
  const label = t.replace(/_/g, ' ').replace(/\b\w/g, c => c.toUpperCase());
  typeSelect.add(new Option(label, t));
});

// Resource ID to resource map
const resourceMap = {};
RESOURCES.forEach(r => resourceMap[r.id] = r);

function scoreClass(score) {
  if (score >= 0.7) return 'high';
  if (score >= 0.5) return 'medium';
  return 'low';
}

function renderResource(r) {
  const domains = (r.domains || []).map(d => '<span class="tag tag-domain">' + d.replace(/_/g, ' ') + '</span>').join('');
  const typeLabel = (r.content_type || '').replace(/_/g, ' ');
  const hours = r.estimated_hours ? '<span class="tag tag-hours">' + r.estimated_hours + 'h</span>' : '';
  return '<div class="card">' +
    '<div class="card-header">' +
      '<div class="card-title"><a href="' + r.url + '" target="_blank" rel="noopener">' + escHtml(r.title) + '</a></div>' +
      '<span class="card-score ' + scoreClass(r.quality_score) + '">' + (r.quality_score || 0).toFixed(2) + '</span>' +
    '</div>' +
    (r.description ? '<div class="card-desc">' + escHtml(r.description).substring(0, 300) + '</div>' : '') +
    '<div class="resource-link"><a href="' + r.url + '" target="_blank" rel="noopener">' + escHtml(r.url) + '</a></div>' +
    '<div class="card-tags" style="margin-top:0.5rem">' +
      domains +
      '<span class="tag tag-type">' + typeLabel + '</span>' +
      '<span class="tag tag-difficulty">' + (r.difficulty || 'beginner') + '</span>' +
      (r.provider ? '<span class="tag tag-provider">' + r.provider + '</span>' : '') +
      hours +
    '</div>' +
  '</div>';
}

function renderPath(path) {
  const diffClass = (path.difficulty || 'beginner');
  let modulesHtml = '';
  if (path.modules) {
    modulesHtml = '<ol class="module-list">';
    path.modules.forEach(mod => {
      const resourceLinks = (mod.resource_ids || []).map(rid => {
        const res = resourceMap[rid];
        if (res) return '<a href="' + res.url + '" target="_blank" rel="noopener">' + escHtml(res.title) + '</a>';
        return rid;
      }).join('<br>');
      modulesHtml += '<li class="module-item"><strong>' + escHtml(mod.title) + '</strong> (' + (mod.estimated_hours || 0).toFixed(1) + 'h)' +
        '<div style="margin-top:0.3rem;font-size:0.85rem;color:#555">' + resourceLinks + '</div></li>';
    });
    modulesHtml += '</ol>';
  }
  const prereqs = (path.prerequisites || []).length > 0
    ? '<div style="margin-top:0.5rem;font-size:0.85rem;color:#888">Prerequisites: ' + path.prerequisites.join(', ') + '</div>'
    : '';
  return '<div class="card path-card">' +
    '<div class="card-header">' +
      '<div class="card-title">' + escHtml(path.title) + '</div>' +
      '<span class="tag tag-hours">' + (path.total_estimated_hours || 0).toFixed(1) + 'h</span>' +
    '</div>' +
    '<div><span class="path-difficulty ' + diffClass + '">' + diffClass.toUpperCase() + '</span>' +
      '<span style="color:#666;font-size:0.9rem">' + (path.modules || []).length + ' modules &middot; ' + escHtml(path.target_audience || '') + '</span>' +
    '</div>' +
    (path.description ? '<div class="card-desc" style="margin-top:0.5rem">' + escHtml(path.description) + '</div>' : '') +
    prereqs +
    modulesHtml +
  '</div>';
}

function escHtml(s) {
  if (!s) return '';
  return s.replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;').replace(/"/g,'&quot;');
}

function filterResources() {
  const query = document.getElementById('search-input').value.toLowerCase();
  const domain = document.getElementById('domain-filter').value;
  const type = document.getElementById('type-filter').value;
  const diff = document.getElementById('difficulty-filter').value;
  const filtered = RESOURCES.filter(r => {
    if (query && !(r.title + ' ' + r.description + ' ' + (r.tags || []).join(' ')).toLowerCase().includes(query)) return false;
    if (domain && !(r.domains || []).includes(domain)) return false;
    if (type && r.content_type !== type) return false;
    if (diff && r.difficulty !== diff) return false;
    return true;
  });
  filtered.sort((a, b) => (b.quality_score || 0) - (a.quality_score || 0));
  document.getElementById('resource-count').textContent = 'Showing ' + filtered.length + ' of ' + RESOURCES.length + ' resources';
  document.getElementById('resource-list').innerHTML = filtered.length
    ? filtered.map(renderResource).join('')
    : '<div class="empty-state">No resources match your filters.</div>';
}

function filterPaths() {
  const query = document.getElementById('path-search').value.toLowerCase();
  const domain = document.getElementById('path-domain-filter').value;
  const diff = document.getElementById('path-difficulty-filter').value;
  const paths = CURRICULUM.learning_paths || [];
  const filtered = paths.filter(p => {
    if (query && !(p.title + ' ' + p.description).toLowerCase().includes(query)) return false;
    if (domain && !(p.domains || []).includes(domain)) return false;
    if (diff && p.difficulty !== diff) return false;
    return true;
  });
  document.getElementById('path-list').innerHTML = filtered.length
    ? filtered.map(renderPath).join('')
    : '<div class="empty-state">No learning paths match your filters.</div>';
}

function switchTab(tab) {
  document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
  document.querySelectorAll('.section').forEach(s => s.classList.remove('active'));
  if (tab === 'catalog') {
    document.querySelectorAll('.tab')[0].classList.add('active');
    document.getElementById('catalog-section').classList.add('active');
  } else {
    document.querySelectorAll('.tab')[1].classList.add('active');
    document.getElementById('curriculum-section').classList.add('active');
  }
}

// Initial render
filterResources();
filterPaths();
</script>
</body>
</html>